<h1><a href="http://rg.157careers.in/" target="_blank"> Recruiter's Gear Documentation</a></h1>


 #### **Note:** While third party links in this application may open in the same tab by default, users can easily open them in a new tab by using the following keyboard shortcuts:
       - **Windows/Linux:** Hold the `CTRL` key and click the link.
       - **MacOS:** Hold the `CMD` key and click the link.
       These shortcuts allow users to open links in a new tab, providing greater flexibility in navigating the application.

  
<Table>
  <thead>
    <tr>
      <th>Aspect</th>
      <th>Software Documentation</th>
      <th>Project Documentation</th>
      <th>User Documentation</th>
      <th>Developer Documentation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><b>Purpose</b></td>
        <td><a href = "#comprehensive-solutions">Comprehensive Solutions</a></td>
        <td><a href = "#comprehensive-solutions">Comprehensive Solutions</a></td>
	<td><a href = "#comprehensive-solutions">Comprehensive Solutions</a></td>
        <td><a href = "#comprehensive-solutions">Comprehensive Solutions</a></td>
    </tr>
    <tr>
      <td><b>Target Audience</b></td>
      <td><a href = "#back-end-code-flow">Back-End: Code Structure, <a/><a href = "#front-end-code-flow">Front-End: Code Structure<a/></td>
      <td><a href = "#back-end-code-flow">Back-End: Code Structure<a/></td>
      <td><a href = " "><a/></td>
      <td><a href = "#back-end-code-flow">Back-End: Code Structure, <a/><a href = "#front-end-code-flow">Front-End: Code Structure, <a/><a href = " "><a/><a href = "#api-fetching-in-react">Front-End: API CRUD Operation, <a/><a href = "#socketio">SocketIO, <a/></td>
    </tr>
    <tr>
      <td><b>Level of Details</b></td>
      <td><a href = "#best-practices">Code Convention, <a/><a href = "#database">Database, <a/><a href = "#testing-reports">Testing Reports, <a/></td>
      <td><a href = "#development-workflow-full-stack">Front-End: Development workflow, <a/><a href = "#development-workflow-full-stack">Back-End: Development workflow, <a/><a href = "#deployment">Deployment, <a/><a href = "#deployment-process">Deployment Process<a/></td>
      <td><a href = "#full-stack-development-flowchart">Back-End: Flow Chart, <a/><a href = "#full-stack-development-flowchart">Front-End: Logic Flow Chart, <a/><a href = "#development-workflow-full-stack">Back-End: Development workflow, <a/><a href = "#development-workflow-full-stack">Front-End: Development workflow<a/></td>
      <td><a href = "#best-practices">Code Convention, <a/><a href = "#development-workflow-full-stack">Back-End: Development workflow, <a/><a href = "#database">Database, <a/><a href = "#testing-reports">Testing Reports, <a/><a href = "#deployment">Deployment<a/><a href = "#deployment-process">Deployment Process<a/></td>
    </tr>
    <tr>
      <td><b>Focus Area</b></td>
      <td><a href = "#error-handling">Error Handling<a/></td>
      <td><a href = " "><a/></td>
      <td><a href = " "><a/></td>
      <td><a href = "#error-handling">Error Handling<a/></td>
    </tr>
    <tr>
      <td><b>Examples</b></td>
      <td><a href = "#details-about-app-dot-jsx">Front-End: App.jsx Details<a/></td>
      <td><a href = " "><a/></td>
      <td><a href = " "><a/></td>
      <td><a href = "#back-end">Back-End: How to Install?, <a/><a href= "#back-end">Back-End: How to Run?, </a><a href = "#front-end">Front-End: How to Install?, <a/><a href = "#front-end">Front-End: How to Run?, </a><a href = "#details-about-app-dot-jsx">Front-End: App.jsx Details<a/></td>
    </tr>
    <tr>
      <td><b>Format</b></td>
      <td><a href = "#understanding-endpoints">Back-End: End-Points, <a/><a href = "#back-end-project-structure">Back-End: Project Structure, <a/><a href = "#front-end-project-structure">Front-End: Project Structure<a/></td>
      <td><a href = "#understanding-endpoints">Back-End: End-Points, <a/><a href = " ">Types of Controllers, <a/><a href = "#back-end-project-structure">Back-End: Project Structure, <a/><a href = "#front-end-project-structure">Front-End: Project Structure<a/></td>
      <td><a href = "#understanding-endpoints">Back-End: End-Points, <a/><a href = " "><a/></td>
      <td><a href = "#understanding-endpoints">Back-End: End-Points, <a/><a href = " ">Types of Controllers, <a/><a href = "#back-end-project-structure">Back-End: Project Structure, <a/><a href = "#front-end-project-structure">Front-End: Project Structure<a/></td>
    </tr>
    <tr>
      <td><b>Requirements</b></td>
      <td><a href = "#how-to-set-the-path-of-the-environment-variable">ENV Variable, <a/><a href = "#front-end-dependencies">Front-End: Dependencies & Versions, <a/><a href = "#back-end-dependencies">Back-End: Dependencies & Versions, <a/><a href = "#socketio">SocketIO<a/><a href = "#configuration-of-application-dot-properties">Back-End: application.properties, <a/><a href = "#about-package-dot-json">Fron-End: pacakge.json file, <a/><a href = " ">Front-End: npm libraries<a/></td>
      <td><a href = "#software-and-hardware-compatibility">Application Compatibility: Software/Hardware, <a/><a href = "#subscription">Subscription<a/></td>
      <td><a href = "#software-and-hardware-compatibility">Application Compatibility: Software/Hardware, <a/><a href = "#subscription">Subscription<a/></td>
      <td><a href = "#technologies">Technologies: Front-End, Back-End, Database, Cloud, Authentication, Version Control, Servers, <a/><a href = "#how-to-set-the-path-of-the-environment-variable">ENV Variable, <a/><a href = " "><a/><a href = "#front-end-dependencies">Front-End: Dependencies & Versions, <a/><a href = "#back-end-dependencies">Back-End: Dependencies & Versions, <a/><a href = "#socketio">SocketIO Server, <a/><a href = "#configuration-of-application-dot-properties">Back-End: application.properties, <a/><a href = "#about-package-dot-json">Front-End: pacakge.json file, <a/><a href = "#dependencies">Front-End: npm libraries, <a/><a href = "#css-tailwind-bootstrap">Front-End: CSS, Tailwind<a/></td>
    </tr>
  </tbody>
</Table>

### **Technologies**

#### **1. Front-End: React + Vite**

- **1.1. React** is one of the most popular and powerful JavaScript libraries for building user interfaces, especially Single Page Applications (SPAs). It provides a component-based architecture, promoting reusability, maintainability, and scalability.
- **1.2. Vite** is a modern, fast build tool optimized for speed and performance. Unlike older bundlers like Webpack, Vite uses native ES modules in the development environment, resulting in extremely fast hot module replacement (HMR) and faster builds. It's designed to be simple, minimal, and super fast, making it ideal for modern React projects.

#### **1.3. Why it's good:**
- **1.3.1. Developer Experience**: Vite's lightning-fast build times and React's component model enhance productivity, making development smoother.
- **1.3.2. Performance**: Vite's on-demand code loading helps keep initial load times fast, improving the user experience.

---

#### **2. Back-End: Java; Framework: Spring Boot**

- **2.1. Java** is a time-tested, reliable, and highly scalable programming language with a vast ecosystem and community. It's ideal for building large-scale, enterprise-level applications due to its stability, security features, and performance.
- **2.2. Spring Boot** is a popular Java framework that simplifies the setup and configuration of Spring applications. It offers out-of-the-box solutions for many common problems, such as REST API development, database connections, and security. It follows the principles of convention over configuration, allowing developers to focus on business logic rather than boilerplate code.

#### **2.3. Why it's good:**
- **2.3.1. Scalability**: Java with Spring Boot is perfect for building scalable, high-performance back-end systems. It easily integrates with various databases and third-party services, and Spring Boot's microservices support allows for building complex applications.
- **2.3.2. Security**: Spring Boot has built-in support for security features, making it easier to protect applications.
- **2.3.3. Ease of Use**: Spring Boot’s extensive set of pre-configured templates and auto-configuration features makes it quicker to set up and develop applications.

---

#### **3. Database: MySQL**

- **3.1. MySQL** is one of the most popular relational database management systems (RDBMS) in the world. Known for its performance, reliability, and ease of use, MySQL supports ACID-compliant transactions, ensuring data consistency, durability, and integrity — all critical for modern web applications.

#### **3.2. Why it's good:**
- **3.2.1. Mature and Reliable**: MySQL is battle-tested in production environments for years and is often the go-to database for various applications, from small startups to large enterprises.
- **3.2.2. Open-source**: As an open-source database, MySQL offers a robust set of features without the licensing costs of commercial databases.
- **3.2.3. Good Integration**: MySQL integrates seamlessly with Spring Boot (via Spring Data JPA, for example), streamlining development.

---

#### **4. Cloud: Ubuntu**

- **4.1. Ubuntu** is a popular open-source operating system, widely used for cloud deployments. It is known for its ease of use, regular updates, and large community support. Ubuntu is often the preferred choice for cloud servers on platforms like AWS, Azure, and DigitalOcean due to its compatibility with most cloud providers.

#### **4.2. Why it's good:**
- **4.2.1. Open Source and Free**: Ubuntu is free to use, making it cost-effective.
- **4.2.2. Stability and Security**: Ubuntu provides regular updates and strong security features, making it a solid choice for production environments.
- **4.2.3. Compatibility**: Most cloud environments (including AWS EC2, Google Cloud, etc.) support Ubuntu, and it’s optimized for cloud deployments.

---

#### **5. Authentication: OAuth2**

- **5.1. OAuth2** is the industry standard for authorization and authentication. It allows users to securely authenticate to applications without exposing their credentials, relying instead on tokens (such as access and refresh tokens). OAuth2 can enable single sign-on (SSO) and third-party authentication, like signing in with Google or Facebook.

#### **5.2. Why it's good:**
- **5.2.1. Security**: OAuth2 is widely accepted, ensuring secure, token-based access management without needing to store passwords directly.
- **5.2.2. Flexibility**: It can be integrated with many identity providers, enabling flexibility and easier management of user access across platforms.
- **5.2.3. Single Sign-On (SSO)**: OAuth2 enables SSO, allowing users to authenticate once and use multiple apps without needing to log in repeatedly.

---

#### **6. Version Control: Git**

- **6.1. Git** is the most widely used version control system in the world. It enables teams to manage code changes efficiently, track history, and collaborate on projects.

#### **6.2. Why it's good:**
- **6.2.1. Collaboration**: Git facilitates easy collaboration by allowing branching, merging, and versioning.
- **6.2.2. Version History**: Git tracks all changes to the codebase, making it easy to roll back to any previous version.
- **6.2.3. Distributed Nature**: Git's distributed model enables every developer to have their own local copy of the repository, which improves speed and offline work.


### Topic: How to Install / Run?

### Front-End:

#### Node.js and React with Vite: Overview and Setup

#### Latest Node.js Versions (As of January 22, 2025)

- **Current Version:** Node.js v23.6.1  
- **Long-Term Support (LTS) Version:** Node.js v22.13.1 (Jod)

The Current version includes the latest features and improvements, suitable for testing and development environments. The LTS version is recommended for production applications due to its stability and extended support.

#### Checking Your Node.js Version
To check your installed Node.js version, run the following command:
```bash
node -v
```

---

#### **What is Node.js Used For?**

Node.js is a powerful, open-source runtime environment that allows you to execute JavaScript code on the server side. It enables developers to build scalable, high-performance web applications and tools. Below is a breakdown of its uses:

#### 1. Server-Side Web Applications
- Build dynamic, fast, and scalable server-side applications.
- Handle multiple client requests efficiently using its non-blocking, event-driven architecture.
- **Example:** RESTful APIs for web and mobile applications.

#### 2. Real-Time Applications
- Ideal for apps requiring real-time interaction, such as:
  - Chat applications
  - Online gaming platforms
  - Collaboration tools (e.g., Google Docs-like apps)
- Technologies like Web Sockets enable real-time communication.

#### 3. API Development
- Create lightweight and efficient REST APIs or GraphQL APIs.
- Popular frameworks like **Express.js** simplify API development.

#### 4. Microservices
- Well-suited for a microservices architecture where applications are split into smaller, independently deployable services.
- Improves scalability and maintainability.

#### 5. Command-Line Tools
- Build CLI tools to automate tasks or simplify workflows.
- **Example:** Tools like ESLint or npm itself are built with Node.js.

#### 6. Static File Servers
- Serve static files such as images, HTML, and CSS without needing a separate web server like Apache or Nginx.

#### 7. Streaming Applications
- Handle data streams efficiently, making Node.js great for video and audio streaming platforms.
- **Example:** Implementing file uploads or media streaming services.

#### 8. IoT Applications
- Manage real-time data processing for Internet of Things (IoT) devices.
- Asynchronous nature helps handle data from numerous devices simultaneously.

#### 9. Data-Intensive Applications
- Process large volumes of data in real-time, such as stock trading apps or analytics platforms.

---

#### **Why Use Node.js**?

1. **Performance:** Built on Chrome’s V8 engine, Node.js offers exceptional speed.
2. **Non-Blocking I/O:** Handles multiple requests simultaneously without waiting for processes to complete.
3. **Scalability:** Ideal for handling large-scale, high-traffic applications.
4. **Rich Ecosystem:** npm provides access to a vast library of open-source packages.
5. **JavaScript Everywhere:** Enables full-stack development using a single language (JavaScript) for both client and server sides.

#### **Key Points:**

1. **Environment Variables:** Use `process.env.PORT` so the port can be configured dynamically, especially in production environments like cloud platforms.
2. **Default Port:** If no environment variable is provided, set a default port like 3000 or any other suitable number.
3. **Common Ports:**
   - 3000, 8080, and 5000 are commonly used for development servers.
   - Ensure the port you choose is not already in use by another service.

---

#### **Why Use React with Vite**?

1. **Blazing Fast Development:** Vite leverages native ES modules and modern tooling for near-instant dev server startup.
2. **Optimized Builds:** Vite ensures optimized production builds with minimal configuration.
3. **Hot Module Replacement (HMR):** Changes in your code reflect instantly in the browser without a full reload.
4. **Minimal Boilerplate:** Setting up a React app with Vite is fast and straightforward.

---

#### **Setting Up React with Vite**

1. **Install Vite**
   Run the following command to create a Vite-powered React project:
   ```bash
   npm create vite@latest my-react-app --template react
   ```
   Alternatively, for TypeScript:
   ```bash
   npm create vite@latest my-react-app --template react-ts
   ```

2. **Navigate to Your Project**
   ```bash
   cd my-react-app
   ```

3. **Install Dependencies**
   ```bash
   npm install
   ```

4. **Start Development Server**
   ```bash
   npm run dev
   ```

---

#### **How To Install React.js On Windows?**

#### **Step 1: Install Node.js And npm**

Start by installing the Node.js installer for Windows. Visit the [Node.js official website](https://nodejs.org/) and download the LTS version. Once the installer is downloaded, run it, and follow the prompts, ensuring you don’t change any default settings. Click “Next” until the installation is complete. 
![Npm](https://github.com/user-attachments/assets/8fdafbc8-4499-4ebc-bd4d-17189d8803d1)


#### **Step 2: Verify that Node.js npm are installed.**

After the installation is complete, you can verify that Node.js and npm are installed by opening a command prompt and running the following commands:

```bash
node --version
```

If the installation is successful, the terminal will display the installed version of Node.js.

```bash
npm --version
```
If the installation is successful, the terminal will display the installed version of npm.

![Version](https://github.com/user-attachments/assets/01ce4967-1297-463c-8d23-ef489ffba116)

These commands should display the version numbers for Node.js and npm, respectively.

#### **3. How To Run Project?**

#### **Step 1: Open Your Project in an IDE**

Open your preferred IDE (e.g., Visual Studio Code) and navigate to the folder where your React app was installed.

![IDE](https://github.com/user-attachments/assets/01d2c8dc-5cd2-419f-b9c1-dc4856cad775)

#### **Step 2: Create a New React Project**

Now that you have Create React App installed, you can use it to create a new React project. To do this, open a command prompt, go to the directory where you want the project to live, and run the following command:

```bash
npm create vite@latest atsfrontend
```
![Npm command](https://github.com/user-attachments/assets/6c035137-3e0b-4ba4-a01c-0262f702b654)

Replace “atsfrontend” with the desired name for your project. Create React App will create a new directory with the specified name and generate a new React project with a recommended project structure and configuration.

#### **Step 3: Start The Development Server**

Once the project is created, head over to the project directory by running the following command in the command prompt:

```bash
cd atsfrontend
```
Replace “atsfrontend” with the name of your project directory. Now, start the development server by running the following command:

```bash
npm install
```
![Start server](https://github.com/user-attachments/assets/da0327d2-85df-4724-ad0d-e0d32ea2a71c)

```bash
npm run dev
```
This command launches the development server, which watches for changes to your project files and automatically reloads the browser when changes are detected.
<br/>

![Page](https://github.com/user-attachments/assets/a3b4ebd5-0952-48a8-afd2-278e10c3934a)

---

### Back-End:

### JDK

#### 1.1: What is JDK?

**JDK 17** (Java Development Kit 17) is a major release of the Java platform, released in September 2021 by Oracle. It is a **Long-Term Support (LTS)** version, meaning it will receive extended support and updates for several years, making it a preferred choice for many developers and enterprises for building production-ready applications.

The **JDK** is a software development kit that provides all the tools required for Java development, including:

- **Java Runtime Environment (JRE)** – the environment in which Java applications run.
- **Java Compiler** – compiles Java code into bytecode for the JVM.
- **Java Virtual Machine (JVM)** – the engine that executes Java bytecode.
- **Java Libraries** – standard classes and APIs that Java developers use for common tasks.
- **Development, Debugging, and Monitoring Tools** – tools like `javac`, `jdb`, and `jconsole` for building, testing, and monitoring Java applications.

---

#### 1.2: Why Do We Use JDK 17?

#### 1.2.1: **Long-Term Support (LTS)**

JDK 17 is an **LTS version**, which means it will receive updates, bug fixes, and security patches for **several years** (until at least 2029). LTS versions are preferred in **production environments** as they ensure stability and long-term support.

#### 1.2.2: **New Features & Enhancements**

JDK 17 brings many new features, enhancements, and improvements to the Java platform, which can improve developer productivity and system performance. These include features like:

- **Pattern Matching** (for switch expressions and `instanceof` operations).
- **Sealed Classes** (a new feature to restrict class inheritance).
- **Strong encapsulation of JDK internals** (improving security).
- **Improved garbage collection** (with new garbage collectors, like the G1 Garbage Collector).
- **Deprecation and removal of outdated APIs** (to streamline and modernize the platform).

#### 1.2.3: **Performance Improvements**

JDK 17 includes performance improvements, such as better garbage collection, improved JVM optimizations, and better support for modern hardware architectures, leading to faster and more efficient applications.

#### 1.2.4: **Security Updates**

With each new version, Oracle addresses known security vulnerabilities and enhances the security of Java applications. JDK 17 comes with enhanced security features, such as support for the latest encryption standards.

#### 1.2.5: **Compatibility**

JDK 17 ensures backward compatibility with older Java versions, ensuring that most existing Java applications can run without issues. However, it is always recommended to test your code when upgrading.

#### 1.2.6: **Deprecations and Removals**

Some older and less-used features or APIs are removed or deprecated, helping to keep the platform lean and modern.

---

#### 1.3: Advantages of JDK 17?

#### 1.3.1: **LTS Support**

As an LTS release, JDK 17 will be supported for several years (until 2029), making it suitable for long-term projects and production environments.

#### 1.3.2: **Improved Performance**

Enhancements like better garbage collection and performance optimizations improve the speed and efficiency of Java applications.

#### 1.3.3: **New Language Features**

- **Pattern Matching** for `switch`: Simplifies code and makes it more concise and readable.
- **Sealed Classes**: Provides more control over class inheritance, leading to better maintainability and security.

#### 1.3.4: **Security**

Improved security features ensure that your applications are less susceptible to vulnerabilities. Additionally, Oracle continuously addresses security threats by releasing regular updates.

#### 1.3.5: **Modernization of the Java Platform**

The removal of deprecated or outdated features streamlines the platform and encourages the use of modern practices.

#### 1.3.6: **Better Garbage Collection**

JDK 17 has optimizations in garbage collection (like the G1 garbage collector), reducing memory overhead and increasing application throughput.

#### 1.3.7: **Support for Modern Development**

JDK 17 is aligned with modern software development practices and tools, including enhanced support for microservices, cloud-native apps, and containerization (e.g., Docker, Kubernetes).

---

#### 1.4: How to Install JDK 17?

#### Step 1: Download JDK 17

1. Visit the official Oracle website or OpenJDK website for downloading JDK 17:
   - **Oracle JDK 17**: [Oracle Downloads](https://www.oracle.com/java/technologies/javase-jdk17-downloads.html)
   - **OpenJDK 17** (Open source version): [OpenJDK Downloads](https://openjdk.java.net/projects/jdk/17/)
     #### **Note:** While links in this application may open in the same tab by default, users can easily open them in a new tab by using the following keyboard shortcuts:
       - **Windows/Linux:** Hold the `CTRL` key and click the link.
       - **MacOS:** Hold the `CMD` key and click the link.
       These shortcuts allow users to open links in a new tab, providing greater flexibility in navigating the application.

2. Choose the appropriate version based on your operating system (Windows, macOS, or Linux). You can download either the Oracle JDK (commercial version) or OpenJDK (open-source, free to use).

3. For Windows, choose the `.exe` file for easy installation. For macOS or Linux, choose the `.dmg` or `.tar.gz` file.

---

#### Step 2: Install JDK 17

#### For Windows:

1. After downloading the `.exe` file, double-click it to begin the installation process.
2. Follow the installation wizard, and make note of the installation directory (usually `C:\Program Files\Java\jdk-17`).
3. Once the installation is complete, you can verify the installation by opening a **Command Prompt** and running:

   ```bash
   java -version

It should show something like: 

Copy: 
```java
java version "17.0.1" 2021-10-19 LTS 

Java(TM) SE Runtime Environment (build 17.0.1+12-39) 

Java HotSpot(TM) 64-Bit Server VM (build 17.0.1+12-39, mixed mode) 
```
#### For macOS:

1. Double-click the downloaded `.dmg` file to mount it and follow the instructions to install JDK 17.
2. After installation, verify by running the following command in the terminal:

   ```bash
   java -version
#### For Linux:

1. For **Ubuntu/Debian-based** distributions, you can use `apt` to install JDK 17:

   ```bash
   sudo apt update
   sudo apt install openjdk-17-jdk
   ```
2. For **Red Hat/CentOS-based** distributions, you can use `yum` or `dnf`:

   ```bash
   sudo dnf install java-17-openjdk
   ```
3. After installation, verify it by running:

   ```bash
   java -version
   ```
#### How to Set the Path of the Environment Variable?

#### For Windows:

1. **Find the JDK installation path** (usually `C:\Program Files\Java\jdk-17`).
2. **Set JAVA_HOME**:
   a. Right-click on **This PC** or **Computer** and select **Properties**.
   b. Click on **Advanced system settings** and then click **Environment Variables**.
   c. Under **System variables**, click **New** and add the following:
      - **Variable name**: `JAVA_HOME`
      - **Variable value**: `C:\Program Files\Java\jdk-17` (or the path where JDK 17 is installed).
3. **Update the PATH variable**:
   a. In the **Environment Variables** window, select the **Path** variable under **System variables**, and click **Edit**.
   b. Click **New** and add the following:
      - `C:\Program Files\Java\jdk-17\bin`
4. **Verify**:
   a. Open **Command Prompt** and run:
      ```bash
      java -version
      ```
      It should display the correct version.

---

#### For macOS/Linux:

1. Open a terminal.
2. **Set JAVA_HOME** by adding it to your shell profile:
   - For **Bash** (`.bash_profile` or `.bashrc`):
     ```bash
     export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home  # For macOS
     export JAVA_HOME=/usr/lib/jvm/java-17-openjdk  # For Linux
     ```
   - For **Zsh** (`.zshrc`):
     ```bash
     export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home  # For macOS
     export JAVA_HOME=/usr/lib/jvm/java-17-openjdk  # For Linux
     ```
3. **Add the bin directory to the PATH**:
   ```bash
   export PATH=$JAVA_HOME/bin:$PATH
 4. Reload the profile to apply the changes:
   ```bash
   source ~/.bash_profile  # For Bash
   source ~/.zshrc         # For Zsh
```
 5. **Verify**: Run the following command to confirm the JDK installation:
   ```bash
   java -version
```

#### Conclusion

- **JDK 17** is a major and stable version of Java, ideal for building modern Java applications with improvements in performance, security, and language features.
- It is an **LTS release**, making it a safe and reliable option for long-term projects.
- Installation involves downloading the JDK, installing it, and configuring environment variables to ensure that Java commands (`java`, `javac`) work from anywhere in the terminal or command prompt.

JDK 17 offers a good balance of new features, performance improvements, and long-term stability, making it a solid choice for developers.

---

### 2. Spring Initializr

#### **2. What is Spring Initializr?**

**Spring Initializr** is an online tool that simplifies the creation of new **Spring Boot** projects by generating a basic scaffold with minimal configuration. It provides developers with a quick way to bootstrap a Spring-based application, offering options like project metadata, dependencies, and build tool configurations.

The generated project includes the necessary configurations for the selected build system (either **Maven** or **Gradle**), and it can be opened directly in an Integrated Development Environment (IDE) like IntelliJ IDEA or Eclipse. This allows developers to start building their Spring Boot applications immediately, without having to worry about project setup and configurations.

---

#### **2.1. How to Access Spring Initializr**

You can use **Spring Initializr** in two main ways:

#### **2.1.1. Via the Web Interface**
   - Open your browser and visit [https://start.spring.io](https://start.spring.io).
   - This is the main interface where you can configure and generate a Spring Boot project.

#### **2.1.2. Via Integrated Development Environments (IDEs)**
   - Many popular IDEs, such as **IntelliJ IDEA**, **Eclipse**, and **Visual Studio Code**, provide built-in support for Spring Initializr, making it even easier to generate Spring Boot projects directly from your IDE.

---

#### **2.2. Creating a New Spring Boot Project**

#### **2.2.1. Steps to create a Spring Boot project:**

1. Open the Spring Initializr web page at [https://start.spring.io](https://start.spring.io).
2. Choose the following configuration options:
    - **2.2.2. Project**: Choose between **Maven Project** or **Gradle Project** as your build tool.
    - **2.2.3. Language**: Select **Java**, **Kotlin**, or **Groovy** based on your preference.
    - **2.2.4. Spring Boot Version**: The current stable version will be selected by default.
    - **2.2.5. Group**: A unique identifier for your project, typically the domain in reverse (e.g., `com.example`).
    - **2.2.6. Artifact**: The name of the project artifact, typically the application name (e.g., `demo`).
    - **2.2.7. Name**: Name of the application (this is also used in your `pom.xml` or `build.gradle` file).
    - **2.2.8. Description**: A brief description of your project.
    - **2.2.9. Package Name**: Default package name (you can leave it as the default or customize it).
    - **2.2.10. Packaging**: Choose either **Jar** or **War** (most projects use **Jar**).
    - **2.2.11. Java Version**: Choose the appropriate Java version (e.g., **Java 11** or **Java 17**).
3. Select the necessary **dependencies** from the available list.
4. Click **Generate** to download the generated zip file.
5. Extract the zip file and import it into your IDE.

---

#### **2.3. Spring Initializr Options**

#### **2.3.1. Project Metadata**

The following fields define the basic setup for your Spring Boot project:

- **2.3.1.1. Project**:
  - **Maven Project**: Uses Maven as the build tool.
  - **Gradle Project**: Uses Gradle as the build tool.
  
- **2.3.1.2. Language**:
  - **Java**: The most commonly used language with Spring Boot.
  - **Kotlin**: A modern, concise language that works well with Spring Boot, especially for new projects.
  - **Groovy**: Another language supported by Spring Boot, commonly used with Gradle.

- **2.3.1.3. Spring Boot Version**: The version of Spring Boot to use. It is always recommended to use the latest stable version unless you have a specific reason to use an older one.

- **2.3.1.4. Group**: The base package name for your application (e.g., `com.example`).
  
- **2.3.1.5. Artifact**: The name of the artifact being generated (e.g., `demo`).

- **2.3.1.6. Name**: The name of the project/application (e.g., `demo`).

- **2.3.1.7. Description**: A short description of your application.

- **2.3.1.8. Package Name**: This is the base package for your project.

- **2.3.1.9. Packaging**: The type of package to be created. You can choose between:
  - **Jar**: Typically used for Spring Boot applications.
  - **War**: Typically used for applications that need to be deployed to a web server (e.g., Tomcat).

- **2.3.1.10. Java Version**: Choose the appropriate version of Java that your project will use (e.g., **Java 8**, **Java 11**, **Java 17**).

---

#### **2.3.2. Dependencies**

Spring Initializr provides a wide range of dependencies to add to your project. Below are descriptions of some common dependencies you may choose:

#### **2.3.2.1. Spring Web**
- **Description**: This dependency is used for building web applications and RESTful web services. It includes Spring MVC and embedded servers such as Tomcat, Jetty, or Undertow. You’ll typically include this in applications that need web support (e.g., a REST API, a server-side web app, etc.).

#### **2.3.2.2. Spring Data JPA**
- **Description**: This dependency provides support for integrating with relational databases using Java Persistence API (JPA). It simplifies database operations and makes it easier to interact with relational databases using repository patterns. Typically used in applications where you need to perform CRUD operations on relational databases.

#### **2.3.2.3. MySQL Driver**
- **Description**: The MySQL Driver dependency provides the necessary drivers to connect your Spring Boot application to a MySQL database. If you're using MySQL for your application's data storage, you'll need this driver to facilitate database communication.

#### **2.3.2.4. Spring Boot DevTools**
- **Description**: Spring Boot DevTools enhances the development experience by providing additional features like automatic restarts, live reload, and debugging tools. It is specifically useful during the development phase as it speeds up the testing and debugging cycle by reloading your application upon changes.

#### **2.3.2.5. Lombok**
- **Description**: Lombok is a library that automatically generates commonly used code, such as getters, setters, `toString()`, `equals()`, and `hashCode()` methods, constructors, etc., by annotating your classes with special annotations. This helps reduce boilerplate code and improves the readability of your application, especially when working with POJOs (Plain Old Java Objects).

#### **2.3.2.6. Spring Boot**
- **Description**: This is the core dependency for Spring Boot applications. It includes essential features such as auto-configuration, embedded servers (like Tomcat, Jetty), and starters (pre-configured, ready-to-use components) that make it easier to set up and run Spring applications with minimal configuration. It is the foundation of your Spring Boot project.

---

#### **2.4. Packaging**

When generating a Spring Boot project, you can choose between two types of packaging:

- **2.4.1. Jar**:
  - JAR (Java Archive) is the most common packaging format for Spring Boot applications. It can be run on any platform with the appropriate JVM. It contains the compiled classes, libraries, resources, and metadata required to run the application.

- **2.4.2. War**:
  - WAR (Web Archive) packaging is used when you want to deploy your application to a servlet container (e.g., Tomcat). You may use WAR packaging when your application is designed to be deployed on traditional web servers.

---

#### **2.5. Java Version**

  - **2.5.1. Java 17** (LTS)

---

#### **2.6. Spring Initializr in IDEs**

Most popular IDEs support **Spring Initializr** for creating Spring Boot projects directly from the IDE. Here’s how you can use it in the most popular IDEs:

#### **2.6.1. IntelliJ IDEA:**
1. Open IntelliJ IDEA.
2. Click on **Create New Project**.
3. Choose **Spring Initializr** from the left sidebar.
4. Configure the project metadata and dependencies as described above.
5. Click **Next** and finish the setup.
6. IntelliJ IDEA will generate the project and import it into your workspace.

#### **2.6.2. Eclipse:**
1. Open Eclipse IDE.
2. Go to **File > New > Project**.
3. Select **Spring Starter Project** under the Spring category.
4. Fill in the project metadata and choose dependencies.
5. Click **Finish** to generate the project.

#### **2.6.3. Visual Studio Code:**
1. Install the **Spring Initializr** extension from the marketplace.
2. Open the Command Palette (Ctrl+Shift+P) and search for **Spring Initializr: Generate a Maven Project**.
3. Follow the prompts to select project metadata and dependencies.
4. The project will be generated and opened in VS Code.

---

#### **2.7. How Spring Initializr Works**

When you configure your project and click **Generate**, Spring Initializr:

1. Collects the metadata and dependencies you selected.
2. Generates the necessary project structure, including:
   - **`pom.xml`** or **`build.gradle`** (depending on the selected build tool).
   - **`application.properties`** or **`application.yml`** for application configuration.
   - The **main class** (e.g., `DemoApplication.java`) containing the `main()` method to run the Spring Boot application.
3. Zips the project into a downloadable archive.
4. You can extract the archive and open the project in your IDE.

Spring Initializr also supports generating projects with specific versions of Spring Boot, making it compatible with various Spring Boot versions.

---

#### **2.8. References**

- [Spring Initializr Documentation](https://docs.spring.io/initializr/docs/current/reference/html/)
- [Spring Boot Documentation](https://docs.spring.io/spring-boot/docs/current/reference/html/)
- [Spring Initializr GitHub Repository](https://github.com/spring-io/initializr)

---

### **Project Structure**

### **Front-End Project Structure:**

```
atsfrontend
│
├── atsfronted
│     ├── public
│     │     ├── files
│     │     │        ├── calling_Tracker_format.xlsx
│     │     │        ├── Lineup_Tracker_format.xlsx
│     ├── src
│     │     ├── AddCandidate
│     │     │        ├── CallingTrackerForm.jsx
│     │     │        ├── employeeMasterSheet.jsx
│     │     │        ├── UpdateSelfCalling.jsx
│     │     ├── App.css
│     │     ├── App.jsx
│     │     ├── index.css
│     │     ├── main.jsx
│     ├── .eslintrc.cjs
│     ├── .gitignore
│     ├── index.html
│     ├── package-lock.json
│     ├── postcss.config.js
│     ├── README.md
│     ├── tailwind.config.js
│     ├── vite.config.js
│     ├── vite.config.js.timestamp-1724634013512-4fb99d3a1e7c6.mjs
│     ├── vite.config.js.timestamp-1724634013512-6473bf87f809d.mjs
│
└── README.md
```

---

### Front-End Dependencies:

### Dependencies

<table>
  <thead>
    <tr>
      <th>Package Name</th>
      <th>Version</th>
    </tr>
  </thead>
  <tbody>
   <tr>
     <tr id="ant-designicons">
      <td><a href="https://www.npmjs.com/package/@ant-design/icons" target="_blank">@ant-design/icons</a></td>
      <td>^5.5.2</td> 
    </tr>
   <tr id="emotionreact">
     <td><a href="https://www.npmjs.com/package/@emotion/react" target="_blank">@emotion/react</a></td>
      <td>^11.13.3</td>
    </tr>
    <tr id="emotionstyled">
       <td><a href="https://www.npmjs.com/package/@emotion/styled" target="_blank">@emotion/styled</a></td>
      <td>^11.13.3</td>
    </tr>
     <tr id="fortawesome">
       <td><a href="https://www.npmjs.com/package/@fortawesome/fontawesome-svg-core" target="_blank">@fortawesome/fontawesome-svg-core</a></td>
      <td>^11.13.0</td>   
    </tr>
    <tr><td><a href="https://www.npmjs.com/package/@fortawesome/free-regular-svg-icons" target="_blank">@fortawesome/free-regular-svg-icons</a></td><td>^6.5.2</td>
   </tr>
    <tr></tr><td><a href="https://www.npmjs.com/package/@fortawesome/free-solid-svg-icons" target="_blank">@fortawesome/free-solid-svg-icons</a></td>><td>^6.5.2</td>
     </tr>
    <tr><td><a href="https://www.npmjs.com/package/@fortawesome/react-fontawesome" target="_blank">@fortawesome/react-fontawesome</a></td><td>^0.2.2</td>
    </tr>
   <tr id="muimaterial">
     <td><a href="https://www.npmjs.com/package/@mui/material" target="_blank">@mui/material</a></td>
      <td>^6.1.5</td>  
    </tr>
    <tr><td><a href="https://www.npmjs.com/package/@mui/x-date-pickers" target="_blank">@mui/x-date-pickers</a></td><td>^7.21.0</td>  
    </tr>
    <tr><td><a href="https://www.npmjs.com/package/@popperjs/core" target="_blank">@popperjs/core</a></td><td>^2.11.8</td>
    </tr>
    <tr id="reactpdfviewer">
      <td><a href="https://www.npmjs.com/package/@popperjs/core" target="_blank">@react-pdf-viewer/core</a></td>
      <td>^3.12.0</td>   
    </tr>
    <tr id="reactpdfviewerdefaultlayout">
      <td><a href="https://www.npmjs.com/package/@react-pdf-viewer/default-layout" target="_blank">@react-pdf-viewer/default-layout</a></td>
      <td>^3.12.0</td> 
    </tr>
    <tr>  <td><a href="https://www.npmjs.com/package/@react-pdf/renderer" target="_blank">@react-pdf/renderer</a></td><td>^3.4.5</td>
    </tr>
    <tr id="reduxjstoolkit">
      <td><a href="https://www.npmjs.com/package/@reduxjs/toolkit" target="_blank">@reduxjs/toolkit</a></td>
      <td>^2.5.0</td>  
    </tr>
    <tr><td><a href="https://www.npmjs.com/package/@stomp/stompjs" target="_blank">@stomp/stompjs</a></td><td>^7.0.0</td>
      </tr>
    <tr><td><a href="https://www.npmjs.com/package/antd" target="_blank">Antd</a></td><td>^5.21.5</td>
    </tr>
    <tr><td><a href="https://www.npmjs.com/package/aos" target="_blank">Aos</a></td><td>^2.3.4</td>
    </tr>
    <tr id="axios">
      <td><a href="https://www.npmjs.com/package/axios" target="_blank">Axios</a></td>
      <td>^1.6.8</td> 
    </tr>
    <tr><td><a href="https://getbootstrap.com/" target="_blank">Bootstrap Documentation</a></td><td>^5.3.3</td></tr>
    <tr><td><a href="https://github.com/catdad/canvas-confetti" target="_blank">canvas-confetti on GitHub</a></td><td>^1.9.3</td></tr>
    <tr><td><a href="https://www.chartjs.org/" target="_blank">Chart.js Documentation</a></td><td>^4.4.7</td></tr>
    <tr><td><a href="https://gka.github.io/chroma.js/" target="_blank">Chroma.js Documentation</a></td><td>^3.1.1</td></tr>
    <tr><td><a href="https://github.com/indigojs/colormap" target="_blank">Colormap on GitHub</a></td><td>^2.3.2</td></tr>
    <tr><td><a href="https://cryptojs.googlecode.com/svn/tags/crypto-js-3.1.9-1/build/crypto-js.js" target="_blank">crypto-js Documentation</a></td><td>^4.2.0</td></tr>
    <tr><td><a href="https://date-fns.org/" target="_blank">date-fns Documentation</a></td><td>^2.30.0</td></tr>
    <tr><td><a href="https://day.js.org/" target="_blank">Day.js Documentation</a></td><td>^1.11.13</td></tr>
    <tr><td><a href="https://formik.org/" target="_blank">Formik Documentation</a> </td><td>^2.4.6</td></tr>
    <tr><td><a href="https://github.com/FortAwesome/Font-Awesome" target="_blank">Fortawesome on GitHub</a></td><td>^0.0.1-security</td></tr>
    <tr><td><a href="https://html2canvas.hertzen.com/" target="_blank">html2canvas Documentation</a></td><td>^1.4.1</td></tr>
    <tr><td><a href="https://github.com/eKoopmans/html2pdf" target="_blank">html2pdf.js on GitHub</a></td><td>^0.10.2</td></tr>
    <tr><td><a href="https://github.com/ianstormtaylor/io" target="_blank">Io on GitHub</a></td><td>1.5.0</td></tr>
    <tr><td><a href="https://github.com/parallax/jsPDF" target="_blank">jsPDF Documentation</a></td><td>^2.5.1</td></tr>
    <tr><td><a href="https://github.com/eKoopmans/html2pdf" target="_blank">jspdf-autotable on GitHub</a></td><td>^3.8.2</td></tr>
    <tr><td><a href="https://github.com/Hopding/pdf-lib" target="_blank">pdf-lib Documentation</a></td><td>^1.17.1</td></tr>
    <tr><td><a href="https://pdfmake.github.io/pdfmake/" target="_blank">Pdfmake Documentation</a></td><td>^0.2.10</td></tr>
     <tr id="react">
      <td> <a href="https://reactjs.org/" target="_blank">React</a></td>
      <td>^18.2.0</td>
    </tr>
    <tr><td><a href="https://github.com/jquense/react-big-calendar" target="_blank">react-big-calendar on GitHub</a></td><td>^1.12.1</td></tr>
    <tr><td><a href="https://react-bootstrap.github.io/" target="_blank">react-bootstrap Documentation</a></td><td>^2.10.2</td></tr>
    <tr><td><a href="https://github.com/wojtekmaj/react-calendar" target="_blank">react-calendar on GitHub</a> r</td><td>^5.0.0</td></tr>
    <tr><td><a href="https://github.com/reactchartjs/react-chartjs-2" target="_blank">react-chartjs-2 on GitHub</a></td><td>^5.2.0</td></tr>
    <tr><td> <a href="https://github.com/reactjs/react-color" target="_blank">react-color on GitHub</a></td><td>^2.19.3</td></tr>
    <tr><td><a href="https://github.com/alampros/react-confetti" target="_blank">react-confetti on GitHub</a></td><td>^6.1.0</td></tr>
    <tr><td><a href="https://reactdatepicker.com/" target="_blank">react-datepicker Documentation</a></td><td>^6.9.0</td></tr>
    <tr><td><a href="https://reactjs.org/docs/react-dom.html" target="_blank">react-dom Documentation</a></td><td>^18.2.0</td></tr>
    <tr><td><a href="https://github.com/Mosha/react-flatpickr" target="_blank">react-flatpickr on GitHub</a></td><td>^3.10.13</td></tr>
    <tr><td> <a href="https://github.com/FortAwesome/react-fontawesome" target="_blank">react-fontawesome on GitHub</a></td><td>^1.7.1</td></tr>
    <tr><td><a href="https://react-hook-form.com/" target="_blank">react-hook-form Documentation</a></td><td>^7.52.1</td></tr>
    <tr><td><a href="https://github.com/ReactIcons/react-icons" target="_blank">react-icon on GitHub</a></td><td>^1.0.0</td></tr>
    <tr><td><a href="https://react-icons.github.io/react-icons/" target="_blank">react-icons Documentation</a></td><td>^5.2.1</td></tr>
    <tr><td> <a href="https://reactcommunity.org/react-modal/" target="_blank">react-modal Documentation</a></td><td>^3.16.1</td></tr>
    <tr><td> <a href="https://react-pdf.org/" target="_blank">react-pdf Documentation</a</td><td>^9.1.0</td></tr>
    <tr><td> <a href="https://github.com/islamsultan/react-phone-number-input" target="_blank">react-phone-number-input on GitHub</a></td><td>^3.4.3</td></tr>
    <tr><td><a href="https://github.com/jorenvanhee/react-qr-code" target="_blank">react-qr-code on GitHub</a></td><td>^2.0.15</td></tr>
    <tr><td><a href="https://react-redux.js.org/" target="_blank">react-redux Documentation</a></td><td>^9.2.0</td></tr>
     <tr id="reactrouterdom">
      <td><a href="https://reactrouter.com/" target="_blank">react-router-dom Documentation</a></td>
      <td>^6.23.1</td>
    </tr>
    <tr><td> <a href="https://github.com/kolodny/react-spinner" target="_blank">react-spinner on GitHub</a></td><td>^0.2.7</td></tr>
    <tr><td> <a href="https://react-spinners.github.io/react-spinners/" target="_blank">react-spinners Documentation</a></td><td>^0.13.8</td></tr>
    <tr><td><a href="https://github.com/jmesnil/stomp-websocket" target="_blank">react-stomp on GitHub</a></td><td>^5.1.0</td></tr>
    <tr><td> <a href="https://github.com/wojtekmaj/react-time-picker" target="_blank">react-time-picker on GitHub</a></td><td>^7.0.0</td></tr>
    <tr><td><a href="https://github.com/gregnb/react-to-print" target="_blank">react-to-print on GitHub</a> </td><td>^2.15.1</td></tr>
   <tr id="reacttoastify">
      <td><a href="https://github.com/fkhadra/react-toastify" target="_blank">react-toastify on GitHub</a></td>
      <td>^10.0.5</td>
    </tr>
    <tr><td><a href="https://react-tooltip.com/" target="_blank">react-tooltip Documentation</a></td><td>^5.27.1</td></tr>
    <tr><td><a href="https://github.com/ogozu/react-web-share" target="_blank">react-web-share on GitHub</a></td><td>^2.0.2</td></tr>
    <tr><td><a href="https://recharts.org/en-US/" target="_blank">Recharts Documentation</a></td><td>^2.12.6</td></tr>
   <tr id="socketioclient">
      <td> <a href="https://socket.io/docs/v4/client-api/" target="_blank">socket.io-client Documentation</a></td>
      <td>^4.8.1</td>
    </tr>
    <tr><td> <a href="https://github.com/sockjs/sockjs-client" target="_blank">Sockjs on GitHub</a></td><td>^0.3.24</td></tr>
    <tr><td><a href="https://github.com/sockjs/sockjs-client" target="_blank">sockjs-client on GitHub</a> </td><td>^1.6.1</td></tr>
    <tr><td><a href="https://github.com/stomp-js/stompjs" target="_blank">Stompjs on GitHub</a></td><td>^2.3.3</td></tr>
    <tr><td><a href="https://github.com/jeremydmiller/svg-to-img" target="_blank">svg-to-img on GitHub</a></td><td>^2.0.9</td></tr>
    <tr><td><a href="https://github.com/andrejuan/theme-change" target="_blank">theme-change on GitHub</a></td><td>^2.5.0</td></tr>
    <tr><td> <a href="https://github.com/SheetJS/js-xlsx" target="_blank">Xlsx Documentation</a></td><td>^0.18.5</td></tr>
    <tr><td> <a href="https://github.com/jquense/yup" target="_blank">Yup Documentation</a></td><td>^1.4.0</td></tr>
  </tbody>
</table>

### DevDependencies

<table>
  <thead>
    <tr>
      <th>Package Name</th>
      <th>Version</th>
    </tr>
  </thead>
  <tbody>
    <tr id="eslint">
      <td><a href="https://eslint.org/" target="_blank">eslint Documentation</a></td>
      <td>^8.57.0</td>
    </tr>
    <tr id="vite">
      <td><a href="https://vitejs.dev/" target="_blank">Vite Documentation</a></td>
      <td>^5.3.3</td>
    </tr>
    <tr id="autoprefixer">
      <td><a href="https://github.com/postcss/autoprefixer" target="_blank">Autoprefixer Documentation</a></td>
      <td>^10.4.19</td>
    </tr>
    <tr id="typescript">
      <td><a href="https://www.typescriptlang.org/" target="_blank">TypeScript Documentation</a> </td>
      <td>^4.7.4</td>
    </tr>
    <tr>
      <td><a href="https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/react" target="_blank">@types/react on GitHub</a></td>
      <td>^18.2.66</td>
    </tr>
    <tr>
      <td><a href="https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/react-dom" target="_blank">@types/react-dom on GitHub</a></td>
      <td>^18.2.22</td>
    </tr>
    <tr>
      <td><a href="https://github.com/vitejs/vite/tree/main/packages/plugin-react" target="_blank">@vitejs/plugin-react on GitHub</a></td>
      <td>^4.2.1</td>
    </tr>
    <tr>
      <td> <a href="https://github.com/yannickcr/eslint-plugin-react" target="_blank">eslint-plugin-react on GitHub</a></td>
      <td>^8.57.0</td>
    </tr>
    <tr>
      <td><a href="https://github.com/facebook/react/tree/main/packages/eslint-plugin-react-hooks" target="_blank">eslint-plugin-react-hooks on GitHub</a></td>
      <td>^4.6.0</td>
    </tr>
    <tr>
      <td><a href="https://github.com/facebook/react/tree/main/packages/eslint-plugin-react-refresh" target="_blank">eslint-plugin-react-refresh on GitHub</a> </td>
      <td>^0.4.6</td>
    </tr>
    <tr>
      <td><a href="https://github.com/postcss/postcss" target="_blank">Postcss Documentation</a></td>
      <td>^8.4.39</td>
    </tr>
    <tr id="tailwindcss">
      <td><a href="https://tailwindcss.com/" target="_blank">Tailwind CSS Documentation</a></td>
      <td>^2.1.2</td>
    </tr>
  </tbody>
</table>


```bash
npm install
```

#### Dependencies Overview

#### Core Dependencies

-  **[@ant-design/icons](#ant-designicons)**: Provides Ant Design icons for UI components.
- **[@emotion/react](#emotionreact) & [@emotion/styled](#emotionstyled)**: Used for CSS-in-JS styling, allowing you to style React components directly.
- **[@fortawesome](#fortawesome)**: Font Awesome icon library for React, offering scalable vector icons.
-  **[@mui/material](#muimaterial)**: Material UI framework components, enabling easy and consistent design patterns for React apps.
- **[@react-pdf-viewer/core](#reactpdfviewer) & [default-layout](#reactpdfviewerdefaultlayout)**: Libraries for rendering and displaying PDF documents in React.
- **[@reduxjs/toolkit](#reduxjstoolkit)**: Simplifies Redux development, providing utilities and a standard approach for managing state.
- **[axios](#axios)**: Promise-based HTTP client for making API requests to communicate with external services.
- **[react](#react)**: Main React library for building user interfaces with reusable components.
- **[react-router-dom](#reactrouterdom)**: For handling routing in the app, allowing users to navigate between different views.
- **[react-toastify](#reacttoastify)**: Toast notifications for easy feedback to users.
- **[socket.io-client](#socketioclient)**: Used for real-time WebSocket communication between the client and server.
- **[tailwindcss](#tailwindcss)**: Utility-first CSS framework for building custom designs with minimal effort.

---

#### DevDependencies

- **[eslint](#eslint)**: A linter for identifying and fixing JavaScript issues in the code.
- **[vite](#vite)**: A fast build tool that serves the app with hot-reloading, improving the development experience.
- **[autoprefixer](#autoprefixer)**: Automatically adds vendor prefixes to CSS rules for compatibility across different browsers.
- **[typescript](#typescript)**: Adds TypeScript support, providing static type checking and improved development experience.

---

### About package dot json:

A `package.json` file is a fundamental component in Node.js projects. It serves as a metadata file for the project and contains important information about the project, including dependencies, scripts, and other configurations.

#### Key Uses of `package.json`

1. **Project Metadata:**
   - **Name:** The name of your project or application.
   - **Version:** The version number of your project.
   - **Description:** A short description of your project.
   - **Author:** The person or organization responsible for the project.
   - **License:** Specifies the license under which the project is released.

2. **Dependencies:**
   - **Dependencies:** External libraries or packages required to run the application.
   - **DevDependencies:** Libraries needed only for development (e.g., testing frameworks, bundlers).
   - **PeerDependencies:** Specifies versions of other packages your package is compatible with.

3. **Scripts:**
   Define custom scripts that can be run using `npm run <script-name>`. Examples:
   ```json
   "scripts": {
     "start": "node server.js",
     "test": "jest"
   }
   ```

4. **Package Management:**
   - Running `npm install` uses the `package.json` file to install the listed dependencies.
   - Ensures consistency of dependencies across environments.

5. **Version Control:**
   - Tracks versions of dependencies, ensuring consistency across environments.

#### **Key Commands Involving `package.json`:**
- `npm init`: Initializes a new Node.js project and creates a `package.json` file.
- `npm install`: Installs dependencies listed in the `package.json` file.
- `npm run <script>`: Executes the script defined in `package.json`.

---

### Front-End Portnumber

#### 1. Purpose of the Port Configuration
The frontend of this project is built using React. By default, React runs on port 3000 during development. This documentation provides guidelines for developers to ensure that the React development server consistently uses port 3000, even if other processes might attempt to occupy this port.

#### 2. Project Port Requirements
This project is designed to run only on port 3000 during development. React's development server will be configured to always use port 3000, and developers should ensure no other services are using this port. If the port is already occupied, React will throw an error, and you will need to free up the port.

`http://localhost:3000`

- **Port Conflict:** If port 3000 is already in use by another application, you will need to free up the port or modify the configuration to use a different one.
- **Firewall Issues:** Ensure that your firewall or network settings are configured to allow traffic on port 3000 for local development.

This command launches the development server, which watches for changes to your project files and automatically reloads the browser when changes are detected.

---

### CSS-Tailwind and Bootstrap

#### 7.1 Tailwind CSS
<a href="https://tailwindcss.com/" target="_blank" >Tailwind</a> CSS offers a utility-first approach to styling, which can greatly speed up the development process. It allows you to apply styles directly in your JSX, reducing the need to switch between CSS and JavaScript files.

#### The Tailwind CSS configuration file (`tailwind.config.js`)

```js
/** @type {import('tailwindcss').Config} */
export default {
  content: ["./index.html", "./src/*/.{js,ts,jsx,tsx}"],
  theme: {
    extend: {
      colors: {
        primary: 'var(--primary-color)', // Use CSS variable for the primary color
      },
    },
  },
  plugins: [],
};
```

#### Key Features of Tailwind CSS:

- **Utility-First:** Use pre-made classes in HTML/JSX for styling (e.g., padding, colors) instead of custom CSS.
- **Customizability:** Easily adjust Tailwind settings to fit your project's unique design.
- **Responsive Design:** Simplifies creating designs that work on different screen sizes using classes like `sm:`, `md:`, `lg:`.
- **No Pre-made UI:** Gives you full control to design your UI without predefined components.
  
#### Example

```js
import React from 'react';

function Button() {
  return (
    <button className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-700">
      Click Me
    </button>
  );
}

export default Button;
```

#### In this example:

- `px-4` adds padding to the left and right of the button.
- `py-2` adds padding to the top and bottom.
- `bg-blue-500` sets the background color.
- `text-white` makes the text color white.
- `rounded-lg` applies rounded corners.
- `hover:bg-blue-700` changes the background color on hover.
  
#### 7.2 Bootstrap

[Bootstrap](https://getbootstrap.com/) is a popular open-source front-end framework that provides a collection of CSS and JavaScript tools for building responsive, mobile-first websites. It was originally developed by Twitter and is now one of the most widely used frameworks in web development.

The following two lines of code are used to import Bootstrap styles and JavaScript functionality into a React project:

```js
import 'bootstrap/dist/css/bootstrap.css';
import 'bootstrap/dist/js/bootstrap.js';
```
#### Example

```js
import React from 'react';
import 'bootstrap/dist/css/bootstrap.css';

function App() {
  return (
    <div className="container">
      <h1 className="text-center text-primary">Hello, Bootstrap!</h1>
      <p className="text-muted">This is a simple example of Bootstrap styling in React.</p>
      <button className="btn btn-success">Click Me</button>
    </div>
  );
}

export default App;
```
#### Component Use:

- `container`: Centers the content with padding.
- `text-center`: Centers the text.
- `text-primary`: Makes the text color blue (Bootstrap's primary color).
- `text-muted`: Makes the text color gray.
- `btn btn-success`: Styles the button with a green background.

---

### Details about App dot jsx 

In a React application, `App.jsx` is a central component file that typically serves as the entry point for rendering the main application. It acts as the root component of your React app and often contains the core structure and layout of the application.

#### Key Points about App.jsx in React:

#### 1. Default Component:

In React apps created with Create React App, `App.jsx` is automatically included as the main component. It is usually rendered by `index.js` and acts as the parent component for other components.

#### 2. Component Structure:

`App.jsx` is a functional or class-based React component. It defines the primary structure of your app and integrates other components.

#### 3. Purpose:

`App.jsx` is typically used to:

- Define the layout and structure of the app.
- Integrate and manage state (often using tools like React's `useState` or `useReducer`).
- Serve as the central hub to load and nest other child components.
- Implement routing using tools like `react-router`.

---

### Front-End: Component Information

#### 1. Component Purpose and Overview:
The purpose of this component is to manage the Calling Tracker Form functionality. It is responsible for fetching data, submitting new data, and updating the calling tracker. The component also integrates with APIs, handles socket transmissions, and shows success/error notifications to the user.

#### Example Code:

```jsx
// App.jsx
import CallingTrackerForm from "./CallingTrackerForm";
export default function App() {
  return (
    <div>
      <CallingTrackerForm/> 
    </div>
  );
}
```


#### CallingTrackerForm.jsx

```javascript
try {
     
      
    axios.post(
        ${API_BASE_URL}/calling-tracker/${employeeId}/${userType},
        dataToUpdate,
        {
          headers: {
            "Content-Type": "application/json",
          },
        }

```
<img src="https://github.com/user-attachments/assets/17b629ae-9bfe-43f4-a034-79875c882f4a" width="900">

#### Dependencies:

1. <a href="https://www.npmjs.com/package/axios" target="_blank">Axios</a>: A popular promise-based HTTP client for the browser and Node.js.

#### Request Body:

2. **dataToUpdate** (Object): This object contains the data to be sent in the request body. The data is typically in JSON format and can include various fields related to the calling tracker (e.g., call count, duration, etc.).

---

### API Fetching in React

API fetching in React means getting data from an external source, like a server or database, using an API (a way to communicate between systems). When you make a request to an API, you ask for information, and the API sends it back to your React app.

#### Why use API fetching in React?

1. **Get Dynamic Data**: Your app can show real-time data, like the latest news, weather, or user information, by fetching it from an API.
   
2. **Organize Code Better**: The app gets data from a backend (like a server), while React focuses on showing it to users. This keeps your code clean.

3. **Save Data**: You can send or receive data to/from a server. For example, if a user fills out a form, you can send that data to be saved.

4. **Load Data in the Background**: React can fetch data without freezing the page, so users can still interact with the app while the data loads.
   
#### Example of API Fetching

```javascript
const response = await fetch(
  `${API_BASE_URL}/calling-lineup/${employeeId}/${userType}?searchTerm=${searchTerm}&page=${page}&size=${size}`
);
if (!response.ok) {
  throw new Error(`HTTP error! Status: ${response.status}`);
}
```
![Api](https://github.com/user-attachments/assets/3113931a-1d56-4148-a084-57b9ed51466b)

#### Method

- **fetch**: A native JavaScript function to make HTTP requests. It returns a `Promise` that resolves to the response of the request.

#### Request Format

- The request is made to the calling lineup API endpoint with dynamic segments (`employeeId` and `userType`) as part of the URL.
- Query parameters (`searchTerm`, `page`, `size`) are appended to the URL to provide filtering and pagination capabilities.

---

### **Back-End Project Structure:**

```
ATS_Backend
│
├── ATS_Project_01
│     ├── src
│     │     ├── main
│     │     │        ├── java
│     │     │        │       └── 🔽 ATS_01.ATS_Project_01
│     │     │        │                    📦 config
│     │     │        │                       📄 Configuration
│     │     │        │                    📦 controller
│     │     │        │                       📄 ApplicantController
│     │     │        │                    📦 dto
│     │     │        │                       📄 ApplicantDto
│     │     │        │                    📦 exception
│     │     │        │                       📄 ApplicantExceptionHandler
│     │     │        │                    📦 model
│     │     │        │                       📄 Applicant
│     │     │        │                    📦 repository
│     │     │        │                       📄 ApplicantRepository
│     │     │        │                    📦 security
│     │     │        │                       📄 Security
│     │     │        │                    📦 SocketEmitEvents
│     │     │        │                       📄 Socket
│     │     │        │                    📦 Util
│     │     │        │                       📄 ApplicantUtil
│     │     │        │                    📦 mailSender
│     │     │        │                       📄 ApplicantMailSender
│     │     │        │                    📦 helper
│     │     │        │                       📄 ApplicantHelper
│     │     │        │                    📦 service
│     │     │        │                       📄 ApplicantService
│     │     │        │                    🚀 AtsProject01Application
│     │     │        └── 🔽 📁 resources
│     │     │                     🔽 📁 META-INF
│     │     │                                 📄 MANIFEST.FM
│     │     │                           ⚙️ application.properties
│     │     └── static
│     │     └── 🔽 📁 test
│     │     └──     🔽 📁 java
│     │     └──        🔽 📁 ATS_01.ATS_Project_01
│     │     └── AtsProject01ApplicationTests.java
│     ├──🔽 target
│     │           📄 mvnw
│     │           📄 mvnw.cmd
│     │           📄 .gitignore
│     │           📄 pom.xml
│     │     ├── 🔽 📁 Out
│     │             ├── 🔽 📁 artifacts
│     │     │                    ├── 📁 ATS_Project_01_jar
│     │     │                       └──           📄 ATS_Project_01.jar
│     │     └── other_compiled_files
│     │    
│     ├── External Libraries
│     │                   📄 <17> C:\Programs Files\Java\jdk-17
│     │    
│     │    
│
├── 🔽 📁 .idea
│                    📜 misc.xml
│                    📄.gitignore
│                    📄 ATS_Backend.iml
│                    📜 compiler.xml
│                    📜 encodings.xml
│                    📜 jarRepositories.xml
│                    📜 material_theme_project_new.xml
│                    📜 misc.xml
│                    📜 modules.xml
│                    📜 workspace.xml
│                    📜 uiDesigner.xml
│
└── README.md
```

---

### **Back-End Dependencies used in Project:**

<p><b> 1) spring-boot-starter-data-jpa</b></p>

```
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-data-jpa</artifactId>
</dependency>
```
<p> <dependency> with the group ID org.springframework.boot and artifact ID spring-boot-starter-data-jpa is a Spring Boot starter that  simplifies the integration of Spring Data JPA into your application. It provides all the necessary libraries and tools required for working  with relational databases using JPA (Java Persistence API) and Hibernate.</p>
<h4>Key Features:</h4>
	
- **JPA Integration**: Enables the use of JPA for object-relational mapping (ORM) to map Java objects to database tables.

- **Hibernate Support**: Includes Hibernate as the default JPA implementation, providing advanced ORM capabilities.

- **Repository Support**: Provides repository interfaces (like `JpaRepository`) to perform CRUD operations and custom queries without writing boilerplate code.

- **Transaction Management**: Simplifies declarative transaction management using `@Transactional`.

- **Database Schema Generation**: Automatically generates or updates database schemas based on your JPA entity mappings.

<p><b>2) spring-boot-starter-web</b></p>

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```
<p>This starter is used to create web applications, including RESTful web services, in Spring Boot. It comes with pre-configured settings for Spring MVC, embedded servers like Tomcat (default), Jackson for JSON binding, and more.</p>
<h4>Key Features:</h4>

- **Spring MVC**: Supports building web applications using the Model-View-Controller architecture.

- **Embedded Tomcat**: Includes the Tomcat server by default (you can also choose other embedded servers like Jetty or Undertow).

- **Jackson**: Automatically includes the Jackson library to handle JSON data binding (for REST APIs).

- **Spring WebSocket**: Provides support for WebSocket communication.

- **Common Usage**: This dependency is typically used in web applications or microservices that need to expose REST APIs or serve web pages.

<p><b>3) spring-boot-devtools</b> </p>

```
<dependency>
	<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-devtools</artifactId>
		<scope>runtime</scope>
	<optional>true</optional>
</dependency>
```
<p>This dependency is used to improve the development workflow by providing features such as automatic restarts, live reload, and remote debugging for Spring Boot applications. It’s meant for use during the development phase only.</p>
<h4>Key Features:</h4>

- **Automatic Restart**: When you make changes to your application, it automatically restarts the application without needing a manual restart, which speeds up the development process.

- **Live Reload**: Integrates with tools like LiveReload to automatically refresh the browser when the code is modified, improving the user experience while testing.

- **Configuration for Development Only**: It is typically included with the runtime scope to ensure it is only included in the development environment, not in production.

- **Common Usage**: This dependency is added during the development phase to make the application development faster and easier. It is not meant to be included in production.

<p><b>4) mysql-connector-j</b> </p>

```
<dependency>
    <groupId>com.mysql</groupId>
    <artifactId>mysql-connector-j</artifactId>
    <scope>runtime</scope>
</dependency>
```
<p> This dependency provides the JDBC driver necessary for connecting Java applications to a MySQL database. It acts as a bridge to allow your Spring Boot (or other Java) applications to send queries to and retrieve data from MySQL databases</p>
<h4>Key Features:</h4>

- **JDBC Driver**: Implements the Java Database Connectivity (JDBC) API, allowing Java applications to interact with relational databases.
  
- **Database Connection**: Facilitates establishing a connection to the MySQL database and performing CRUD (Create, Read, Update, Delete) operations.
  
- **Runtime Scope**: Since it’s used at runtime to interact with the database, it is declared with a `<scope>runtime</scope>`. This ensures the dependency is only included during the execution of the application and not during the compilation.
  
- **Common Usage**: This dependency is used when a Spring Boot application needs to interact with a MySQL database. It is included in the `pom.xml` file to configure the connection between the Java application and MySQL.


<p><b>5) lombok </b></p>

```
<dependency>
    <groupId>org.projectlombok</groupId>
    <artifactId>lombok</artifactId>
    <optional>true</optional>
</dependency>
```
<p>Lombok is a Java library that helps reduce boilerplate code by generating common methods like getters, setters, constructors, and more at compile-time using annotations. This simplifies your code and makes it more readable and maintainable.</p>
<h4>Key Features:</h4>

- **Automatic Getter and Setter Methods**: Lombok automatically generates getters and setters for fields with annotations like `@Getter` and `@Setter`.

- **@ToString, @EqualsAndHashCode**: Automatically generates `toString()`, `equals()`, and `hashCode()` methods.

- **@AllArgsConstructor, @NoArgsConstructor, @RequiredArgsConstructor**: Automatically generates constructors based on the parameters in the class.

- **@Builder**: Allows you to implement the builder pattern, enabling an easy and readable way to construct objects.

- **Compile-Time Code Generation**: Lombok generates code during compilation, so it doesn’t affect runtime performance.

<p><b>6) pdfbox </b></p>

```
<dependency>
    <groupId>org.apache.pdfbox</groupId>
    <artifactId>pdfbox</artifactId>
    <version>2.0.27</version>
</dependency>
```
<p>Apache PDFBox is a Java library that provides capabilities to create, manipulate, and extract data from PDF documents. It is commonly used for tasks like reading PDF files, writing data into PDFs, extracting text, and handling other PDF-related operations.</p>

<h4>Key Features:</h4>

- **Create PDF**: You can generate PDF documents programmatically, adding text, images, and other content.

- **Read PDF**: PDFBox allows extracting text and other elements from existing PDF files, making it useful for parsing PDF content.

- **Manipulate PDFs**: You can manipulate existing PDF documents, such as merging, splitting, and rotating pages.

- **Fill Forms**: You can fill in PDF forms dynamically and even generate reports in PDF format.

- **Signature Support**: Supports adding digital signatures to PDF files.

- **Common Usage**: This dependency is often used in Java applications that need to generate or manipulate PDF files. It's useful in scenarios where reports, invoices, or documents need to be created or processed in PDF format.


<p><b>7) spring-boot-starter-test</b> </p>

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-test</artifactId>
    <scope>test</scope>
</dependency>
```
<p>This dependency provides the necessary tools to perform unit tests, integration tests, and other kinds of tests within a Spring Boot application. It includes a range of popular testing libraries and utilities such as JUnit, Mockito, and Spring TestContext Framework.</p>

<h4>Key Features:</h4>

- **JUnit**: The most widely used testing framework in Java for writing and running tests. Spring Boot Starter Test includes JUnit 5 by default.

- **Mockito**: A mocking framework used to create mock objects for unit testing. Mockito helps simulate behaviors of dependencies and ensures that tests remain isolated.

- **Spring TestContext Framework**: Provides support for integration testing with Spring’s TestContext framework. This allows for setting up application contexts and running tests in a Spring-managed environment.

- **Spring Boot Test**: Provides annotations like `@SpringBootTest` to set up an application context for testing, ensuring tests run in a full Spring Boot environment.

- **Hamcrest**: A library for writing declarative assertions in tests (e.g., `assertThat` statements).

- **JSON and XML testing**: Provides support for validating JSON and XML responses in integration tests.


<p><b>8) socket.io-client</b></p>

```
<dependency>
    <groupId>com.corundumstudio.socketio</groupId>
    <artifactId>netty-socketio</artifactId>
    <version>2.0.12</version>
</dependency>

```
<p>The netty-socketio library is a Java implementation of Socket.IO that uses Netty for handling network connections. It allows Java-based applications to support real-time, event-driven communication between clients and servers via WebSockets or other fallback protocols.</p>

<h4>Key Features:</h4>

- **Real-time Communication**: Enables low-latency, bidirectional communication between a client and a server using WebSockets or long polling.

- **Socket.IO Protocol**: Implements the Socket.IO protocol, allowing Java applications to communicate with Socket.IO clients (e.g., JavaScript clients).

- **Built on Netty**: Uses Netty, a non-blocking I/O framework, to handle incoming requests, enabling scalability and efficiency in handling many concurrent connections.

- **Event-driven Model**: Allows the server to emit and listen for events, enabling real-time functionality like chat, notifications, and live updates.

- **Compatibility with Socket.IO Clients**: Supports communication with Socket.IO clients written in JavaScript, making it ideal for full-stack real-time applications.

- **Live data applications**: Suitable for applications that require real-time data updates, such as sports scores, financial data, and stock prices.


<p><b>9) spring-boot-starter-validation </b></p>

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-validation</artifactId>
</dependency>
```
<p>The <dependency> with the group ID org.springframework.boot and artifact ID spring-boot-starter-validation provides support for validating user input in Spring Boot applications. It integrates the Java Bean Validation API (JSR 380) with Spring Boot and uses Hibernate Validator as the default implementation.</p>

<h4>Key Features:</h4>

- **Input Validation**: Allows you to validate user input in request payloads (e.g., @RequestBody or @ModelAttribute).

- **Built-in Annotations**: Provides standard validation annotations like @NotNull, @Size, @Email, @Pattern, etc.

- **Custom Validation**: Supports custom validation logic using custom constraint annotations.

- **Error Handling**: Automatically generates meaningful error messages for invalid inputs, which can be customized.

- **Validation Groups**: Supports grouping of validation rules for different scenarios.


<p><b>10) jackson-databind </b></p>

```
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
</dependency>
```
<p>The <dependency> with the group ID com.fasterxml.jackson.core and artifact ID jackson-databind is a key component of the Jackson library. Jackson is a widely used Java library for converting Java objects to JSON and vice versa. Specifically, jackson-databind is used for data binding, allowing you to map Java objects to JSON and back, supporting both serialization and deserialization.</p>

<h4>Key Features:</h4>

- **Serialization and Deserialization**: Converts Java objects to JSON (serialization) and JSON to Java objects (deserialization).

- **Supports Various Data Types**: Handles collections, lists, maps, and other custom types seamlessly.

- **Custom Serialization/Deserialization**: Supports custom serializers and deserializers for complex or non-standard Java types.

- **Configuration Flexibility**: Allows customization of JSON processing, including handling of null values, pretty printing, etc.

- **Annotation Support**: Integrates with Jackson annotations like @JsonProperty, @JsonIgnore, @JsonFormat, etc., to control how Java objects are converted to JSON.


<p><b>11) jackson-annotations </b></p>

```
<dependency>
     <groupId>com.fasterxml.jackson.core</groupId>
     <artifactId>jackson-annotations</artifactId>
</dependency>
```
<p>The <dependency> with the group ID com.fasterxml.jackson.core and artifact ID jackson-annotations is part of the Jackson library. This dependency provides annotations that allow developers to customize how Java objects are serialized (converted to JSON) and deserialized (converted from JSON) using Jackson.</p>

<h4>Key Features:</h4>

- **Customization of JSON Mapping**: Allows fine-grained control over how Java object fields and methods are mapped to JSON properties and vice versa.

- **Improved Serialization/Deserialization**: Helps configure how specific fields are included, excluded, renamed, or formatted when converting between Java objects and JSON.

- **Reduction of Boilerplate Code**: Simplifies the JSON processing by adding annotations directly to your Java classes, avoiding manual configuration in code.


<p><b>12) spring-boot-starter-websocket </b></p>

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-websocket</artifactId>
</dependency>
```
<p>The <dependency> with the group ID org.springframework.boot and artifact ID spring-boot-starter-websocket is used to enable WebSocket support in a Spring Boot application.</p>

<h4>Key Features:</h4>

- **Real-Time Communication**: Enables continuous two-way communication between the client and the server.

- **Reduced Latency**: Unlike HTTP, WebSocket connections remain open, removing the need for repeated requests.

- **Event-Driven Architecture**: Suitable for event-based use cases where updates need to be pushed to the client in real-time.

- **Chat Applications**: Sending and receiving messages instantly between clients.

- **Real-Time Dashboards**: Live stock market data, user activity tracking, etc.

- **Gaming**: Multiplayer games that require instant communication between players.


<p><b>13) jakarta.validation-api </b></p>

```
<dependency>
    <groupId>jakarta.validation</groupId>
    <artifactId>jakarta.validation-api</artifactId>
    <version>3.0.2</version>
</dependency>
```
<p>The jakarta.validation-api is the standard for Java Bean Validation and allows you to validate the constraints on:

Class fields. 
Method parameters.
Return values.
It is often used in conjunction with Hibernate Validator, which is the reference implementation of the Jakarta Bean Validation API.</p>

<h4>Key Features:</h4>

- **Declarative Validation with Annotations**: Validate fields, methods, or parameters using annotations such as `@NotNull`, `@Size`, `@Min`, etc.

- **Custom Constraints**: Create your own validation logic with custom annotations.

- **Integration with Frameworks**: Supported out-of-the-box in frameworks like Spring Boot, where validations are automatically triggered.

- **Cross-Parameter Validation**: Validate parameters across method calls or fields in a class.

- **@NotNull**: Ensures the value is not null.

- **@Size**: Validates the size of a collection, array, or string.

<p><b>14) modelmapper </b></p>

```
<dependency>
    <groupId>org.modelmapper</groupId>
    <artifactId>modelmapper</artifactId>
    <version>3.1.1</version>
</dependency>
```
<p>The <dependency> with the group ID org.modelmapper and artifact ID modelmapper provides a library for object mapping in Java. It simplifies the process of transferring data between objects, especially when working with layers like DTOs (Data Transfer Objects) and entities in applications.</p>

<h4>Key Features:</h4>

- **Automated Mapping**: Automatically maps fields with matching names and compatible types between two objects.

- **Customizable Mapping**: Supports defining custom mapping logic for specific scenarios.

- **Property Mapping**: Maps fields even if their names don't match, by using configuration or explicit mapping rules.

- **Bidirectional Mapping**: Supports mapping in both directions (e.g., Entity → DTO and DTO → Entity).

- **Collections Mapping**: Handles mapping between collections (e.g., List of entities to List of DTOs).

- **Deep Mapping**: Maps nested objects and complex structures.


<p><b>15) commons-io </b></p>

```
<dependency>
    <groupId>commons-io</groupId>
    <artifactId>commons-io</artifactId>
    <version>2.11.0</version>
</dependency>
```
<p>The Apache Commons IO library is used to:

Simplify file and stream manipulation.
Perform operations like copying files, reading/writing text, monitoring directories, etc.
Handle advanced I/O tasks such as dealing with file filters, byte arrays, and file comparisons.
</p>

<h4>Key Features:</h4>

- **File Utilities**: Simplifies file operations like copying, deleting, moving, and comparing files.

- **Stream Utilities**: Makes it easier to work with InputStream and OutputStream.

- **IO Monitoring**: Supports monitoring changes in directories (e.g., file creation, deletion, or modification).

- **File Filters**: Provides ready-to-use filters to select files based on conditions (e.g., by extension or size).

- **Filename Utilities**: Handles filename manipulation like extracting extensions or normalizing paths.

- **Endian Support**: Provides utilities to work with big-endian and little-endian data.


<p><b>16) netty-codec-http </b></p>

```
<dependency>
     <groupId>io.netty</groupId>
     <artifactId>netty-codec-http</artifactId>
     <version>4.1.107.Final</version> <!-- You can choose the appropriate version -->
</dependency>
```
<p>The <dependency> with the group ID io.netty and artifact ID netty-codec-http is part of the Netty framework, which is a popular library for building network applications in Java. Specifically, this module provides support for working with HTTP and HTTP/2 protocols.</p>

<h4>Key Features:</h4>
- **HTTP Encoding/Decoding**: Automatically encodes/decodes HTTP messages (requests and responses).

- **HTTP/2 Support**: Provides tools to handle HTTP/2 frames and multiplexing.

- **Lightweight and Efficient**: Built for performance and scalability, suitable for high-throughput applications.

- **Custom Protocol Handling**: Allows customization of HTTP handling logic for specific use cases.

- **Integration with Other Netty Modules**: Works seamlessly with other Netty modules like netty-handler and netty-buffer.


<p><b>17) jakarta.mail:jakarta.mail-api </b></p>

```
<dependency>
     <groupId>jakarta.mail</groupId>
     <artifactId>jakarta.mail-api</artifactId>
     <version>2.1.1</version>
</dependency>
```
<p>The <dependency> with groupId as jakarta.mail and artifactId as jakarta.mail-api provides the Jakarta Mail API (previously known as JavaMail). This dependency is used for building email functionality in Java applications, such as sending and receiving emails via SMTP, POP3, or IMAP protocols.</p>

<h4>Key Features:</h4>

- **SMTP Support**: Send emails using Simple Mail Transfer Protocol (SMTP).

- **POP3/IMAP Support**: Retrieve emails from mail servers.

- **Attachments**: Add file attachments or inline images to emails.

- **Authentication**: Supports authentication for secure email communication.

- **Rich Content**: Send emails with HTML content and multimedia.

- **Custom Headers**: Add custom headers to email messages.


<p><b>18) spring-boot-starter-mail </b></p>

```
<dependency>
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-starter-mail</artifactId>
</dependency>
```
<p>This dependency provides the necessary components to easily integrate email sending functionality into your Spring Boot applications.
It simplifies the process of configuring and sending emails using JavaMailSender interface.</p>

<h4>Key Features:</h4>

- **Easy Integration**: Seamlessly integrates with Spring Boot's auto-configuration mechanism.

- **JavaMailSender**: Provides a convenient interface for sending emails with various configurations (e.g., SMTP, Gmail).

- **Supports various protocols**: Works with SMTP, IMAP, POP3, and other mail protocols.

- **Flexible Configuration**: Easily configure email settings (host, port, credentials, etc.) through application properties or configuration files.


<p><b>19) byte-buddy </b></p>

```
<dependency>
    <groupId>net.bytebuddy</groupId>
    <artifactId>byte-buddy</artifactId>
    <version>1.14.16</version>
</dependency>
```
<p>The byte-buddy dependency provides you with the tools to dynamically work with Java bytecode. This is a powerful technique with various applications, especially in scenarios where you need to customize the behavior of classes or implement advanced features like AOP.</p>

<h4>Key Features:</h4>

- **Code Generation**: Create new classes or modify existing ones without needing to write or compile Java source code directly. This is incredibly useful for:

- **AOP (Aspect-Oriented Programming)**: Implement cross-cutting concerns (like logging, security) by dynamically weaving in behavior at runtime.

- **Dynamic Proxies**: Create proxies for objects to intercept method calls and add custom logic.

- **Class Transformation**: Modify existing classes to enhance their behavior or adapt them to specific needs.


<p><b>20) twilio </b></p>

```
 <dependency>
    <groupId>com.twilio.sdk</groupId>
    <artifactId>twilio</artifactId>
   <version>8.23.0</version>
</dependency>
```
<p>The twilio dependency allows you to leverage the power of the Twilio platform within your Java applications. It provides a convenient and efficient way to implement communication features like SMS, voice calls, and more.</p>

<h4>Key Features:</h4>

- **Simplified API Interactions**: The SDK abstracts away the complexities of interacting with Twilio's REST API.

- **Language Support**: Available for various programming languages (Java, Python, Node.js, etc.).

- **Easy Integration**: Easily integrate Twilio functionality into your applications.

- **Well-Documented**: Extensive documentation and examples are available to help you get started.


<p><b>21) javax.mail </b></p>

```
<dependency>
    <groupId>com.sun.mail</groupId>
    <artifactId>javax.mail</artifactId>
    <version>1.6.2</version>
</dependency>
```
<p>The javax.mail dependency provides you with the necessary tools to work with email in your Java applications. It offers a standardized and robust way to handle email-related tasks.

Note: While com.sun.mail is a common implementation of the JavaMail API, other implementations might be available.</p>

<h4>Key Features:</h4>

- **Platform-Independent**: Works across different operating systems and Java platforms.

- **Protocol Support**: Supports various email protocols like SMTP, IMAP, POP3, and more.

- **Flexible**: Allows you to customize email messages with attachments, headers, and other properties.

- **Well-Established**: A widely used and well-supported standard API for email operations.


<p><b>22) poi-ooxml </b></p>

```
<dependency>
    <groupId>org.apache.poi</groupId>
   <artifactId>poi-ooxml</artifactId>
   <version>5.2.3</version>
</dependency>
```
<p>The poi-ooxml dependency provides you with the tools to work with OOXML files (Excel, Word, PowerPoint) programmatically in Java. It's a powerful library for a wide range of use cases involving data processing and document generation.</p>

<h4>Key Features:</h4>

- **Data Processing**: Read and manipulate data from Excel files for analysis, reporting, and other tasks.

- **Report Generation**: Create dynamic reports in Excel format.

- **Document Automation**: Generate customized Word documents or PowerPoint presentations.

- **File Conversion**: Convert between different file formats (e.g., Excel to CSV).


<p><b>22) java-jwt </b></p>

```
<dependency>
     <groupId>com.auth0</groupId>
     <artifactId>java-jwt</artifactId>
     <version>3.18.1</version>
</dependency>
```
<p>The java-jwt dependency provides you with the necessary tools to work with JWTs in your Java applications. It simplifies the process of implementing secure and reliable authentication and authorization mechanisms.</p>

<h4>Key Features:</h4>
- **JWT Creation**: Easily create signed JWTs with claims (e.g., user ID, roles, expiration time).

- **JWT Verification**: Verify the authenticity and integrity of received JWTs.

- **Algorithm Support**: Supports various JWT signing algorithms (e.g., HS256, RS256, RSA).

- **Claim Extraction**: Extract claims from a JWT for use within your application.

<p><b>23) tika-core </b></p>

```
<dependency>
    <groupId>org.apache.tika</groupId>
    <artifactId>tika-core</artifactId>
    <version>2.8.0</version>
</dependency>
```
<p>The tika-core dependency provides you with a robust and versatile toolkit for working with various file formats. It simplifies the process of detecting file types, extracting metadata, and extracting text content, making it a valuable tool for many data-related tasks.</p>

<h4>Key Features:</h4>

- **Supports a Wide Range of File Formats**: Handles a vast number of file formats, including common office documents, images, archives, and more.

- **Extensible**: Easily extend Tika to support new file formats through custom parsers.

- **Efficient**: Leverages efficient parsing techniques for fast and accurate results.

- **Open Source**: A community-driven project with a large and active user base.


<p><b>24) spring-boot-starter-security </b></p>

```
<dependency>
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```
<p>The spring-boot-starter-security dependency is essential for building secure Spring Boot applications. It provides a solid foundation for implementing authentication and authorization features, making it easier to protect your application from unauthorized access and data breaches.</p>

<h4>Key Features:</h4>

- **Spring Security Integration**: Leverages the powerful Spring Security framework, providing a robust and flexible security solution.

- **Easy Configuration**: Simplifies the process of setting up security by providing default configurations and allowing for customization.

- **Support for Various Authentication Mechanisms**: Supports various authentication methods, including:
  - **Username/Password**: Traditional username and password-based authentication.
  - **OAuth2**: Integrate with popular OAuth2 providers (e.g., Google, Facebook, GitHub).
  - **JWT**: Implement token-based authentication using JSON Web Tokens.

- **Support for Authorization**: Implement role-based access control (RBAC), attribute-based access control (ABAC), and other authorization mechanisms.


<p><b>25) tika-parsers-standard-package </b></p>

```
<dependency>
    <groupId>org.apache.tika</groupId>
    <artifactId>tika-parsers-standard-package</artifactId>
    <version>2.8.0</version>
</dependency>
```
<p>The tika-parsers-standard-package dependency enhances the capabilities of the Apache Tika library by providing a collection of pre-built parsers for common file formats. This simplifies the process of working with various file types and improves the overall efficiency of your Tika-based applications.</p>

<h4>Key Features:</h4>

- **Enhanced Functionality**: Adds support for a large number of file formats beyond the basic capabilities of the tika-core library.

- **Convenience**: Provides ready-to-use parsers, saving you the effort of developing custom parsers for common file types.

- **Improved Performance**: Often includes optimized parsers for specific file formats, leading to faster processing.


<p><b>26) jjwt </b></p>

```
<dependency>
     <groupId>io.jsonwebtoken</groupId>
     <artifactId>jjwt</artifactId>
     <version>0.9.1</version>
</dependency>
```
<p>The jjwt dependency provides you with the necessary tools to work with JWTs in your Java applications. It simplifies the process of implementing secure and reliable authentication and authorization mechanisms.</p>

<h4>Key Features:</h4>

- **JWT Creation**: Easily create signed JWTs with claims (e.g., user ID, roles, expiration time).
  
- **JWT Verification**: Verify the authenticity and integrity of received JWTs
  
- **Algorithm Support**: Supports various JWT signing algorithms (e.g., HS256, RS256, RSA).
  
- **Claim Extraction**: Extract claims from a JWT for use within your application.
  
- **Easy to Use**: Provides a simple and intuitive API for working with JWTs.
  
- **Authentication**: Implement user authentication and authorization within your applications.

---

### SocketIO

#### 3.1. What is Socket.IO?

**Socket.IO** is a JavaScript library that enables real-time, bi-directional communication between web clients (such as browsers) and servers over **WebSockets** or other protocols. It's often used in applications that require real-time updates, such as messaging apps, live notifications, and multiplayer games.

Socket.IO is built on top of **WebSockets**, but it offers additional features like automatic reconnection, fallback mechanisms (e.g., using long polling when WebSockets are unavailable), and broadcasting, which makes it more reliable and easier to work with compared to raw WebSocket connections.

#### 3.1.1. Key Features of Socket.IO:

3.1.1.1. **Real-time Communication**: Allows real-time, low-latency communication between the server and the client. For example, a message can be sent from the server to the client and vice versa in real-time.
3.1.1.2. **Bi-directional Communication**: Both the client and server can send messages to each other, making it ideal for interactive applications like chat apps or live collaboration tools.
3.1.1.3. **Automatic Reconnection**: Socket.IO automatically tries to reconnect when the connection is lost, ensuring reliability.
3.1.1.4. **Fallbacks**: If WebSockets are not supported, Socket.IO can automatically fall back to other communication protocols, such as long polling.
3.1.1.5. **Namespaces**: Allows you to divide your application into different channels (called namespaces), enabling message isolation between them.
3.1.1.6. **Rooms**: A way of grouping clients together, which makes it easier to broadcast messages to certain groups of users.
3.1.1.7. **Event-based Communication**: Uses a simple event-driven architecture. Clients and servers emit and listen to events, making the interaction very intuitive.

---

#### 3.2. Which version have we used in the application?

#### **Socket.IO Version 2.0.12 Overview**

Socket.IO **version 2.0.12** is a **patch version** of **Socket.IO 2.x**, released after version 2.0, which brought significant changes to Socket.IO’s core architecture, including improved performance, support for newer browser versions, and API changes.

#### 3.2.1 **Key Features and Updates in Socket.IO 2.0.12**

While Socket.IO 2.x includes several important changes, version **2.0.12** (released in 2019) focused mainly on **bug fixes**, minor improvements, and ensuring compatibility with the latest platforms and environments.

---

#### Socket.IO Configuration in the Application

```java
import com.corundumstudio.socketio.Configuration;
import com.corundumstudio.socketio.SocketIOServer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class SocketIOConfig {

    @Bean
    public SocketIOServer socketIOServer() {
        Configuration config = new Configuration();
        config.setHostname("localhost");
        config.setPort(8080);
        config.setOrigin("*");

        return new SocketIOServer(config);
    }
}
```

#### 3.2.2. Explanation of Configuration Code in Detail

#### 3.2.2.1. **Package Imports** 
```java

import com.corundumstudio.socketio.Configuration; 

import com.corundumstudio.socketio.SocketIOServer; 

import org.springframework.context.annotation.Bean;
``` 

- **com.corundumstudio.socketio.Configuration**: This class is used to configure various settings for the **Socket.IO server** (such as the hostname, port, and other parameters). 
- **com.corundumstudio.socketio.SocketIOServer**: This is the main class that represents the **Socket.IO server**. It is responsible for starting the server, managing connections, and handling events. 
- **org.springframework.context.annotation.Bean**: The @Bean annotation from Spring is used to indicate that the method that follows should be treated as a **bean definition**. This allows Spring to manage the lifecycle of the SocketIOServer object and inject it into other parts of the application.

#### 3.2.2.2. **@Configuration Annotation** 
```java
@org.springframework.context.annotation.Configuration 

public class SocketIOConfig { 
```
- **@Configuration**: This annotation is used to define a **Spring configuration class**, which contains bean definitions for the Spring IoC (Inversion of Control) container. By marking the class with @Configuration, we tell Spring to treat it as a source of bean definitions, which are later injected where needed. 
- **public class SocketIOConfig**: This is the class where we configure the Socket.IO server. The class is named `SocketIOConfig` to reflect that it holds the configuration for Socket.IO.

#### 3.2.2.3. **@Bean Method for Socket.IO Server** 
```java
@Bean 

public SocketIOServer socketIOServer() { 

`    `Configuration config = new Configuration(); 

`    `config.setHostname("localhost"); 

`    `config.setPort(8080); 

`    `config.setOrigin("\*"); 

`    `return new SocketIOServer(config); 

} 
```
- **@Bean**: The @Bean annotation is used to declare a method as a **Spring Bean**. When Spring sees this annotation, it will call this method, create an object (in this case, a `SocketIOServer`), and manage it as a Spring-managed bean. This makes it possible to inject `SocketIOServer` into other components of the Spring application, enabling real-time communication features. 

- **public SocketIOServer socketIOServer()**: This is the method definition that returns a `SocketIOServer` bean. This method creates and configures a `SocketIOServer` instance, which is the core of your Socket.IO server.

 ---

#### 3.3. **Creating and Configuring the Socket.IO Server:** 

3.3.1. - **Configuration config = new Configuration();**: 
  - The `Configuration` class is used to hold the various configuration parameters for the Socket.IO server (such as hostname, port, and origins).
  
3.3.2. - **config.setHostname("localhost");**: 
  - This sets the **hostname** to "localhost". This means the server will only be accessible on the local machine (localhost). If you wanted the server to be accessible externally, you would need to set this to your machine's IP address or a domain name (like "example.com").
  
3.3.3. - **config.setPort(8080);**: 
  - This sets the **port** number for the Socket.IO server to listen on. In this case, the server will listen on port 8080. This is the same port number often used by web servers for development, so it will be accessible at [http://localhost:8080](http://localhost:8080) in a browser (or through WebSocket connections).

3.3.4. - **config.setOrigin("\*");**: 
  - This sets the **CORS (Cross-Origin Resource Sharing)** settings for the server. `setOrigin("*")` allows connections from any origin. This is useful in development environments or when your server needs to accept requests from multiple domains. In a production environment, you may want to restrict the allowed origins for security purposes (e.g., `config.setOrigin("https://example.com");`).

3.3.4. - **return new SocketIOServer(config);**: 
  - Finally, a **new SocketIOServer** instance is created with the configured `Configuration` object and returned from the method. This instance is now managed by the Spring context as a bean and can be used to listen for connections, emit events, and broadcast messages.

---

#### 3.4. **Why is This Code Used?**

This configuration is used to **initialize a Socket.IO server** within a Spring Boot application. The server is then capable of handling **real-time communication** with clients (e.g., web browsers, mobile apps). Socket.IO is used for applications that need low-latency, bidirectional communication, such as:

- **Chat applications** 
- **Real-time notifications** 
- **Collaborative tools**
- **Live updates** (sports scores, stock prices, etc.)
- **Multiplayer games** 

The `SocketIOServer` will listen for connections on the specified port (8080), handle events like user connections and disconnections, and can send/receive messages in real time.

---

#### 3.5 **How This Fits into the Spring Boot Application:** 

3.5.1. **Spring Boot Integration:**
   - Spring Boot applications typically use `@Configuration` classes to define and configure beans. In this case, we define a `SocketIOServer` bean, which is then available for injection into other components of the application.

3.5.2. **Real-Time Communication:**
   - With this configuration, the Socket.IO server is set up to handle real-time communication for clients that connect to the Spring Boot backend. The clients could be web clients (using **JavaScript Socket.IO client**), mobile apps, or even desktop applications.

3.5.3. **Dependency Injection:**
   - Spring will manage the lifecycle of the `SocketIOServer` bean. This means you can inject this `SocketIOServer` into other Spring beans to interact with the Socket.IO server and manage connections.

---

#### 3.6 **Potential Use Case**

In a typical scenario, after configuring the `SocketIOServer`:

- You might define a **Socket.IO event listener** that listens for custom events (e.g., messages, user actions).
- You could use **broadcasting** to send real-time updates to multiple connected clients.
- The **Socket.IO server** could emit events back to the client or listen for client messages and trigger actions on the backend.

For example, you might have a **message event** where a client sends a message to the server, and the server broadcasts it to all other connected clients. 

java 

Copy: 
```java
socketIOServer.addEventListener("message", String.class, (client, data, ackSender) -> { 

socketIOServer.getBroadcastOperations().sendEvent("newMessage", data); 

}); 
```
3.6.1. **Key Concepts:** 

- **Spring Boot Configuration**: Using `@Configuration` and `@Bean` to configure and manage `SocketIOServer` as a Spring bean.
- **Socket.IO Server**: A server that manages real-time communication using WebSockets or other protocols and is integrated into a Spring Boot application.
- **Event-driven Architecture**: Using Socket.IO to send and receive events, enabling real-time bidirectional communication between server and client.

---

#### 3.7 **Conclusion**:

This configuration class sets up a **Socket.IO server** that listens for WebSocket connections on a Spring Boot backend. By doing so, it enables your application to support **real-time communication** with clients. Using **Spring's dependency injection** and **Socket.IO's real-time capabilities**, your app can handle events, broadcast updates, and communicate with clients instantly.

---

#### 3.8 **Set up of Socket.IO using ReactJS (with Vite) on the Front End and Spring Boot on the Back End for Real-Time Communication**

#### **Overview**

- **Backend**: We'll use **Spring Boot** with **Socket.IO** for handling real-time connections.
- **Frontend**: We'll use **ReactJS** (created using **Vite**) and the **Socket.IO client** to connect to the Spring Boot server for real-time communication.

#### 3.8.1 **Backend: Spring Boot + Socket.IO**

#### 3.8.1.1 **Step 1: Set up Spring Boot with Socket.IO** 

1. **Create a Spring Boot project** using Spring Initializr or your preferred IDE. 
   - Dependencies: 
     - **Spring Web** (for basic REST APIs)
     - **Socket.IO** (via the `netty-socketio` library)

2. **Add dependencies to `pom.xml`:** 

```xml
<dependencies>
    <!-- Spring Boot Starter Web -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Socket.IO (Netty version) -->
    <dependency>
        <groupId>com.corundumstudio.socketio</groupId>
        <artifactId>netty-socketio</artifactId>
        <version>2.0.0</version> <!-- Make sure to use the correct version -->
    </dependency>

    <!-- Spring Boot Starter for JPA (Optional, if using databases) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-jpa</artifactId>
    </dependency>
</dependencies>
```
#### **Step 3: Create `SocketIOConfig.java` to Configure the Socket.IO Server**

#### `SocketIOConfig.java`

```java
import com.corundumstudio.socketio.Configuration;
import com.corundumstudio.socketio.SocketIOServer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class SocketIOConfig {

    @Bean
    public SocketIOServer socketIOServer() {
        // Create the configuration object for Socket.IO server
        Configuration config = new Configuration();

        // Set the hostname to localhost and port to 8080
        config.setHostname("localhost");
        config.setPort(8080); // Socket.IO server listens on port 8080

        // Set origin to '*' to allow all origins (adjust for production)
        config.setOrigin("*");

        // Initialize the Socket.IO server with the configuration
        SocketIOServer server = new SocketIOServer(config);

        // Listen to 'chat' events from the client
        server.addEventListener("chat", String.class, (client, data, ackSender) -> {
            System.out.println("Message received from client: " + data);

            // Broadcast the message to all connected clients
            server.getBroadcastOperations().sendEvent("chat", data);
        });

        // Start the Socket.IO server
        server.start();

        // Return the SocketIOServer bean to be managed by Spring
        return server;
    }
}
```
- In this configuration, we are setting up a **Socket.IO server** that listens for **"chat"** events and sends the received data to all connected clients (broadcasting).

---

#### **Step 4: Create `SocketController.java` (Optional)** to Expose an HTTP Endpoint

If you need to expose additional HTTP endpoints along with the Socket.IO server, you can create a simple controller. Below is an optional example of a Spring Boot controller.

#### `SocketController.java`

```java
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class SocketController {

    @GetMapping("/hello")
    public String hello() {
        return "Hello from Spring Boot!";
    }
}
```
#### **Step 5: Run the Spring Boot Application** This starts a **Socket.IO server** on localhost:8080. 

#### 3.8.2 **Frontend: ReactJS + Vite + Socket.IO Client**

#### 3.8.2.1 **Step 2: Set up React with Vite and Socket.IO Client**

1. **Create a new React app** using **Vite**:

   Run the following command to create a new React app with the Vite template:

   ```bash
   npm create vite@latest my-app --template react
   cd my-app
   ```

---

#### **Step 2: Install the required dependencies**

To enable real-time communication between the React frontend and the Socket.IO server, you need to install the **Socket.IO client**.

Run the following command to install it:

```bash
npm install socket.io-client
```

---

#### **Step 3: Create the ChatApp.js Component**

In this step, you will create a **ChatApp.js** component that allows the user to send and receive messages using **Socket.IO**.

```jsx
import { useState, useEffect } from "react";
import { io } from "socket.io-client";

// Connect to the Spring Boot Socket.IO server
const socket = io("http://localhost:8080");

function ChatApp() {
  const [message, setMessage] = useState("");
  const [messages, setMessages] = useState([]);

  // Listen for incoming messages from the server
  useEffect(() => {
    socket.on("chat", (data) => {
      setMessages((prevMessages) => [...prevMessages, data]);
    });

    // Clean up the socket connection when the component is unmounted
    return () => {
      socket.off("chat");
    };
  }, []);

  // Handle sending messages to the server
  const sendMessage = () => {
    if (message.trim() !== "") {
      socket.emit("chat", message); // Emit "chat" event to the server
      setMessage(""); // Clear the input field
    }
  };

  return (
    <div>
      <h2>Socket.IO Chat</h2>
      <div>
        <div style={{ marginBottom: "20px" }}>
          {messages.map((msg, index) => (
            <div key={index}>{msg}</div>
          ))}
        </div>
        <input
          type="text"
          value={message}
          onChange={(e) => setMessage(e.target.value)}
          placeholder="Type a message"
        />
        <button onClick={sendMessage}>Send</button>
      </div>
    </div>
  );
}

export default ChatApp;
```

---

#### **Understanding Key Parts of the Code:**

1. **Connecting to the Socket.IO Server**:
   - `socket = io("http://localhost:8080")`: 
     - This establishes a WebSocket connection to the **Socket.IO server** running on `localhost:8080`, which is handled by the Spring Boot backend. 
     - The `io()` function from the `socket.io-client` library is used to initiate this connection.

2. **Handling Incoming Messages**:
   - `socket.on("chat", (data) => {...})`: 
     - Listens for the `"chat"` event emitted by the server.
     - When a message is received, it adds the message to the `messages` state array, which updates the UI to display the new message.

3. **Sending Messages**:
   - `socket.emit("chat", message)`:
     - This sends the `"chat"` event to the Socket.IO server along with the message content (`message`).
     - The server receives the event and can broadcast it to all connected clients, enabling real-time communication between them.

---

#### **Summary:**

- The **Socket.IO client** in the React app connects to the backend, listens for incoming messages, and sends messages to the server using the `emit` and `on` methods.
- This allows for **bidirectional, real-time communication** between the frontend (ReactJS) and the backend (Spring Boot with Socket.IO).

---

---

#### 3.8.3 **Step 3: Update `App.js` to Use `ChatApp` Component**

In this step, you'll import the `ChatApp` component into the `App.js` file and render it inside the main application.

#### **Code:**
```jsx
import React from "react"; 
import ChatApp from "./ChatApp"; // Import the ChatApp component

function App() { 
  return ( 
    <div className="App">
      <ChatApp />  {/* Render the ChatApp component */}
    </div> 
  ); 
}

export default App;
```

---

#### 3.8.4 **Step 4: Run the React + Vite Application**

#### **1. Start the React Development Server**:

To run the React application, execute the following command:

```bash
npm run dev
```

---

#### 3.9 **How Socket.IO Works Here:**

#### 3.9.1. Backend (Spring Boot):**
1. When a client sends a chat event (through `socket.emit("chat", message)`), the Spring Boot backend receives it via `server.addEventListener("chat", ...)`.
2. The backend then broadcasts the message to all connected clients using `server.getBroadcastOperations().sendEvent("chat", data)`.

#### 3.9.2. Frontend (React + Vite):**
1. The React app listens for the `chat` event through `socket.on("chat", ...)`, and when the event is received, it updates the UI with the new message.
2. When a user sends a message, the React app emits a `chat` event to the Spring Boot server, which broadcasts it back to all connected clients.

---

#### 3.10 **Summary of Communication Flow:**

3.10.1. **User Interaction**: 
   - The user types a message in the React app and clicks the "Send" button.
   
3.10.2. **Frontend**: 
   - The React app emits a `chat` event to the Spring Boot backend.
   
3.10.3. **Backend**: 
   - The Spring Boot server receives the `chat` event, processes it, and broadcasts it to all connected clients.
   
3.10.4. **Frontend**: 
   - All connected React clients receive the `chat` event and update their UI with the new message.

---

#### 3.11 **Testing It:**

3.11.1. Open **two browser windows** at [http://localhost:3000](http://localhost:3000).
3.11.2. Send a message in one window, and you should see the message appear in real-time in the other window.
3.11.3. The message is sent from the client to the server, and the server broadcasts it to all connected clients.

---

#### **Conclusion**

This setup demonstrates how to use **Socket.IO** for real-time communication between a **React frontend** and a **Spring Boot backend**. By combining the power of **Socket.IO** for event-driven, bi-directional communication with **Spring Boot** and **ReactJS**, you can easily build interactive real-time web applications.

#### **Note**: The backend API and SocketIO operate independently and do not rely on each other.

---

### Configuration of application dot properties

#### 3.1. what is application.properties?
In Spring Boot, `application.properties` is a configuration file that allows you to set various properties to customize the behavior of the application. It's the default file used to store configuration settings for different components of a Spring Boot application, such as the server, database, logging, security, and more.

It can be used to configure properties related to:

- **Database connections**
- **Server settings** (e.g., port number, context path)
- **Logging configuration**
- **JPA** (Java Persistence API) settings
- **Security properties**
- **File upload limits**
- **Spring-specific configuration properties** (such as cache, session management, etc.)

You can use `application.properties` to configure your Spring Boot application in a **centralized** and **externalized** way, so the application can be easily customized without having to modify the source code.

---

#### How has the application.properties file been configured in the application?
```java
spring.application.name=157-project1
server.port=3000
spring.datasource.url=jdbc:MySql://localhost:3306/157task
spring.datasource.username=root
spring.datasource.password=8446394639
#spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
```

#### Explanation of `application.properties` Configuration

This configuration file is typically found in the `application.properties` file in a Spring Boot project. It's used to configure various properties for the Spring Boot application, such as server settings, data source (database) configurations, and file upload settings. Let's go through each line of this file to explain its significance.

#### 1. `spring.application.name=157-project1`
- **Purpose**: This sets the name of the Spring Boot application. It's useful for identifying the application, especially when using tools like Spring Boot Admin or logging.
- **Why it's necessary**: It helps give a human-readable name to the application, which is particularly useful when you have multiple services running.

#### 2. `server.port=3000`
- **Purpose**: This sets the port on which the embedded web server (e.g., Tomcat) will run. By default, Spring Boot runs on port 8080, but in this case, it's explicitly set to run on port 3000.
- **Why it's necessary**: This is needed if you want to change the default port Spring Boot uses to a custom port (in this case, port 3000). You might need to change it to avoid port conflicts or for specific requirements in your environment.

#### 3. `spring.datasource.url=jdbc:MySql://localhost:3306/157task`
- **Purpose**: This property configures the URL of the database Spring Boot will connect to. The `jdbc:mysql://localhost:3306/157task` URL specifies that the application should use MySQL as the database and connect to it via localhost (the local machine) on port 3306 (default MySQL port). The database name is `157task`.
- **Why it's necessary**: This is needed to tell Spring Boot which database to connect to. Without this, the application won’t know where to find the database, and database operations would fail.

#### 4. `spring.datasource.username=root`
- **Purpose**: This specifies the username that Spring Boot will use to authenticate to the database. In this case, it is set to `root`, which is a default MySQL user.
- **Why it's necessary**: The username is required to connect to the database. It tells the application what credentials to use for accessing the database.

#### 5. `spring.datasource.password=8446394639`
- **Purpose**: This specifies the password corresponding to the username (`root` in this case). It's used for authenticating the connection to the MySQL database.
- **Why it's necessary**: The password is essential for authenticating the user and establishing a secure connection to the database.

#### 6. `#spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver`
- **Purpose**: This is a commented-out line (due to the `#` symbol) that typically specifies the driver class for the MySQL database. The driver class is necessary for connecting Java to MySQL. However, Spring Boot automatically detects the correct driver when using the `spring-boot-starter-data-jpa` dependency, so you generally don’t need to specify this unless there are specific issues.
- **Why it's necessary**: If you're using a database like MySQL, you would normally specify the driver class (`com.mysql.cj.jdbc.Driver`), but in most cases, Spring Boot can automatically detect it when the appropriate dependency (`spring-boot-starter-data-jpa`) is added. The commented-out line is simply a fallback or an optional setting.

#### 7. `spring.jpa.hibernate.ddl-auto=update`
- **Purpose**: This property tells Hibernate (the JPA implementation) how to handle database schema generation. The value `update` means that Hibernate will automatically update the database schema to match the entity classes each time the application is run.
    - Possible values:
        - `none`: No schema generation is performed.
        - `update`: Updates the schema by adding new tables/columns or modifying existing ones, but doesn't delete any data.
        - `create`: Drops and recreates the schema on each startup.
        - `create-drop`: Same as `create`, but it also drops the schema when the session factory is closed (useful for testing).
- **Why it's necessary**: This is important for automatic schema management. Setting it to `update` ensures that if your entity classes change, the database schema will automatically adjust accordingly.

#### 8. `spring.jpa.show-sql=true`
- **Purpose**: This property enables SQL logging. When set to `true`, it will log the SQL statements executed by Hibernate (or any JPA provider).
- **Why it's necessary**: It’s useful for debugging, as you can see the exact SQL queries that Hibernate is executing on the database. This helps when you want to verify the SQL that your entities are producing, especially during development.

#### 9. `spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect`
- **Purpose**: This property defines the Hibernate dialect to use. The dialect is a Hibernate configuration setting that ensures the correct SQL is generated for the underlying database. In this case, `MySQL8Dialect` tells Hibernate to generate SQL optimized for MySQL 8.
- **Why it's necessary**: It's crucial to set the correct dialect so that Hibernate generates the right SQL syntax for your MySQL database. Without the proper dialect, Hibernate may produce SQL that’s not compatible with your database, leading to errors.

#### 10. `spring.servlet.multipart.enabled=true`
- **Purpose**: This property enables support for multipart file uploads in the application.
- **Why it's necessary**: It’s needed if your application will handle file uploads. For example, if you have a feature that allows users to upload images or documents, this property enables Spring Boot to handle those files.

#### 11. `spring.servlet.multipart.max-file-size=10MB`
- **Purpose**: This specifies the maximum allowed file size for uploads. In this case, it’s set to `10MB`.
- **Why it's necessary**: It defines a file size limit for uploads. This is useful to prevent users from uploading excessively large files that could impact server performance or stability. Without this, there would be no limit on the file sizes, which could be problematic.

#### 12. `spring.servlet.multipart.max-request-size=10MB`
- **Purpose**: This property sets the maximum size for an entire HTTP request, including the uploaded file(s). It’s also set to `10MB` in this case.
- **Why it's necessary**: It’s essential to have a limit on the total size of the request to avoid issues when dealing with multiple or very large files. Without this, users could upload very large files, potentially affecting the server’s memory and performance.

---

### Development Workflow Full-Stack

#### Front-End Interaction:

- The user interacts with the front-end of the application, built using HTML, CSS, and JavaScript.
- The front-end, powered by ReactJS library, renders the user interface and handles user inputs.
- When the user performs an action (e.g., clicking a button, submitting a form), the front-end sends a request to the API.

#### API Processing:

- The API receives the request from the front-end.
- It processes the request, which may involve:
  - Validating the input data
  - Fetching data from the database
  - Performing business logic operations
  - Creating or updating data in the database

#### Back-End Processing:

- The API interacts with the back-end, which is built using Java and the Spring Boot framework.
- The back-end handles the API request, executes the necessary logic, and communicates with the database using the JDBC connector.

#### Database Interaction:

- The back-end interacts with the MySQL database through the JDBC connector.
- It retrieves or stores data as per the API request.

#### API Response:

- Once the back-end processes the request and interacts with the database, it sends a response back to the API.

#### Front-End Update:

- The API receives the response from the back-end.
- It sends the response to the front-end.
- The front-end updates the user interface based on the received data, providing feedback to the user.

#### DevOps:

- After development, the application is deployed using DevOps practices.
- Nginx server is used to handle incoming requests and route them to the appropriate backend services.
- Hostinger provides the infrastructure for hosting the application and managing the database.

#### Workflow Summary:

1. User interaction on the front-end.
2. Communication between the front-end, API, and back-end.
3. Database interaction for data storage and retrieval.
4. Deployment and maintenance using DevOps tools.

This workflow ensures that user actions are processed efficiently, data is managed securely, and the application is available to users.

![WhatsApp Image 2025-01-24 at 12 23 48 PM](https://github.com/user-attachments/assets/cbd3f4da-afb5-439d-8b45-8c3f285fb2f9)

---

### Front-End Code flow:

#### Request Body:
```json
{
  "employeeId": "127",
  "userType": "Recruiters",
  "employeeName": "Sahil Karnekar",
  "dateOfJoining": "Date: 23-1-2025, Time: 3:54 PM",
  "userName": "sahilkarnekarnewrecruiter",
  "aadhaarNo": "",
  "alternateContactNo": "",
  "anniversaryDate": "",
  "bloodGroup": "",
  "companyMobileNumber": "",
  "confirmPassword": "",
  "dateOfBirth": "",
  "department": "",
  "designation": "",
  "document": null,
  "editDeleteAuthority": "",
  "educationalQualification": "",
  "emergencyContactNumber": "",
  "emergencyContactPerson": "",
  "emergencyPersonRelation": "",
  "employeeAddress": "",
  "employeeEmail": "",
  "employeeExperience": "",
  "employeeNumber": "",
  "employeePassword": "",
  "employeePresentAddress": "",
  "employeeStatus": "",
  "entrySource": "",
  "esIcNo": "",
  "faceBookURL": "",
  "gender": "",
  "inductionComment": "",
  "inductionYesOrNo": "",
  "insuranceNumber": "",
  "interviewTakenPerson": "",
  "jobRole": "Recruiters",
  "lastCompany": "",
  "lastWorkingDate": "",
  "linkedInURl": "",
  "maritalStatus": "",
  "offeredSalary": "",
  "officialContactNumber": "",
  "officialMail": "",
  "panNo": "",
  "performanceIndicator": "",
  "perks": "",
  "pfNo": "",
  "professionalPtNo": "",
  "profileImage": null,
  "reasonForLeaving": "",
  "reportingMangerDesignation": "",
  "reportingMangerName": "",
  "resumeFile": null,
  "roundsOfInterview": "",
  "teamLeaderMsg": "Swapnil Rokade",
  "trainingCompletedYesOrNo": "",
  "trainingSource": "",
  "trainingTakenCount": "",
  "tshirtSize": "",
  "twitterURl": "",
  "warningComments": "",
  "whatsAppNumber": "",
  "workLocation": ""
}
```
#### Add Employee Post Operation: 

```javascript
try {    
  const response = await fetch(
    `${API_BASE_URL}/add-employee/${employeeId}/${userType}`,
    {
      method: "POST",
      body: formDataToSend,
    }
  );
  ```


#### Add Employee Put Operation:
```javascript
const response = await fetch(`${API_BASE_URL}/update-employee/${employeeId}`, {
  method: "PUT",
  body: formDataToSend,
});

```
#### Add Employee Delete Operation:
```javascript
const response = await fetch(`${API_BASE_URL}/delete-employee/${employeeId}`, {
  method: "DELETE",
});

```
#### Add Employee Get Operation:
```javascript
const response = await fetch(`${API_BASE_URL}/get-employee/${employeeId}`);
const data = await response.json();

```
<img src="https://github.com/user-attachments/assets/a55a03e3-7ea0-4eb8-8cdf-e4d7e377e69a" width="1000" height="auto" />

```
```

#### **Employee Management API Explanation:**


This API defines endpoints for managing employee data in a system. It supports operations like adding, updating, deleting, and retrieving employee details.

#### 1. POST (Add Employee)
**Purpose:** To add a new employee to the system.  
**Request:**  
It makes a POST request to a URL that includes the `employeeId` and `userType` (e.g., role of the employee, like "manager", "staff", etc.). These are dynamic values, meaning they are replaced by actual data when the request is made.  
**Body:**  
The body of the request contains `formDataToSend`, which is the data of the new employee (e.g., name, email, department, etc.).  
**Example URL:**  
`/add-employee/123/manager`  
(Where `123` is the `employeeId` and `manager` is the `userType`).  
**Outcome:**  
The server processes this data and adds the new employee to the system.

#### 2. PUT (Update Employee)
**Purpose:** To update an existing employee's details.  
**Request:**  
It makes a PUT request to a URL that includes the `employeeId` to specify which employee to update.  
**Body:**  
The request body contains `formDataToSend`, which includes the updated employee details (e.g., updated name, email, etc.).  
**Example URL:**  
`/update-employee/123`  
(Where `123` is the `employeeId` of the employee to be updated).  
**Outcome:**  
The server updates the employee's data with the new information provided in the request body.

#### 3. DELETE (Delete Employee)
**Purpose:** To delete an existing employee from the system.  
**Request:**  
It makes a DELETE request to a URL that includes the `employeeId` of the employee to be deleted.  
**Example URL:**  
`/delete-employee/123`  
(Where `123` is the `employeeId` of the employee to be deleted).  
**Outcome:**  
The server removes the employee's data from the system.

#### 4. GET (Get Employee)
**Purpose:** To retrieve the details of a specific employee.  
**Request:**  
It makes a GET request to a URL that includes the `employeeId` of the employee whose details are to be fetched.  

#### Fetch Employee Team Details with `useEffect`

This code demonstrates how to use the `useEffect` hook in React to fetch employee team details from a backend API whenever certain state variables (`currentPage` or `pageSize`) change.

#### Code Example

```javascript
useEffect(() => {
  const fetchData = async (page, size) => {
    try {
      const response = await axios.get(
        `${API_BASE_URL}/fetch-Team-details/${employeeId}/${userType}?page=${page}&size=${size}`
      );
      setEmployeeData(response.data.content);
      setLoading(false);
    } catch (error) {
      console.error("Error fetching data:", error);
      setLoading(false);
    }
  };

  fetchData(currentPage, pageSize);
}, [currentPage, pageSize]);

```

### Understanding the `useEffect` Hook in React

The following code demonstrates the use of the `useEffect` hook to handle side effects in a React component, specifically fetching data from an API.

#### Code Example

```javascript
useEffect(() => {
  // fetchData function and API call inside the useEffect
}, [currentPage, pageSize]);
```



#### 1. **Purpose of `useEffect`**
- `useEffect` allows you to run side effects in your components.
- In this example, the side effect is **fetching data from an API**.

#### 2. **Arguments of `useEffect`**
The `useEffect` hook takes **two arguments**:
1. **Callback Function**:
   - Contains the logic for the side effect. 
   - For example, the API fetching logic would go inside this callback.
2. **Dependency Array**:
   - Specifies when the effect should re-run.
   - In this case, the dependency array is `[currentPage, pageSize]`.
   - **Effect Behavior**: 
     - The effect will run whenever either `currentPage` or `pageSize` changes.

#### 3. **When Does `useEffect` Run?**
- **Initial Render**: The `useEffect` runs after the first render.
- **Dependency Changes**: It re-runs whenever a value in the dependency array changes.
- **No Dependencies**: If the array is empty (`[]`), the effect runs only once, after the component mounts.

#### API Response: Employee Data

This document explains the structure and details of the API response for fetching employee data.

```

#### Sample JSON Response

```json
{
    "content": [
        {
            "id": 5,
            "contact": 9244055548,
            "email": null,
            "joinDate": "2024-06-10",
            "designation": "HR Consultant",
            "jobRole": "Recruiters",
            "department": "IT ",
            "reportingManger": "Nisha Singh",
            "resume": null,
            "status": "Active",
            "name": "Arshad Attar R"
        },
        {
            "id": 15,
            "contact": 0,
            "email": null,
            "joinDate": "",
            "designation": "",
            "jobRole": "",
            "department": "",
            "reportingManger": "",
            "resume": null,
            "status": "",
            "name": ""
        },
        {
            "id": 16,
            "contact": 0,
            "email": null,
            "joinDate": "NA",
            "designation": "Recruiter",
            "jobRole": "NA",
            "department": "NA",
            "reportingManger": "NA",
            "resume": null,
            "status": "NA",
            "name": "r1"
        },
        {
            "id": 17,
            "contact": 0,
            "email": null,
            "joinDate": "NA",
            "designation": "Recruiter",
            "jobRole": "NA",
            "department": "NA",
            "reportingManger": "NA",
            "resume": null,
            "status": "NA",
            "name": "r2"
        },
        {
            "id": 18,
            "contact": 0,
            "email": null,
            "joinDate": "NA",
            "designation": "Recruiter",
            "jobRole": "NA",
            "department": "NA",
            "reportingManger": "NA",
            "resume": null,
            "status": "NA",
            "name": "r3"
        }
    ],
    "pageable": {
        "pageNumber": 0,
        "pageSize": 5,
        "sort": {
            "sorted": false,
            "empty": true,
            "unsorted": true
        },
        "offset": 0,
        "paged": true,
        "unpaged": false
    },
    "totalPages": 22,
    "totalElements": 106,
    "last": false,
    "size": 5,
    "number": 0,
    "sort": {
        "sorted": false,
        "empty": true,
        "unsorted": true
    },
    "numberOfElements": 5,
    "first": true,
    "empty": false
}
```

---

###  Back-End Code flow

#### 3.1. Add Employee

#### **Main class code:**
```java
package _7.project1;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class Application {

	public static void main(String[] args) {
		SpringApplication.run(Application.class, args);
	}

}
```
#### **Explantion of code:**
#### Spring Boot Application: `Application.java`

This is the main entry point of a Spring Boot application. Let's break it down:

#### 1. **`@SpringBootApplication` Annotation:**
   - **`@SpringBootApplication`** is a convenience annotation that combines the following:
     - **`@EnableAutoConfiguration`**: Tells Spring Boot to automatically configure your application based on the dependencies in the classpath.
     - **`@ComponentScan`**: Enables component scanning, so Spring can detect and register your beans (such as controllers, services, repositories, etc.) in the application context.
     - **`@Configuration`**: Indicates that this class contains Spring configuration (i.e., bean definitions).
   
   This annotation is typically placed on the main class of a Spring Boot application, as it kick-starts the auto-configuration and sets up the application context.

#### 2. **`public class Application`:**
   - This is the main class of the application. It's typically named `Application` or something similar, and it serves as the entry point for running the Spring Boot application.

#### 3. **`public static void main(String[] args)`:**
   - This is the main method that runs when the application starts.
   - **`String[] args`** allows command-line arguments to be passed when starting the application. These arguments are passed to `SpringApplication.run(...)`.
   
#### 4. **`SpringApplication.run(Application.class, args)`:**
   - **`SpringApplication.run(Application.class, args)`** is a method that launches the Spring Boot application.
     - **`Application.class`**: Refers to the class that contains the `@SpringBootApplication` annotation. It's the starting point of the Spring context.
     - **`args`**: These are the command-line arguments passed to the application.

   This method will initialize the Spring context and all the beans defined in the application, start the embedded web server (like Tomcat, Jetty, etc.), and handle HTTP requests (if your application is a web application). After calling this, the application starts running.

#### In Summary:
- **`@SpringBootApplication`** configures the Spring Boot application.
- **`main()` method** is the entry point for the Java application.
- **`SpringApplication.run()`** starts the Spring Boot application and the embedded web server.

This structure is standard for a Spring Boot application, and it's often referred to as the **"Spring Boot Bootstrap"** because it initializes the Spring context and enables all auto-configured components.

---

#### **Entity Class code:**
```java
package _7.project1.Entity;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.NoArgsConstructor;

@Entity
@NoArgsConstructor
@AllArgsConstructor
@Getter
@Setter
@Table(name = "employee", uniqueConstraints = {@UniqueConstraint(columnNames = "user_name")})
public class Employee {

    @Id
    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "employee_seq_generator")
    @SequenceGenerator(name = "employee_seq_generator", sequenceName = "employee_seq",
                 allocationSize = 1)
    @Column(name = "emp_id")
    private Long employee_Id;

    @Column(name = "employee_name")
    private String employeeName;

    @Column(name = "user_name", unique = true, nullable = false)
    private String userName;

    @Column(name = "date_of_joining")
    private String dateOfJoining;

    @Column(name = "designation")
    private String designation;

    @Column(name = "department")
    private String department;

    @Column(name = "official_mail")
    private String officialMail;

    @Column(name = "employee_email")
    private String employeeEmail;

    @Column(name = "official_contact_no")
    private long officialContactNumber;

    @Column(name = "alternate_contact_no")
    private long alternateContactNo;

    @Column(name = "date_of_birth")
    private String dateOfBirth;

    @Column(name = "gender")
    private String gender;

    @Column(name = "company_mobile_number")
    private long companyMobileNumber;

    @Column(name = "whats_App_number")
    private long whatsAppNumber;

    @Column(name = "emergency_contact_number")
    private String emergencyContactNumber;

    @Column(name = "emergency_person_relation")
    private String emergencyPersonRelation;

    @Column(name = "employee_present_address")
    private String employeePresentAddress;

    @Column(name = "employee_experience")
    private String employeeExperience;

    @Column(name = "perks")
    private String perks;

    @Column(name = "marital_status")
    private String maritalStatus;

    @Column(name = "anniversary_date")
    private String anniversaryDate;

    @Column(name = "t_shirt_size")
    private String tshirtSize;

    @Column(name = "last_company")
    private String lastCompany;

    @Column(name = "work_location")
    private String workLocation;

    @Column(name = "entry_source")
    private String entrySource;

    @Column(name = "employee_status")
    private String employeeStatus;

    @Column(name = "last_working_date")
    private String lastWorkingDate;

    @Column(name = "reason_for_leaving")
    private String reasonForLeaving;

    @Column(name = "induction_yes_or_no")
    private String inductionYesOrNo;

    @Column(name = "induction_comment")
    private String inductionComment;

    @Column(name = "training_source")
    private String trainingSource;

    @Column(name = "training_completed_yes_or_no")
    private String trainingCompletedYesOrNo;

    @Column(name = "training_taken_count")
    private int trainingTakenCount;

    @Column(name = "rounds_of_interview")
    private String roundsOfInterview;

    @Column(name = "interview_taken_person")
    private String interviewTakenPerson;

    @Column(name = "warning_comments")
    private String warningComments;

    @Column(name = "performance_indicator")
    private String performanceIndicator;

    @Column(name = "team_leader_msg")
    private String teamLeaderMsg;

    @Column(name = "edit_delete_authority")
    private String editDeleteAuthority;

    @Column(name = "linked_inurl")
    private String linkedInURl;

    @Column(name = "face_bookurl")
    private String faceBookURL;

    @Column(name = "twitterurl")
    private String twitterURl;

    @Column(name = "employee_address")
    private String employeeAddress;

    @Column(name = "blood_group")
    private String bloodGroup;

    @Column(name = "aadhaar_no")
    private long aadhaarNo;

    @Column(name = "pan_no")
    private String panNo;

    @Column(name = "educational_qualification")
    private String educationalQualification;

    @Column(name = "offered_salary")
    private double offeredSalary;

    @Column(name = "job_role")
    private String jobRole;

    @Column(name = "professional_pt_no")
    private long professionalPtNo;

    @Column(name = "es_ic_no")
    private long esIcNo;

    @Column(name = "pf_no")
    private long pfNo;

    private long insuranceNumber;
    private String reportingMangerName;
    private String reportingMangerDesignation;

    @Column(name = "employee_password")
    private String employeePassword;

    @Column(name = "confirm_password")
    private String confirmPassword;

    @Lob
    @Column(columnDefinition = "LONGBLOB", name = "profile_image")
    private byte[] profileImage;

    @Lob
    @Column(columnDefinition = "LONGBLOB", name = "document")
    private byte[] document;

    @Lob
    @Column(columnDefinition = "LONGBLOB", name = "resume_file")
    private byte[] resumeFile;

    private int oldTeamLeaderId;

    @Column(name = "login_status")
    private String loginStatus;

    
}

```
#### **Explanation of code:**
#### Employee Entity Class (JPA Model)

This Java class represents an **Employee** entity in a database using **JPA (Java Persistence API)**. It is annotated with **Jakarta Persistence** annotations and **Lombok** annotations to simplify the code.

#### 1. Annotations:
- **`@Entity`**: Marks the class as a JPA entity, indicating that it will map to a table in the database.
- **`@Table(name = "employee", uniqueConstraints = {@UniqueConstraint(columnNames = "user_name")})`**: Specifies the name of the table (`employee`) and enforces a unique constraint on the `user_name` column.
- **`@Id`**: Denotes that the `employee_Id` field is the primary key of the entity.
- **`@GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "employee_seq_generator")`**: Specifies how the `employee_Id` value will be generated, using a sequence generator defined by `@SequenceGenerator`.
- **`@SequenceGenerator(name = "employee_seq_generator", sequenceName = "employee_seq", allocationSize = 1)`**: Defines the sequence generator used to generate primary key values.
- **`@Column`**: Maps the class fields to corresponding columns in the database table. It allows specifying additional constraints like `nullable`, `unique`, etc.
- **`@Lob`**: Indicates that the field should be stored as a large object (binary data like files or large text). This is used for `profile_image`, `document`, and `resume_file`.

#### 2. Fields (Attributes):
The class has numerous fields, each representing a piece of information about an employee. The fields have various data types like `String`, `long`, `double`, and `byte[]` (for storing large binary objects). Here’s an overview of what each field represents:

- **Basic Info**: `employee_Id`, `employeeName`, `userName`, `dateOfJoining`, `dateOfBirth`, `gender`, `maritalStatus`, etc.
- **Contact Info**: `officialMail`, `employeeEmail`, `officialContactNumber`, `companyMobileNumber`, `whatsAppNumber`, etc.
- **Job Details**: `designation`, `department`, `lastCompany`, `workLocation`, `jobRole`, `offeredSalary`, etc.
- **Personal Info**: `bloodGroup`, `aadhaarNo`, `panNo`, `employeeAddress`, etc.
- **Emergency Info**: `emergencyContactNumber`, `emergencyPersonRelation`, etc.
- **Miscellaneous**: `perks`, `employeeStatus`, `inductionYesOrNo`, `performanceIndicator`, etc.
- **Social Media/Links**: `linkedInURl`, `faceBookURL`, `twitterURl`.
- **Documents**: `profileImage`, `document`, `resumeFile` (stored as large binary objects using `@Lob`).

#### 3. Lombok Annotations:
- **`@NoArgsConstructor`**: Automatically generates a no-argument constructor for the class. This is required by JPA for creating instances.
- **`@AllArgsConstructor`**: Generates a constructor with parameters for all fields in the class. This allows creating objects with all properties at once.

#### 4. Other Attributes:
- **Profile Image/Document/Resume**: These are stored as binary data (`byte[]`), and **`@Lob`** is used to indicate that they are large objects (e.g., images, PDFs).
- **Login and Authority**: Fields like `loginStatus` and `editDeleteAuthority` control permissions and the user’s login status.
- **Miscellaneous Fields**: Fields like `inductionComment`, `performanceIndicator`, and `teamLeaderMsg` are likely used to store feedback or comments related to the employee’s performance or other work-related aspects.

#### 5. Methods:
The class includes **getters and setters** for all fields. These methods are generated manually, but **Lombok** annotations (`@NoArgsConstructor` and `@AllArgsConstructor`) help reduce boilerplate code for constructors.

#### Summary of What's Happening:
- The **Employee** class represents an entity in a relational database, capturing various details about an employee (personal, contact, job-related, etc.).
- **JPA annotations** are used to map the class to a table and define column mappings, constraints (like primary key generation and unique constraints).
- **Lombok annotations** reduce boilerplate code by automatically generating constructors.
- The class handles **binary data** (like profile images and documents) using `@Lob`, indicating these fields store large binary objects.
- The class facilitates interaction with a database by storing employee details, possibly using **EntityManager** or **JpaRepository** for persistence operations.

---

#### **Repository code:**
```java
package _7.project1.Repository;

import _7.project1.Entity.Employee;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.stereotype.Repository;
import java.util.Optional;

@Repository
public interface EmployeeRepository extends JpaRepository<Employee, Long> {
    Optional<Employee> findByUserName(String username);
    Optional<Employee> findById(Long id);
}
```
#### **Explanation of code:**
#### Spring Boot Application: `Application.java`

This is the main entry point of a Spring Boot application. Let's break it down:

#### 1. **`@SpringBootApplication` Annotation:**
   - **`@SpringBootApplication`** is a convenience annotation that combines the following:
     - **`@EnableAutoConfiguration`**: Tells Spring Boot to automatically configure your application based on the dependencies in the classpath.
     - **`@ComponentScan`**: Enables component scanning, so Spring can detect and register your beans (such as controllers, services, repositories, etc.) in the application context.
     - **`@Configuration`**: Indicates that this class contains Spring configuration (i.e., bean definitions).
   
   This annotation is typically placed on the main class of a Spring Boot application, as it kick-starts the auto-configuration and sets up the application context.

#### 2. **`public class Application`:**
   - This is the main class of the application. It's typically named `Application` or something similar, and it serves as the entry point for running the Spring Boot application.

#### 3. **`public static void main(String[] args)`:**
   - This is the main method that runs when the application starts.
   - **`String[] args`** allows command-line arguments to be passed when starting the application. These arguments are passed to `SpringApplication.run(...)`.
   
#### 4. **`SpringApplication.run(Application.class, args)`:**
   - **`SpringApplication.run(Application.class, args)`** is a method that launches the Spring Boot application.
     - **`Application.class`**: Refers to the class that contains the `@SpringBootApplication` annotation. It's the starting point of the Spring context.
     - **`args`**: These are the command-line arguments passed to the application.

   This method will initialize the Spring context and all the beans defined in the application, start the embedded web server (like Tomcat, Jetty, etc.), and handle HTTP requests (if your application is a web application). After calling this, the application starts running.

#### In Summary:
- **`@SpringBootApplication`** configures the Spring Boot application.
- **`main()` method** is the entry point for the Java application.
- **`SpringApplication.run()`** starts the Spring Boot application and the embedded web server.

This structure is standard for a Spring Boot application, and it's often referred to as the **"Spring Boot Bootstrap"** because it initializes the Spring context and enables all auto-configured components.

---

#### **Service Class code:**
```java
package _7.project1.Service;

import _7.project1.Entity.Employee;
import _7.project1.Repository.CallingTrackerRepository;
import _7.project1.Repository.EmployeeRepository;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.Optional;

@Service
public class EmployeeService {

    @Autowired
    private EmployeeRepository employeeRepository;

    @Autowired
    private CallingTrackerRepository callingTrackerRepository;


    public Employee addEmployee(Employee employee){
        Optional<Employee> existingEmployee = employeeRepository.findByUserName(employee.getUserName());
        if (existingEmployee.isPresent()){

            Employee updatedEmployee = existingEmployee.get();
            updatedEmployee.setEmployeeName(employee.getEmployeeName());
            updatedEmployee.setUserName(employee.getUserName());
            updatedEmployee.setDateOfBirth(employee.getDateOfBirth());
            updatedEmployee.setDateOfJoining(employee.getDateOfJoining());
            updatedEmployee.setDesignation(employee.getDesignation());
            updatedEmployee.setDepartment(employee.getDepartment());
            updatedEmployee.setOfficialMail(employee.getOfficialMail());
            updatedEmployee.setEmployeeEmail(employee.getEmployeeEmail());
            updatedEmployee.setOfficialContactNumber(employee.getOfficialContactNumber());
            updatedEmployee.setAlternateContactNo(employee.getAlternateContactNo());
            updatedEmployee.setGender(employee.getGender());
            updatedEmployee.setCompanyMobileNumber(employee.getCompanyMobileNumber());
            updatedEmployee.setWhatsAppNumber(employee.getWhatsAppNumber());
            updatedEmployee.setEmergencyContactNumber(employee.getEmergencyContactNumber());
            updatedEmployee.setEmergencyPersonRelation(employee.getEmergencyPersonRelation());
            updatedEmployee.setEmployeePresentAddress(employee.getEmployeePresentAddress());
            updatedEmployee.setEmployeeExperience(employee.getEmployeeExperience());
            updatedEmployee.setPerks(employee.getPerks());
            updatedEmployee.setMaritalStatus(employee.getMaritalStatus());
            updatedEmployee.setAnniversaryDate(employee.getAnniversaryDate());
            updatedEmployee.setTshirtSize(employee.getTshirtSize());
            updatedEmployee.setLastCompany(employee.getLastCompany());
            updatedEmployee.setWorkLocation(employee.getWorkLocation());
            updatedEmployee.setEntrySource(employee.getEntrySource());
            updatedEmployee.setEmployeeStatus(employee.getEmployeeStatus());
            updatedEmployee.setLastWorkingDate(employee.getLastWorkingDate());
            updatedEmployee.setReasonForLeaving(employee.getReasonForLeaving());
            updatedEmployee.setInductionYesOrNo(employee.getInductionYesOrNo());
            updatedEmployee.setInductionComment(employee.getInductionComment());
            updatedEmployee.setTrainingSource(employee.getTrainingSource());
            updatedEmployee.setTrainingCompletedYesOrNo(employee.getTrainingCompletedYesOrNo());
            updatedEmployee.setTrainingTakenCount(employee.getTrainingTakenCount());
            updatedEmployee.setRoundsOfInterview(employee.getRoundsOfInterview());
            updatedEmployee.setInterviewTakenPerson(employee.getInterviewTakenPerson());
            updatedEmployee.setWarningComments(employee.getWarningComments());
            updatedEmployee.setPerformanceIndicator(employee.getPerformanceIndicator());
            updatedEmployee.setTeamLeaderMsg(employee.getTeamLeaderMsg());
            updatedEmployee.setEditDeleteAuthority(employee.getEditDeleteAuthority());
            updatedEmployee.setLinkedInURl(employee.getLinkedInURl());
            updatedEmployee.setFaceBookURL(employee.getFaceBookURL());
            updatedEmployee.setTwitterURl(employee.getTwitterURl());
            updatedEmployee.setEmployeeAddress(employee.getEmployeeAddress());
            updatedEmployee.setBloodGroup(employee.getBloodGroup());
            updatedEmployee.setAadhaarNo(employee.getAadhaarNo());
            updatedEmployee.setPanNo(employee.getPanNo());
            updatedEmployee.setEducationalQualification(employee.getEducationalQualification());
            updatedEmployee.setOfferedSalary(employee.getOfferedSalary());
            updatedEmployee.setJobRole(employee.getJobRole());
            updatedEmployee.setProfessionalPtNo(employee.getProfessionalPtNo());
            updatedEmployee.setEsIcNo(employee.getEsIcNo());
            updatedEmployee.setPfNo(employee.getPfNo());
            updatedEmployee.setInsuranceNumber(employee.getInsuranceNumber());
            updatedEmployee.setReportingMangerName(employee.getReportingMangerName());
            updatedEmployee.setReportingMangerDesignation(employee.getReportingMangerDesignation());
            updatedEmployee.setEmployeePassword(employee.getEmployeePassword());
            updatedEmployee.setConfirmPassword(employee.getConfirmPassword());
            updatedEmployee.setProfileImage(employee.getProfileImage());
            updatedEmployee.setDocument(employee.getDocument());
            updatedEmployee.setResumeFile(employee.getResumeFile());
            updatedEmployee.setOldTeamLeaderId(employee.getOldTeamLeaderId());
            updatedEmployee.setLoginStatus(employee.getLoginStatus());

            return employeeRepository.save(updatedEmployee);
        } else {
            return employeeRepository.save(employee);
        }
    }

// Get an Employee by ID
    public Optional<Employee> getEmployeeById(Long empId) {
        return employeeRepository.findById(empId);
    }

// Get All Employees
    public Iterable<Employee> getAllEmployees() {
        return employeeRepository.findAll();
    }

// Delete an Employee by ID
    public void deleteEmployee(Long empId) {
        employeeRepository.deleteById(empId);
    }

    public Optional<Employee> getEmployeeByUserName(String username){
        return employeeRepository.findByUserName(username);
    }
}

```

#### **Explanation of code:**
#### EmployeeService Class

This code defines the `EmployeeService` class, which is part of a Spring Boot application. The purpose of this service is to manage `Employee` entities in the system. It handles adding and updating employee information and interacts with two repositories: `EmployeeRepository` (for managing employee data) and `CallingTrackerRepository` (although the latter is not used in this code).

#### 1. Annotations

#### `@Service`
- **Purpose**: This annotation marks the class as a service component in Spring's service layer.
- **Functionality**: By annotating the `EmployeeService` class with `@Service`, Spring will automatically register it as a Spring Bean in the application context, meaning it will be automatically managed by Spring's Dependency Injection (DI) container.

#### `@Autowired`
- **Purpose**: The `@Autowired` annotation is used to automatically inject dependencies.
- **Functionality**: In this case, Spring will automatically provide instances of the `EmployeeRepository` and `CallingTrackerRepository` beans into the `EmployeeService` class. These repositories will be used to interact with the database.

#### 2. Instance Variables

#### `private EmployeeRepository employeeRepository`
- **Purpose**: This is the repository interface for `Employee` entities. `EmployeeRepository` extends `JpaRepository`, so it provides basic CRUD operations such as `save()`, `findById()`, and `findByUserName()` out of the box, without the need to write custom SQL queries.

#### `private CallingTrackerRepository callingTrackerRepository`
- **Purpose**: This is another repository that is injected, but it is not used in the current code. It might be useful for future features that track calls or actions related to employees (e.g., tracking communication or interactions).

#### 3. The `addEmployee` Method

This is the primary method in the service. It either updates an existing employee or adds a new one based on whether an employee with the given username already exists.

#### Method Signature:
```java
public Employee addEmployee(Employee employee)

```
#### Purpose:
This method takes an Employee object as input and returns the saved Employee object. It handles both creating new employees and updating existing ones.

#### Logic:
#### Step 1. **Check if the Employee Already Exists:**
```java
Optional<Employee> existingEmployee = employeeRepository.findByUserName(employee.getUserName());

```
This line checks if an employee with the same `userName` already exists in the database by calling the `findByUserName` method in the `EmployeeRepository`. This method returns an `Optional<Employee>`, which may contain an `Employee` if one is found, or be empty if no employee with the provided username exists.

#### Step 2: If Employee Exists, Update Their Details
```java
if (existingEmployee.isPresent()) {
    Employee updatedEmployee = existingEmployee.get();
    // Set all employee fields from the incoming employee object
    updatedEmployee.setEmployeeName(employee.getEmployeeName());
    updatedEmployee.setUserName(employee.getUserName());
    // ... (set all other fields)
    return employeeRepository.save(updatedEmployee);
}

```
If an employee with the given username exists, we retrieve the existing employee (`existingEmployee.get()`).  
Then, we update each field of the existing employee using the values from the `employee` object passed to the method. This allows us to modify specific details (like name, email, designation, etc.) without replacing the entire record.  
After updating all fields, the method saves the updated employee back into the database using `employeeRepository.save(updatedEmployee)`. This persists the changes to the database.

#### Step 3: If Employee Does Not Exist, Save as a New Employee
```java
else {
    return employeeRepository.save(employee);
}

```
If no existing employee is found (i.e., the `existingEmployee` is empty), this block of code is executed. In this case, the method directly saves the new `Employee` object to the database using `employeeRepository.save(employee)`.

The `save()` method is provided by `JpaRepository` and performs the persistence operation, either inserting a new record or updating an existing one depending on the state of the `Employee` entity.

#### step 4: Get Employee By ID
```java
public Optional<Employee> getEmployeeById(Long empId) {
    return employeeRepository.findById(empId);
}
```
This method allows you to retrieve an employee by their employee ID (empId).
employeeRepository.findById(empId) returns an Optional<Employee>, which will contain the employee data if found, or be empty if no employee exists with that ID.

#### step 5:Get All Employees
```java
public Iterable<Employee> getAllEmployees() {
    return employeeRepository.findAll();
}

```
This method retrieves all the employees in the database.
employeeRepository.findAll() returns an Iterable of Employee objects, representing all the records in the Employee table.

#### step 6: Delete Employee By ID
```java
public void deleteEmployee(Long empId) {
    employeeRepository.deleteById(empId);
}

```
This method deletes an employee by their ID.
employeeRepository.deleteById(empId) deletes the employee record with the given empId from the database.

#### step 7: The getEmployeeByUserName Method:
```java
public Optional<Employee> getEmployeeByUserName(String username)

```   
#### Purpose:
This method retrieves an `Employee` from the database by their username.  
It uses the `findByUserName` method in the `EmployeeRepository` to fetch the employee. The return type is an `Optional<Employee>`, which is a safe way of handling potential null values. If no employee with the provided username exists, it returns `Optional.empty()`.

#### **Key Points:**

#### 1. **Repository Layer**:  
The `EmployeeRepository` is a Spring Data JPA repository that provides methods like `findByUserName()` and `save()`. These methods allow the `EmployeeService` to interact with the database without the need to write custom SQL queries. The repository handles data access and provides an abstraction over the underlying database operations.

#### 2. **Updating an Employee**:  
The `addEmployee` method offers a detailed approach to updating an employee’s record. Instead of replacing the entire employee entity, it updates individual fields of the existing employee. This approach provides more control, as it allows you to update specific fields while leaving other fields unchanged. It prevents overwriting unnecessary data and ensures only relevant changes are made.

#### 3. **Use of Optional**:  
The `Optional<Employee>` return type from methods like `findByUserName` is a good practice because it helps avoid potential `NullPointerExceptions`. By using `Optional`, the code forces the caller to explicitly handle the case where the employee might not exist. For example, the caller must check if the `Optional` contains a value using methods like `isPresent()` before accessing the actual employee data.

#### 4. **The Role of CallingTrackerRepository**:  
Although `CallingTrackerRepository` is injected into the `EmployeeService`, it is not used within the current method. This repository might serve another purpose in the application, such as tracking employee-related calls, actions, or interactions elsewhere in the codebase. This is a placeholder for potential future use or another area of the application that deals with employee call tracking.

#### 5. **Spring's Dependency Injection**:  
The `@Autowired` annotations are used to indicate that Spring will automatically inject dependencies into the `EmployeeService` class. In this case, Spring manages the lifecycle of `EmployeeRepository` and `CallingTrackerRepository`. The framework automatically wires these repositories into the service class, ensuring that the service can use them to interact with the database without manual setup.

#### 6. **Get Employee by ID**:  
The `getEmployeeById` method retrieves an employee using their unique **employee ID**. It calls `employeeRepository.findById(empId)`, which returns an `Optional<Employee>`. The use of `Optional` ensures that the method handles the possibility of the employee not being found in the database, preventing null pointer exceptions. The caller must check if the `Optional` contains an employee before attempting to access the data.

#### 7. **Get All Employees**:  
The `getAllEmployees` method fetches all employees from the database. It uses `employeeRepository.findAll()`, which returns all employee records stored in the database as an iterable collection. This method provides a way to access every employee in the system.

#### 8. **Delete Employee by ID**:  
The `deleteEmployee` method allows the deletion of an employee based on their unique **employee ID**. It calls `employeeRepository.deleteById(empId)` to remove the corresponding record from the database. This operation ensures that the employee's data is permanently removed from the system.


#### Summary:

- The `EmployeeService` class is a Spring service component that handles the logic for adding or updating employee records.
- The `addEmployee` method checks whether an employee with a specific username exists and either updates the existing record or creates a new one.
- The getEmployeeByUserName method allows fetching an employee by their username.
- The getEmployeeById method fetches an employee by their ID.
- The getAllEmployees method retrieves all employees stored in the database.
- The deleteEmployee method deletes an employee record by their ID.
- The `getEmployeeByUserName` method allows fetching an employee by their username.
- This class acts as an intermediary between the controller layer (which handles HTTP requests) and the repository layer (which interacts with the database).

---

#### **Controller Class code:**
```java
package _7.project1.Controller;

import _7.project1.Dto.CallingTrackerLineUpDto;
import _7.project1.Entity.Employee;
import _7.project1.Service.CallingTrackerService;
import _7.project1.Service.EmployeeService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import java.time.LocalDate;

@RestController
@RequestMapping("/api/employee")
public class EmployeeController {

    @Autowired
    private EmployeeService employeeService;

    @Autowired
    private CallingTrackerService callingTrackerService;

    @PostMapping("/add")
    public ResponseEntity<Employee> addEmployee( @RequestBody Employee employee){
        try{
            return new ResponseEntity<>(employeeService.addEmployee(employee), HttpStatus.OK);

        }catch (RuntimeException e){
            return new ResponseEntity<>(null, HttpStatus.BAD_REQUEST);
        }
    }

   / Get an Employee by ID
    @GetMapping("/{empId}")
    public Optional<Employee> getEmployee(@PathVariable Long empId) {
        return employeeService.getEmployeeById(empId);
    }

 // Get All Employees
    @GetMapping
    public Iterable<Employee> getAllEmployees() {
        return employeeService.getAllEmployees();
    }

    // Delete an Employee by ID
    @DeleteMapping("/{empId}")
    public void deleteEmployee(@PathVariable Long empId) {
        employeeService.deleteEmployee(empId);
    }

 // Update an Employee by ID
    @PutMapping("/{empId}")
    public Employee updateEmployee(@PathVariable Long empId, @RequestBody Employee employeeDetails) {
        Optional<Employee> optionalEmployee = employeeService.getEmployeeById(empId);

        if (optionalEmployee.isPresent()) {
            Employee existingEmployee = optionalEmployee.get();
            existingEmployee.setName(employeeDetails.getName());
            existingEmployee.setDate(employeeDetails.getDate());
            existingEmployee.setAddress(employeeDetails.getAddress());

            return employeeService.saveEmployee(existingEmployee);
        } else {
            // Return null or throw an exception if employee not found
            return null; // You can handle it as per your requirement
        }
    }
    }
}

```

#### **Explanation of code:**
#### This code defines a Spring Boot `EmployeeController` class that handles HTTP requests related to employee and calling tracker data. It serves as an interface between the frontend (or client) and the service layer, allowing clients to add employees and calling tracker data.

#### Let’s break down the code in detail:

#### Code Breakdown

#### 1. Annotations

- **@RestController**
  - **Purpose**:  
    The `@RestController` annotation is a specialized version of `@Controller`. It is used in Spring MVC to create RESTful web services. It combines `@Controller` and `@ResponseBody`, meaning every method in this controller will return the response body directly, typically in JSON or XML format.
  - **Functionality**:  
    This class is a controller in a REST API, and the return values of methods will automatically be converted to HTTP responses (e.g., JSON).
  
- **@RequestMapping("/api/employee")**
  - **Purpose**:  
    The `@RequestMapping` annotation is used to map HTTP requests to handler methods of MVC and REST controllers. In this case, the base URL for all routes in this controller is `/api/employee`.
  - **Functionality**:  
    All endpoints in this controller will be prefixed with `/api/employee`.

- **@Autowired**
  - **Purpose**:  
    The `@Autowired` annotation is used for dependency injection in Spring. It automatically injects the necessary service beans into this controller.

- **@PostMapping**
  - **Purpose**:  
    The `@PostMapping` annotation is used to handle HTTP POST requests. It is shorthand for `@RequestMapping(method = RequestMethod.POST)`.
  - **Functionality**:  
    In this case, the controller has two POST methods for adding employees and calling tracker data.

- **@RequestBody**
  - **Purpose**:  
    The `@RequestBody` annotation binds the HTTP request body to a method parameter. In this code, it is used to deserialize the incoming JSON payload into a Java object (`Employee` or `CallingTrackerLineUpDto`).

- **@PathVariable**
  - **Purpose**:  
    The `@PathVariable` annotation is used to bind the value of a URI template variable to a method parameter. In this case, the employee ID is extracted from the URL and passed to the method.

#### 2. Instance Variables

- **private EmployeeService employeeService**
  - **Purpose**:  
    This is the service layer that handles business logic for employee-related operations (e.g., adding and updating employees). It is injected into the controller using `@Autowired`.

- **private CallingTrackerService callingTrackerService**
  - **Purpose**:  
    This is another service layer that handles business logic related to calling tracker operations. It is also injected into the controller using `@Autowired`.

#### 3. Methods

- **addEmployee Method**
```java
@PostMapping("/add")
public ResponseEntity<Employee> addEmployee(@RequestBody Employee employee) {
    try {
        return new ResponseEntity<>(employeeService.addEmployee(employee), HttpStatus.OK);
    } catch (RuntimeException e) {
        return new ResponseEntity<>(null, HttpStatus.BAD_REQUEST);
    }
}

```
#### Purpose:
This method is responsible for adding a new employee to the system. It is mapped to the URL `/api/employee/add`.

#### Request:
The method expects an `Employee` object in the HTTP request body (annotated with `@RequestBody`).

#### Logic:
- The employee data is passed to the `addEmployee` method of the `EmployeeService` class.
- If the employee is successfully added, the method returns a `ResponseEntity` with a `HttpStatus.OK` (200) status and the employee data.
- If any error occurs (e.g., a `RuntimeException`), it returns a `ResponseEntity` with a `HttpStatus.BAD_REQUEST` (400) status.

#### Return:
A `ResponseEntity<Employee>` is returned, containing the employee data and an HTTP status code indicating whether the operation was successful.

#### **`@GetMapping("/{empId}")` Method:** 
```java
@GetMapping("/{empId}")
public Optional<Employee> getEmployee(@PathVariable Long empId) {
    return employeeService.getEmployeeById(empId);
}
```
Certainly! Here's the explanation in Markdown format:

---

#### **Purpose:**
This endpoint is designed to retrieve an employee’s details based on their unique employee ID.

#### **@GetMapping("/{empId}")**:
- This annotation maps HTTP GET requests to the method.
- The `{empId}` part of the path is a path variable that will be substituted with the actual employee ID passed in the request URL.

#### **@PathVariable Long empId**:
- The `empId` parameter gets the value of the employee ID from the URL.

#### **Method**:
- It calls the `employeeService.getEmployeeById(empId)` method to fetch the employee data from the database using the service layer.

#### **Return Type**:
- The method returns an `Optional<Employee>`. This means that if an employee with the provided ID exists, the `Optional` will contain the employee object; if not, the `Optional` will be empty.

#### **(@GetMapping) Method:**
```java
@GetMapping
public Iterable<Employee> getAllEmployees() {
    return employeeService.getAllEmployees();
}

```
Certainly! Here's the explanation in Markdown format:

---

#### **Purpose:**
This endpoint is designed to retrieve a list of all employees from the database.

#### **@GetMapping:**
- The method is mapped to the HTTP GET request for the `/employees` path (i.e., it will be triggered by a GET request without any specific employee ID).

#### **Method:**
- It calls the `employeeService.getAllEmployees()` method, which fetches all employee records from the database.

#### **Return Type:**
- The method returns an `Iterable<Employee>`, which is a collection of all employee records.

####  **(@DeleteMapping("/{empId}")) Method:**
```java
@DeleteMapping("/{empId}")
public void deleteEmployee(@PathVariable Long empId) {
    employeeService.deleteEmployee(empId);
}

```
---

#### **Purpose:**
This endpoint is designed to delete an employee from the database using their employee ID.

#### **@DeleteMapping("/{empId}")**:
- The `@DeleteMapping` annotation maps the HTTP DELETE request to this method.
- The `{empId}` part of the path is a path variable that will be replaced with the actual employee ID passed in the request URL.

#### **@PathVariable Long empId**:
- The `empId` is extracted from the URL and passed into the method to identify the employee to be deleted.

#### **Method:**
- It calls the `employeeService.deleteEmployee(empId)` method to delete the employee record with the specified ID from the database.

#### **Return Type:**
- This method does not return any data; it’s a `void` return type because the primary goal is to delete the employee.

#### **(@PutMapping("/{empId}")) Method:**
```java
@PutMapping("/{empId}")
public Employee updateEmployee(@PathVariable Long empId, @RequestBody Employee employeeDetails) {
    Optional<Employee> optionalEmployee = employeeService.getEmployeeById(empId);

    if (optionalEmployee.isPresent()) {
        Employee existingEmployee = optionalEmployee.get();
        existingEmployee.setName(employeeDetails.getName());
        existingEmployee.setDate(employeeDetails.getDate());
        existingEmployee.setAddress(employeeDetails.getAddress());

        return employeeService.saveEmployee(existingEmployee);
    } else {
        // Return null or throw an exception if employee not found
        return null; // You can handle it as per your requirement
    }
}

```

---

#### **Purpose:**
This endpoint is designed to update an employee’s details by their employee ID. The employee data to be updated is sent in the request body.

#### **@PutMapping("/{empId}")**:
- The `@PutMapping` annotation maps HTTP PUT requests to this method.
- The `{empId}` part of the URL is a path variable that represents the employee's unique ID.

#### **@PathVariable Long empId**:
- This gets the employee ID from the URL to identify the employee that is to be updated.

#### **@RequestBody Employee employeeDetails**:
- The employee data that needs to be updated is passed in the request body as a JSON object.
- This annotation binds the incoming JSON data to the `employeeDetails` parameter.

#### **Method:**
1. The method first calls `employeeService.getEmployeeById(empId)` to check if the employee with the provided ID exists.
2. If the employee exists (`optionalEmployee.isPresent()` is true):
   - It retrieves the employee object and updates fields such as `name`, `date`, and `address` based on the `employeeDetails` provided in the request body.
   - After updating the fields, the employee object is saved back to the database using `employeeService.saveEmployee(existingEmployee)`.
   
#### **Return Type:**
- The method returns the updated `Employee` object, which will be sent back to the client as a response.

#### **Handling Non-Existent Employee:**
- If the employee with the provided ID doesn't exist (`optionalEmployee.isPresent()` is false), the method will return `null`.
- You can modify this behavior to throw a specific exception (such as `EmployeeNotFoundException`) or handle it differently based on your requirements.

#### 4. Exception Handling
- In the `addEmployee` method, if a `RuntimeException` occurs while adding the employee, it is caught in the catch block, and a response with `HttpStatus.BAD_REQUEST` (400) is returned. This is basic error handling to inform the client that there was an issue with the request.

---

---

#### **Summary of Endpoints**

#### **1. GET /api/employee/{empId}** - Get an Employee by ID

- **Purpose**: This endpoint is designed to retrieve an employee’s details based on their unique employee ID.
- **Request**: The `empId` is passed as a path variable in the URL.
- **Logic**: 
  - It calls the `getEmployeeById(empId)` method in the `EmployeeService` to fetch the employee data from the database.
  - Returns an `Optional<Employee>`, which will contain the employee data if found, or be empty if no employee exists with that ID.
  
---

#### **2. GET /api/employee** - Get All Employees

- **Purpose**: This endpoint is designed to retrieve a list of all employees from the database.
- **Request**: This is a simple GET request without any path variables.
- **Logic**: 
  - It calls the `getAllEmployees()` method in the `EmployeeService` to fetch all employee records.
  - Returns an `Iterable<Employee>`, which represents a collection of all employee records in the database.

---

#### **3. DELETE /api/employee/{empId}** - Delete an Employee by ID

- **Purpose**: This endpoint is designed to delete an employee from the database using their employee ID.
- **Request**: The `empId` is passed as a path variable in the URL.
- **Logic**: 
  - It calls the `deleteEmployee(empId)` method in the `EmployeeService` to delete the employee with the given ID from the database.
  - This method does not return any data (void method) since the operation is simply to delete the employee.

---

#### **4. PUT /api/employee/{empId}** - Update an Employee by ID

- **Purpose**: This endpoint is designed to update an employee’s details by their employee ID. The employee data to be updated is sent in the request body.
- **Request**: 
  - The `empId` is passed as a path variable to identify the employee.
  - The updated employee data is provided in the request body (`@RequestBody Employee employeeDetails`).
  
- **Logic**:
  - It first checks if the employee with the given `empId` exists using the `getEmployeeById(empId)` method.
  - If the employee exists, it updates the relevant fields (like `name`, `date`, `address`, etc.) with the data provided in the request body.
  - The updated employee data is then saved back to the database using the `saveEmployee(existingEmployee)` method.
  - If the employee does not exist, the method returns `null` (you can handle it with custom error handling or exceptions if needed).

---

#### **Key Points:**

1. **@GetMapping, @PutMapping, @DeleteMapping**:
   - These annotations are used to map HTTP methods (GET, PUT, DELETE) to Java methods in the controller.
   - They allow the API to handle different types of requests like retrieving data, updating records, and deleting resources.

2. **Path Variables (@PathVariable)**:
   - The `@PathVariable` annotation allows extracting values from the URL path.
   - For example, `{empId}` in the URL is captured and passed as a method parameter to identify a specific employee.

3. **Request Body (@RequestBody)**:
   - The `@RequestBody` annotation binds the incoming JSON data to a Java object.
   - In the `PUT` endpoint, the `employeeDetails` object is populated from the request body to update the employee data.

4. **Service Layer Interaction**:
   - The controller communicates with the `EmployeeService` layer for business logic like fetching, updating, or deleting employee records from the database.
   - Methods like `getEmployeeById()`, `getAllEmployees()`, `deleteEmployee()`, and `saveEmployee()` are invoked to interact with the database.

5. **Response Handling**:
   - The controller does not explicitly return HTTP status codes (other than in `POST` methods) but relies on the service methods to perform the necessary operations (CRUD operations).
   - For `GET` requests, the return type is `Optional<Employee>` (for single employee retrieval) or `Iterable<Employee>` (for all employees). For `DELETE` and `PUT`, the methods typically return `void` or a modified employee object.

6. **Optional Return Type**:
   - In the `GET` methods, `Optional<Employee>` is used to handle the case where an employee may not be found, ensuring no `NullPointerExceptions` occur.
   - In the `PUT` method, if the employee does not exist, the method returns `null` (though it can be modified to throw an exception or handle it differently).

7. **Void Return for Delete**:
   - The `DELETE` method returns `void` because the action is completed without returning any data, indicating a successful deletion.

---

### Full-Stack Development flowchart:

![Full Stack development](https://github.com/user-attachments/assets/451a6d7c-9d12-441e-b83f-a2bd8f189ddc)

---

### Database:

#### Recruiters Gear Database Documentation

#### Introduction to the Database:
The **Recruiters Gear** project uses **MySQL** as its database management system to store, manage, and retrieve structured data efficiently. MySQL is a widely adopted relational database that is reliable, robust, and scalable, making it an ideal choice for web applications like Recruiters Gear.

In this project, MySQL is utilized to handle critical data such as:
- Candidate information
- Job details
- Recruitment activity logs
- User authentication data
- Performance metrics and analytics

#### Version of MySQL used in Recruiter's Gear:
This project uses **MySQL version 8.4.3**, the latest stable release as of **October 15, 2024**. MySQL 8.4.3 brings significant performance improvements, enhanced security features, and expanded support for JSON functions, making it a robust and reliable choice for database management in modern applications.

#### Why MySQL is Ideal for This Project:

1. **Open-Source and Cost-Effective**  
   MySQL is open-source, meaning it is free to use and provides all the essential features for database management without licensing costs. It is supported by a large community, ensuring continuous improvements and 
   support.

2. **Compatibility with Spring Boot**  
   MySQL integrates seamlessly with Spring Boot, making database configurations and operations straightforward. Tools like **Spring Data JPA** make it easier to map entities and perform CRUD operations effortlessly.

3. **High Performance**  
   MySQL is optimized for speed and performance, making it a great choice for applications that need to handle large datasets or high traffic. It uses efficient indexing and query execution strategies to ensure fast 
   data retrieval.

4. **Reliability and Data Integrity**  
   MySQL ensures **ACID compliance** (Atomicity, Consistency, Isolation, Durability), which guarantees the reliability of transactions and data integrity in case of system failures.

5. **Scalability**  
   MySQL is designed to handle both small and large-scale applications. It supports **horizontal scaling**, which means it can manage increasing loads by distributing the data across multiple servers.

6. **Wide Ecosystem Support**  
   MySQL has extensive support for tools and platforms, including:
   - GUI tools like **MySQL Workbench** for database design and management.
   - Integration with Cloud providers like **AWS**, **Google Cloud**, and **Azure**.
   - Compatibility with a variety of programming languages.

7. **Security Features**  
   MySQL offers robust security features, including:
   - **User authentication**, **access control**, and **SSL/TLS** (Secure Socket Layer/Transport Layer Security) encryption for data transfer.
   - These features help protect sensitive recruiter and candidate information stored in the database.

8. **Replication and High Availability**  
   MySQL supports **master-slave replication**, ensuring high availability and disaster recovery. This feature is particularly useful for applications that cannot afford downtime.

9. **Query Optimization**  
   MySQL comes with advanced query optimization techniques, such as indexing and caching, to ensure faster execution of complex queries.

10. **Community and Support**  
    MySQL has a massive developer community and excellent documentation, ensuring that support is readily available for troubleshooting and enhancements.

#### How MySQL Excels Compared to Other Databases:

| Features        | MySQL          | Other Databases       |
|-----------------|----------------|----------------|
| Ease of Use     | Simple setup and well-documented.  | Some databases like PostgreSQL may require more configuration.|
| Performance  | High performance for read-heavy applications.  | Slower in some NoSQL or complex use cases (e.g., MongoDB).  |
|Cost  | Open-source with free licensing.  | Some databases (e.g., Oracle) are expensive.  |
| Scalability  | Supports vertical and horizontal scaling.  | May not scale as efficiently in certain cases (e.g., SQLite).  |
| Community Support  | One of the largest open-source communities.  | Limited support for niche databases.  |
|Integration | Works seamlessly with Spring Boot, PHP, etc.  | Some databases might require custom drivers or plugins. |

#### **Key Advantages of MySQL in Recruiters Gear**

- **Speed and Responsiveness**: Ensures quick data retrieval, which is essential for real-time user interactions like job searching or candidate matching.
- **Structured Data Storage**: The relational model of MySQL is perfect for managing recruiter-candidate relationships and job-related information.
- **Ease of Backup and Restoration**: Regular backups are simple with MySQL, ensuring the safety of critical data.
- **Future Scalability**: As Recruiters Gear grows, MySQL's ability to handle more users, more data, and more transactions ensures that it remains a robust choice.

#### MySQL Database Architecture

#### 1) Database Design
- **Schema Overview**: The MySQL database is organized into multiple schemas representing different modules of the application (e.g., users, orders, transactions, products).
- **Tables**: The database consists of relational tables that store structured data for various entities such as users, orders, payments, etc.
- **Normalization**: The database schema is normalized to the Third Normal Form (3NF) to ensure data consistency and minimize redundancy.
- **Indexes**: Indexes are created on frequently queried columns to optimize performance. For example, an index on the `user_id` column in the users table and on the `transaction_date` column in the transactions table.
- **Foreign Keys**: Relationships between tables are established through foreign keys. For example, `order_id` in the `order_items` table is a foreign key that references `orders.order_id`.

#### 2) Entity-Relationship (ER) Diagram
- An ER diagram visually represents the database entities and their relationships.
  - **Entities**: Users, Products, Orders, Payments, etc.
  - **Relationships**: A user can place many orders, each order can have many products, and each order can have many payments.

#### 3) Data Flow
- **Data Insertion**: Data is inserted into the database via application APIs or batch processes. For example, a new user registers through the application and the users table is populated with their details.
- **Data Access Patterns**: Common queries include retrieving a user's order history, fetching payment details, and listing products.
- **Data Transformation**: Data transformations, such as currency conversion for payments or discount calculations for products, occur in the application layer before storing or displaying data.

#### 4) Storage Engine
- **InnoDB Storage Engine**: The primary storage engine for the database is InnoDB, providing full ACID compliance for transactions, foreign key constraints, and row-level locking for concurrent transactions.
- **MyISAM**: For certain tables requiring fast read operations and where transactions are not critical, MyISAM is used.

#### 5) Security
- **Authentication**: Users are authenticated via username and password. Passwords are stored using bcrypt hashing.
- **Authorization**: Role-based access control (RBAC) is applied, ensuring only authorized users can perform specific actions like adding data or querying sensitive tables.
- **Encryption**: SSL/TLS encryption is enforced for secure communication between the database and the application. Sensitive data such as credit card information is encrypted using AES-256.

#### 6) Backup and Recovery
- **Backup Strategy**: The database is backed up every night using `mysqldump` for full backups and `Percona XtraBackup` for incremental backups.
- **Recovery Plan**: In case of failure, backups are restored to the previous day's state, and recovery is monitored through automated tools. Recovery procedures also include rebuilding indexes and re-importing any missing transactional data.

#### 7) Performance Optimization
- **Indexing**: Indexes are applied on frequently queried columns, such as `email` in the users table, `order_date` in the orders table, and `product_id` in the order_items table.
- **Query Caching**: Query caching is enabled for read-heavy operations to reduce database load.
- **Partitioning**: Large tables, such as the orders table, are partitioned by `order_date` to improve query performance and manage data more effectively.
- **Replication**: MySQL master-slave replication is set up for scaling read operations, with the master server handling writes and slave servers handling read queries.

#### 8) Scalability and High Availability
- **Replication**: MySQL replication is used to ensure high availability and distribute read traffic across multiple servers.
- **Sharding**: For very large datasets, horizontal sharding is employed to distribute data across multiple database servers.
- **Clustering**: MySQL Cluster is used to provide automatic failover, ensuring continued service availability during server failure.

#### 9) Monitoring and Logging
- **MySQL Performance Schema**: The MySQL Performance Schema is enabled to collect detailed statistics on queries, events, and database operations to identify slow queries and potential bottlenecks.
- **Error Logs**: The MySQL error log captures critical errors and issues such as crashes or failed transactions.
- **Query Logs**: All database queries are logged for auditing and troubleshooting purposes.
- **Monitoring Tools**: Tools such as **Prometheus** and **Grafana** are used for real-time monitoring of database health and performance metrics.

#### 10) Version Control and Updates
- **Schema Versioning**: Schema changes are tracked using **Liquibase** for version control. This allows smooth transitions between versions and minimizes errors during updates.
- **Update Procedures**: When updating MySQL or applying schema changes, a backup is always taken first, and changes are applied in a staging environment before being pushed to production.

#### 11) Integration with Other Systems
- **APIs**: The MySQL database is integrated with **REST APIs**, allowing other systems to interact with the data (e.g., mobile applications, admin dashboards).
- **Third-party Tools**: The system integrates with reporting tools like **Tableau** and **Power BI** for real-time analytics.

#### **Database Connection Information**

#### 1) Database Host:
- **Host**: `localhost` or the IP address of the server hosting the database.
- **Port**: `3306` (default MySQL port).

#### 2) Connection Credentials:
- **Username**: `your_database_username`.
- **Password**: `your_secure_password`.
- **Database Name**: `your_database_name`.

#### 3) JDBC URL:
- The JDBC URL is the connection string used by the Spring Boot application to connect to the MySQL database.
```java
jdbc:mysql://localhost:3306/your_database_name?useSSL=false&serverTimezone=UTC
```
#### 4) Connection Pooling:
**HikariCP** (default in Spring Boot) is used for database connection pooling.

#### Configuration in `application.properties` or `application.yml`:

```properties
spring.datasource.url=jdbc:mysql://localhost:3306/your_database_name?useSSL=false&serverTimezone=UTC
spring.datasource.username=your_database_user
spring.datasource.password=your_secure_password
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.idle-timeout=30000
spring.datasource.hikari.connection-timeout=30000
```

#### 5) SSL/TLS Configuration:
If SSL is enabled for secure communication, you may need additional parameters.

#### Example:

```properties
spring.datasource.url=jdbc:mysql://localhost:3306/your_database_name?useSSL=true&requireSSL=true
```

#### 6) Database Configuration in `application.properties`:
Here’s an example configuration for connecting to MySQL with Spring Boot:

```properties
spring.datasource.url=jdbc:mysql://localhost:3306/recruiters_gear?useSSL=false&serverTimezone=UTC
spring.datasource.username=root
spring.datasource.password=your_password
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.hibernate.ddl-auto=update
spring.datasource.initialization-mode=always
```

#### 7) Database Connection Testing:
You can test the database connection through a simple test class in Spring Boot:

```java
@SpringBootTest
public class DatabaseConnectionTest {

    @Autowired
    private DataSource dataSource;

    @Test
    public void testConnection() throws SQLException {
        try (Connection connection = dataSource.getConnection()) {
            assertNotNull(connection);
        }
    }
}
```

#### Data Types and Constraints Used in MySQL:

####  Tabular Format (Recommended):
To provide a clear overview of the database schema, a tabular format is used to detail the columns, their data types, constraints, and descriptions for each table in the database. This structure helps developers quickly understand the database design and relationships between tables.

#### Table: `employee`
| Column Name      | Data Type       | Constraints                  | Default Value      | Description                  |
|-------------------|-----------------|------------------------------|--------------------|------------------------------|
| emp_id           | INT             | PRIMARY KEY, AUTO_INCREMENT | -                  | Unique identifier for employees |
| name             | VARCHAR(255)    | NOT NULL                    | -                  | Full name of the employee    |
| date_of_joining  | DATE            | -                           | CURRENT_DATE       | Date when the employee joined |
| address          | TEXT            | -                           | NULL               | Residential address          |
| dept_id          | INT             | FOREIGN KEY (`dept_id`) REFERENCES `department(dept_id)` | - | Links employee to their department |

#### MySQL Query Guidelines:

```sql
-- 1. Create Table
CREATE TABLE employees (
    id INT AUTO_INCREMENT PRIMARY KEY,
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    email VARCHAR(100),
    department VARCHAR(50),
    hire_date DATE
);

-- 2. Insert Data
INSERT INTO employees (first_name, last_name, email, department, hire_date)
VALUES
    ('John', 'Doe', 'john.doe@example.com', 'Engineering', '2023-03-01'),
    ('Jane', 'Smith', 'jane.smith@example.com', 'Marketing', '2022-08-15'),
    ('Mark', 'Johnson', 'mark.johnson@example.com', 'HR', '2021-11-30');

-- 3. Select All Data
SELECT * FROM employees;

-- 4. Select Specific Data
SELECT first_name, last_name, email FROM employees WHERE department = 'Engineering';

-- 5. Update Data
UPDATE employees
SET email = 'john.doe@company.com'
WHERE id = 1;

-- 6. Delete Data
DELETE FROM employees WHERE id = 3;

-- 7. Join Tables
SELECT e.first_name, e.last_name, d.department_name
FROM employees e
JOIN departments d ON e.department = d.department_id;

-- 8. Group By
SELECT department, COUNT(*) AS num_employees
FROM employees
GROUP BY department;

-- 9. Order By
SELECT * FROM employees ORDER BY last_name;

-- 10. Limit Results
SELECT * FROM employees LIMIT 5;

-- 11. Using LIKE
SELECT * FROM employees WHERE first_name LIKE 'J%';

-- 12. Create Index
CREATE INDEX idx_email ON employees(email);

-- 13. Drop Index
DROP INDEX idx_email ON employees;

-- 14. Create View
CREATE VIEW employee_department_view AS
SELECT e.first_name, e.last_name, d.department_name
FROM employees e
JOIN departments d ON e.department = d.department_id;

-- 15. Select from View
SELECT * FROM employee_department_view;

```

---

### Software and Hardware Compatibility 

#### Application Compatibility

This document provides the compatibility requirements for the application in terms of software, hardware, and other key specifications.

---

#### 1. Software Compatibility

The application is **OS independent**, meaning it can be run on any operating system that supports the required software dependencies.

#### Supported Browsers
The application is compatible with the following browsers:
- **Google Chrome**
- **Microsoft Edge**
- **Safari**

> **Note:** The application can be used with any other browser that supports JavaScript, but performance and experience may vary depending on the browser.

---

#### 2. Hardware Compatibility

To ensure optimal performance and smooth usage of the application, the following hardware specifications are recommended:

- **Minimum RAM:** 4 GB
- **Minimum ROM:** 16 GB

---

#### 3. Screen Size Compatibility

This application is designed for **desktop-only** usage. Below is the range of screen sizes that are supported:

- **Minimum Screen Size:** 1366 x 768 pixels
- **Maximum Screen Size:** 3840 x 2160 pixels (4K resolution)

> **Note:** The application has been optimized for various desktop screen resolutions within the specified range.

---

#### 4. Network (Internet) Requirements

For an optimal experience, the following internet connection speed is recommended:

- **Minimum Network Speed:** 10 Mbps

> **Note:** The application may still work with slower speeds, but certain features may not perform as expected or could be slower.

---

#### 5. Colour Compatibility

The application's colour display is dependent on the resolution of your laptop or desktop monitor. It is recommended to use a display that supports at least **16.7 million colours** for the best visual experience.

---

#### Conclusion

To summarize, the application is compatible with desktop devices and does not rely on any specific operating system. It is designed to work with commonly used browsers and requires a stable internet connection and certain hardware specifications for optimal performance.

---

### Comprehensive Solutions

#### Application Purpose Overview

This document outlines the key challenges faced by organizations and the solutions our application offers to resolve these issues. Our application is designed to address critical pain areas such as system performance, integration, user experience, support, cost management, and more.

---

#### 1. System Performance Issues

#### Description:
Clients often face challenges with system speed, responsiveness, and overall performance. These issues can negatively impact user productivity and operational efficiency.

#### Pain Areas:
- **Slow Processing:** Systems may lag or take too long to process requests or data.
- **Downtime:** Frequent outages or unavailability of services disrupt business continuity.
- **Scalability:** Difficulty in scaling systems to meet growing demands or increased loads.

#### Our Solutions:
- **Optimized Code and Infrastructure:** Our application leverages optimized code and efficient infrastructure design to ensure fast processing and high responsiveness.
- **Performance Monitoring Tools:** We integrate performance monitoring tools that allow you to track and address potential issues proactively, minimizing downtime and ensuring smooth operation.
- **Scalable Architecture:** Our cloud-based solution is designed with scalability in mind, making it easy to upgrade resources and accommodate increased workloads without any service disruption.

---

#### 2. Integration Challenges

#### Description:
Organizations often struggle to integrate new technologies with existing systems. Our application is designed to simplify these integrations and eliminate compatibility barriers.

#### Pain Areas:
- **Compatibility Issues:** Ensuring smooth integration between different systems and platforms.
- **Data Silos:** Fragmented data stored across multiple systems, leading to inefficiencies.
- **Complex Integration Processes:** Complex, time-consuming integration processes that delay the adoption of new technologies.

#### Our Solutions:
- **Middleware for Seamless Integration:** Our application offers built-in middleware to facilitate smooth communication between various systems and platforms.
- **Custom Integration Services:** We provide tailored integration services to ensure compatibility with your existing infrastructure and minimize the risk of system conflicts.
- **Data Synchronization Framework:** Our solution ensures consistent data synchronization, helping you break down data silos and improve data integrity across all systems.

---

#### 3. User Experience (UX) Problems

#### Description:
User experience plays a crucial role in system adoption and productivity. We prioritize intuitive design and optimized interfaces in our application to ensure ease of use and satisfaction.

#### Pain Areas:
- **Complex Interfaces:** Difficult-to-navigate or non-intuitive user interfaces hinder user adoption.
- **Lack of Customization:** Systems that do not meet specific user needs or preferences lead to poor engagement.
- **Poor Performance:** Unresponsive or slow user interfaces can lead to frustration.

#### Our Solutions:
- **Intuitive Interface Design:** We conduct extensive user research and usability testing to deliver a clean, easy-to-navigate interface.
- **Customization Options:** Our application allows users to tailor settings and features according to their specific preferences, improving user satisfaction.
- **Optimized UI/UX for Speed:** We focus on providing a seamless experience by optimizing user interfaces for speed, ensuring responsiveness even under heavy use.

---

#### 4. Support and Maintenance

#### Description:
Ongoing support and maintenance are critical for ensuring the continuous availability and reliability of IT systems. Our application is designed with support and easy maintenance in mind.

#### Pain Areas:
- **Inadequate Support:** Delays or inadequate support can lead to operational disruptions.
- **Lack of Documentation:** Poor or outdated documentation can make troubleshooting and system management difficult.
- **High Maintenance Costs:** Expensive or time-consuming maintenance can strain resources.

#### Our Solutions:
- **Comprehensive Support Services:** We offer responsive, multi-channel customer support to resolve issues quickly and minimize downtime.
- **Up-to-date Documentation:** We provide detailed, up-to-date documentation, making it easier for users to understand and manage the system.
- **Cost-Effective Maintenance:** Regular updates and proactive system checks help minimize maintenance costs by ensuring the application runs smoothly without requiring constant attention.

---

#### 5. Cost Management

#### Description:
Organizations often struggle with the cost-effectiveness of IT solutions. Our application provides flexible pricing options and cost-control features to help manage budgets effectively.

#### Pain Areas:
- **High Costs:** Expensive upfront costs and ongoing operational expenses.
- **ROI Concerns:** Uncertainty regarding the return on investment for IT solutions.
- **Unpredictable Expenses:** Unexpected costs due to system failures or upgrades.

#### Our Solutions:
- **Flexible Pricing Models:** We offer subscription-based or pay-as-you-go pricing models to provide flexibility and control over your budget.
- **Transparent Cost-Benefit Analysis:** Our application includes built-in tools that provide clear cost-benefit analyses, helping you assess the ROI and long-term value of the system.
- **Budgeting Tools:** We provide tools to monitor usage and track spending, allowing you to manage costs proactively and avoid unexpected expenses.

---

#### 6. Training and Adoption

#### Description:
Training and adoption of new technologies can be a significant barrier. Our application includes built-in training resources and adoption support to ensure smooth transitions.

#### Pain Areas:
- **Lack of Training:** Insufficient training leads to poor utilization of systems.
- **Resistance to Change:** Employees may be hesitant to adopt new technologies.
- **Implementation Difficulties:** Challenges integrating new technologies into existing workflows.

#### Our Solutions:
- **Comprehensive Training Resources:** We offer detailed user guides, tutorials, and training programs to ensure your team is proficient in using the system.
- **Change Management Support:** We implement strategies to facilitate smooth adoption, addressing resistance and ensuring users are confident in using the new system.
- **Seamless Integration:** Our application is designed for easy integration into existing workflows, ensuring minimal disruption during implementation.

---

#### 7. Customization Needs

#### Description:
Organizations often require custom features or modifications to meet specific needs. Our application is highly customizable to address these requirements efficiently.

#### Pain Areas:
- **Limited Flexibility:** Off-the-shelf solutions may not meet unique business needs.
- **High Customization Costs:** Custom features can be expensive and complex to develop.
- **Long Development Times:** Custom development may take extended periods, delaying implementation.

#### Our Solutions:
- **Highly Customizable Features:** Our application offers a modular design with customizable options to meet specific business requirements.
- **Consulting and Custom Development:** We provide expert consulting services to understand your needs and deliver tailored solutions that fit seamlessly with your business.
- **Agile Development Process:** We employ agile methodologies to expedite the customization process, ensuring that custom features are delivered within your desired timeframe.

---

#### 8. Data Security and Compliance

#### Description:
With increasing concerns about data security and regulatory compliance, we prioritize safeguarding your data and ensuring compliance with industry standards.

#### Pain Areas:
- **Data Breaches:** The risk of unauthorized access to sensitive data.
- **Compliance Issues:** Difficulty in adhering to industry-specific regulations such as GDPR, HIPAA, etc.
- **Inadequate Security Measures:** Weak security protocols or outdated encryption can leave systems vulnerable.

#### Our Solutions:
- **Robust Security Features:** We implement industry-standard security measures such as encryption, multi-factor authentication, and role-based access control to protect your data.
- **Regular Security Updates:** Our application is regularly updated to address vulnerabilities and ensure compliance with the latest security standards.
- **Compliance Consulting:** We offer compliance consulting services to help you meet industry regulations and maintain a secure, compliant environment.

---

#### Conclusion

Our application is built to address the most common IT challenges, providing solutions that improve performance, streamline integration, enhance user experience, and reduce costs. By utilizing our features, you can overcome key pain points and ensure smooth, secure, and efficient system operations.

---

### Subscription
This document outlines the subscription plans, pricing, features, and management of subscriptions for our Applicant Tracking System (ATS) application. Our subscription-based model offers flexibility and scalability to meet the needs of various organizations.

---

#### 1. Overview

Our Applicant Tracking System (ATS) is designed to streamline the recruitment process for companies of all sizes. We offer a flexible subscription model that scales with your organization’s needs. Choose the plan that fits your recruitment requirements and start managing candidates more efficiently today.

---

#### 2. Subscription Plans

We offer three main subscription plans, each catering to different business needs:

#### **Basic Plan**
- **Ideal for:** Small teams or startups with simple hiring needs.
- **Key Features:**
  - Job posting management
  - Basic candidate tracking
  - Interview scheduling
  - Reporting tools
  - 1 User Account
- **Support:** Email support during business hours

#### **Professional Plan**
- **Ideal for:** Growing businesses requiring advanced recruitment tools and more collaboration.
- **Key Features:**
  - All features of the Basic Plan
  - Advanced candidate filtering
  - Team collaboration tools
  - Automated email templates
  - Customizable workflows
  - 5 User Accounts
  - Priority support
- **Support:** Email and live chat support

#### **Enterprise Plan**
- **Ideal for:** Large enterprises with complex hiring needs and integrations.
- **Key Features:**
  - All features of the Professional Plan
  - Unlimited user accounts
  - Advanced analytics and reporting
  - Custom integrations (HRIS, job boards, etc.)
  - Dedicated account manager
  - Priority customer support
- **Support:** 24/7 dedicated support via email, phone, and live chat

---

#### 3. Pricing

Our pricing is designed to be simple and transparent. Below is the breakdown of each plan’s cost:

| Plan               | Monthly Price | Annual Price (Save 20%) |
|--------------------|---------------|-------------------------|
| Basic Plan         | $19/month     | $228/year               |
| Professional Plan  | $49/month     | $588/year               |
| Enterprise Plan    | Custom Pricing| Custom Pricing          |

> **Note:** Prices are subject to change. Discounts and promotions may apply. For custom pricing on the Enterprise Plan, please contact us.

---

#### 4. Subscription Features

Each plan offers a set of core features, but they scale with more advanced functionalities as you move up the tiers. Here's an overview of the key features available in each plan:

- **Job Posting Management:** Manage, publish, and track job postings.
- **Candidate Tracking:** Track candidates through the hiring pipeline with status updates and notes.
- **Interview Scheduling:** Easily schedule and manage interviews with candidates.
- **Team Collaboration:** Share candidate profiles, feedback, and interview notes across your team.
- **Reporting & Analytics:** Gain insights into your recruitment metrics, such as time-to-hire, candidate sources, and more.
- **Customizable Workflows:** Tailor your hiring process to fit your unique business needs.
- **Priority Support:** Faster response times for troubleshooting and inquiries.

---

#### 5. Managing Your Subscription

#### How to Access Subscription Settings
- Log into your ATS account.
- Navigate to the **Settings** tab.
- Select **Subscription** to view your current plan, billing details, and other options.

#### Upgrading/Downgrading Your Plan
To upgrade or downgrade your plan:
- Go to **Subscription** under **Settings**.
- Choose the **Change Plan** option.
- Select your desired plan and confirm the changes.
- If upgrading, the new plan will take effect immediately; if downgrading, the new plan will be applied at the start of the next billing cycle.

---

#### 6. Upgrading/Downgrading Your Plan

- **Upgrading:** If you need more features, you can upgrade your plan at any time. The new plan will take effect immediately, and your next billing will reflect the new plan’s price.
- **Downgrading:** If you no longer need certain features, you can downgrade your plan. Downgrades will take effect at the start of the next billing cycle, and no refunds will be issued for the unused portion of the current billing period.

---

#### 7. Billing and Payment

We offer secure billing and payment through our trusted payment gateway. Here's what you need to know:

#### Payment Methods
We accept the following payment methods:
- Credit/Debit cards (Visa, MasterCard, American Express)
- PayPal
- Bank Transfers (for Enterprise plans)

#### Billing Cycle
You can choose between a **monthly** or **annual** billing cycle. Annual subscriptions come with a discount.

#### Invoices
Invoices are generated and sent to your registered email address at the beginning of each billing cycle. You can also download invoices from the **Billing** section of your account.

---

#### 8. Cancellation and Refund Policy

We want you to be satisfied with our ATS. If you decide to cancel your subscription, you can do so at any time.

#### How to Cancel Your Subscription
- Log into your ATS account.
- Navigate to the **Subscription** section under **Settings**.
- Click on **Cancel Subscription** and follow the prompts.

#### Refund Policy
- Monthly subscribers: Refunds are not provided for cancellations mid-cycle, but your subscription will continue until the end of the current billing period.
- Annual subscribers: We offer a **30-day money-back guarantee** for annual subscriptions. If you cancel within the first 30 days, you will receive a full refund. After 30 days, no refunds are issued.

---

#### 9. FAQ

#### Can I change my plan at any time?
Yes, you can upgrade or downgrade your plan at any time through the **Subscription** settings.

#### Do you offer discounts for non-profits or educational institutions?
Yes, we offer discounts for eligible non-profits and educational institutions. Please contact us for more details.

#### What happens if I exceed the number of users allowed on my plan?
If you exceed the number of users included in your plan, you will be prompted to upgrade to the next plan tier or purchase additional user slots.

#### How do I get support for billing issues?
For billing-related support, please contact our customer service team at **billing@atsapp.com**.

---

#### Conclusion

Our subscription-based ATS offers flexible plans to suit businesses of all sizes. Whether you're a small startup or a large enterprise, you can choose the plan that meets your needs. Enjoy all the features you need for efficient recruitment and candidate management, with transparent pricing, easy subscription management, and dedicated support.

---

### Application flowcharts:

#### Recruiter' Gear application flowchart:

![Regruiter's Gear](https://github.com/user-attachments/assets/a942fdef-8940-47a2-84b5-9d977ab621ff)

#### Super User's flowchart:

![SUPER USER](https://github.com/user-attachments/assets/878cc6bd-0745-45f9-8fa5-b15960a31d49)

#### Manager's flowchart:

![Manager](https://github.com/user-attachments/assets/90046df8-5d83-4e89-b0ed-6b2a1df99610)

#### Team Lead's flowchart:

![Team Leader](https://github.com/user-attachments/assets/31ff2a35-b6e0-41b1-8bbb-2d77469db8b4)

#### Recruiter's flowchart:

![Recruiter](https://github.com/user-attachments/assets/7ab81931-1552-49b7-bc3a-5e5377d894a0)

---

### Testing Reports

#### **Manual Testing:**

---

#### **Manual Testing** is the process of manually executing test cases without the use of automation tools to ensure that software behaves as expected. It involves a tester following a set of predefined test scenarios to identify bugs or issues in the software.

#### Key Points:

1. **Human Involvement:** A tester performs actions on the application, verifies outputs, and checks for defects.
2. **Test Case Execution:** Testers execute tests based on written test cases or use cases, which describe the inputs, actions, and expected results.
3. **Exploratory Testing:** Testers may also perform exploratory testing, where they use the software freely to identify unexpected issues.
4. **Bug Reporting:** Any issues found during testing are documented and reported to the development team for resolution.
5. **Use Cases:** It includes functional, integration, UI, and user acceptance testing.

#### Advantages:

- **Flexibility:** Testers can adapt test cases based on real-time observations.
- **No Setup Required:** It doesn't require automation tools or scripts.
- **Usability Testing:** Effective for checking the user experience and interface issues.

#### Disadvantages:

- **Time-Consuming:** Manual testing can be slower compared to automated testing.
- **Human Error:** Test results may be affected by tester's experience and attention to detail.
- **Repetitiveness:** The same test cases must be run multiple times for different software versions.

In short, **manual testing** is a critical quality assurance process that ensures the software is working as expected from the user’s perspective, but it’s generally slower and more prone to human error compared to automated testing.

#### **Test-Cases:**

![WhatsApp Image 2025-01-24 at 2 27 09 PM](https://github.com/user-attachments/assets/0d90a2d2-a8e8-45c3-9519-bc18c0955b6e)

#### **Structure of a Manual Test Case:**

Test Case ID: A unique identifier for the test case (e.g., TC001). 

Test Case Name: A short and descriptive title (e.g., "Verify Login Functionality"). 

Preconditions: Any setup or prerequisites required before executing the test case (e.g., "User should be registered"). 

Test Steps: Detailed steps to execute the test case. 

Test Data: Data inputs required for the test (if applicable). 

Expected Result: The desired outcome if the system behaves correctly. 

Actual Result: The result observed after execution (filled in during testing). 

Pass/Fail: The status of the test case based on comparison between expected and actual results. 

Comments: Any additional observations or notes 

---

#### **Automation Testing:**

---

An **Automation Report** generated from tests run using **Selenium** provides detailed insights into the outcomes of automated test executions. Selenium is an open-source tool for automating web applications across different browsers. After running tests, an automation report summarizes key information such as test success, failure, and errors, which helps in tracking the quality of the application.

#### Key Components of a Selenium Automation Report:

1. **Test Execution Summary:**
   
   - **Total Tests Run:** The number of test cases that were executed.
   - **Passed:** How many tests passed successfully.
   - **Failed:** The number of tests that failed.
   - **Skipped/Not Executed:** Tests that were not executed or skipped.
   - **Execution Time:** Total time taken for the tests to execute.

3. **Test Details:**
   
   - **Test Case Name:** Descriptions or IDs for each test case.
   - **Step-by-Step Execution:** Logs of actions performed in each step of the test (e.g., clicking buttons, entering text).
   - **Assertions Results:** Outcomes of assertions made during the test (e.g., validating page elements, verifying UI text).
   
5. **Screenshots:**
   
   - Selenium WebDriver can capture screenshots at the moment of failure, which are often included in the report to help with debugging.

7. **Error Logs/Stack Traces:**
   
   - If a test fails, the report may include detailed logs with stack traces that help identify the root cause of the failure.

9. **Browsers and Environments Tested:**
    
   - Reports may indicate which browsers (e.g., Chrome, Firefox, Safari) and environments (e.g., operating systems) were used for testing.

#### Common Tools for Selenium Test Reporting:

- **TestNG:** A popular testing framework that integrates with Selenium and generates HTML reports.
- **JUnit:** Another testing framework that can be used with Selenium to create detailed reports.
- **Allure Report:** A powerful tool for generating visually rich, interactive reports.
- **Extent Reports:** A commonly used framework for Selenium that provides detailed, customizable reports with screenshots, logs, and a clean, user-friendly interface.

#### Example of a Simple TestNG HTML Report:

After running a test suite with **TestNG**, you would typically find an **HTML report** that includes:
- Test execution statistics.
- Pass/fail status of each test.
- Test duration.
- Logs of each step of the test.

#### Advantages of Selenium Automation Reports:

- **Quick Analysis:** Helps in quickly identifying failed tests and understanding the reasons.
- **Documentation:** Serves as documentation for test results that can be shared with stakeholders.
- **Debugging:** Provides detailed information that assists developers in fixing issues efficiently.

In summary, an **automation report** from Selenium provides valuable insights into the health of an application by summarizing the results of the automated tests, making it easier to track progress, detect failures, and improve overall software quality.

#### **Test-Report:**

![Image 1-24-25 at 12 40 PM](https://github.com/user-attachments/assets/0920a4eb-3407-4adc-bc06-b698a271770d)

An automation test report is a detailed document generated after running automated test scripts to validate the functionality, performance, and reliability of a software application. 

#### Here’s a breakdown of key elements in an automation test report: 

#### Test Execution Summary:  

1.Overview of the number of tests run, passed, failed, skipped, or blocked. 

2. It also include the duration of the test execution. 

     2.   Test Status: 

          - Status of individual test cases (e.g., passed, failed, skipped, or in progress). 

     3. Test Case Details: 

          - Each test case's execution result is included, along with any relevant information, such                         as: 

            - Test case ID 

            - Description 

            - Expected vs. actual results 

            - Steps executed 

            - Pass/fail status 

            - Errors or exceptions encountered 

            - Screenshots or logs (if configured). 

4. Error/Failure Details: 

   - A detailed report of failed tests, including the error message, stack trace, or logs associated with the failure. 

   - It helps to diagnose issues and identify potential bugs or inconsistencies in the application. 

5. Test Coverage: 

   - Information on which features or functionalities were covered during the test execution. 

6. Test Run Environment: 

   - Details about the test environment, such as: 

   - Operating system 

   - Browser version 

Test cases are step-by-step instructions used to verify that a specific functionality of a system works as expected. These are executed manually by a tester without the use of automation tools. Here's a general structure for writing manual test cases: 

---

#### **Performance Testing:**

---

**Performance Testing** using **Apache JMeter** is a widely-used approach for testing the performance, scalability, and stability of web applications and services. JMeter is an open-source tool designed for load testing and measuring the performance of various services, including web servers, databases, and applications.

#### Key Features of JMeter for Performance Testing:

1. **Load Testing:**
   
   - Simulates multiple users (virtual users) accessing the system simultaneously to test how it performs under heavy load.
   - Helps identify system bottlenecks, response time issues, and capacity limits.

3. **Stress Testing:**
   
   - Pushes the system beyond its capacity to determine how it behaves under extreme conditions (e.g., excessive load, high traffic).
   - Helps identify how the application fails and recovers under stress.

5. **Scalability Testing:**
   
   - Assesses how well the application scales with increased load or data.
   - Useful for planning resource allocation and identifying points where performance degrades.

7. **Functional Testing:**
   
   - Verifies the application's basic functionality under load conditions to ensure the business-critical features are not affected by performance issues.

9. **Distributed Testing:**
   - JMeter allows the distribution of test loads across multiple machines, simulating high traffic scenarios that can’t be replicated on a single machine.

---

#### Steps for Performance Testing with JMeter:

1. **Install and Set Up JMeter:**
   
   - Download and install Apache JMeter.
   - Set up the necessary environment (Java, JMeter, etc.).

3. **Create a Test Plan:**
   
   - Define the **Test Plan** in JMeter, which outlines the test's execution flow, including thread groups (simulated users), HTTP requests, and listeners.
   - **Thread Group**: Defines the number of virtual users and the behavior (e.g., ramp-up time, loops).
   - **Samplers**: Used to simulate HTTP requests, database queries, etc.

5. **Define HTTP Requests:**
   
   - Set up requests for the resources you want to test, such as GET, POST, PUT, etc.
   - Specify the server URL, parameters, and headers.

7. **Add Listeners:**
   
   - Listeners capture and display results from the test, such as response times, throughput, and error rates.
   - Common listeners include **Graph Results**, **Summary Report**, and **View Results Tree**.

9. **Run the Test:**
    
   - Execute the test plan, simulating the desired load.
   - JMeter will send requests and capture the responses during the test.

11. **Analyze Results:**
    
   - Review the performance metrics like **response times**, **throughput**, **error rates**, and **latency**.
   - Identify performance bottlenecks, issues with server capacity, or resource limitations.

---

#### Key Performance Metrics in JMeter:

- **Response Time:** The time taken for the server to respond to a request.
- **Throughput:** The number of requests processed per unit of time (requests/sec).
- **Error Rate:** Percentage of failed requests during the test.
- **Latency:** The time taken for a request to travel from the client to the server and back.

---

#### Advantages of Using JMeter for Performance Testing:

- **Open-Source:** JMeter is free to use, making it an accessible tool for performance testing.
- **Extensibility:** It supports plugins and can integrate with other tools.
- **User-Friendly Interface:** Provides a graphical interface for designing test plans and visualizing results.
- **Supports Multiple Protocols:** Can test not only HTTP but also FTP, JDBC, JMS, and more.
- **Scalability:** Can handle large-scale load tests, especially with distributed testing.

---

#### Example Use Cases:

1. **Website Load Testing:** Simulate multiple users accessing a website to measure how it performs under load.
2. **API Performance Testing:** Test the performance of RESTful APIs or SOAP web services under stress.
3. **Database Load Testing:** Simulate database queries and measure the response times under varying loads.

#### Conclusion:

**Apache JMeter** is a powerful tool for performance testing that helps you assess how well your application performs under various load conditions. It provides insights into performance bottlenecks, scalability, and the overall user experience under stress, enabling teams to improve the application’s reliability and performance before production deployment.

#### **Performance Testing Reports:**

![Image 1-24-25 at 12 46 PM](https://github.com/user-attachments/assets/54616444-9e59-4fca-bc37-7a68134521bb)

![Image 1-24-25 at 12 47 PM](https://github.com/user-attachments/assets/057f2d8a-f20a-41c7-bc1f-f4a1887c69f1)

![Image 1-24-25 at 12 49 PM](https://github.com/user-attachments/assets/5253c313-d8fd-44ed-8461-41de0ef2323e)

#### **Analyzing JMeter Test Results**

Analyzing JMeter test results is crucial to understanding the performance of your application and identifying bottlenecks. JMeter provides several listeners to help analyze data. Here's a step-by-step guide to analyze results effectively:

#### 1. Key Metrics to Analyze

When analyzing results, focus on the following metrics:

| Metric        | Description                                                                 |
|---------------|-----------------------------------------------------------------------------|
| **Response Time** | Time taken for a request to be processed. Look at Min, Max, and Average response times. |
| **Throughput**    | Number of requests handled by the server per second. Higher throughput is generally better. |
| **Error Rate**    | Percentage of failed requests. High error rates indicate server instability or misconfiguration. |
| **Latency**       | Time taken to send the request to the server and receive the first byte of the response. |
| **Concurrency**   | Number of users being served simultaneously. |

#### 2. Using Listeners

JMeter provides different listeners to visualize and analyze results. Here are some commonly used ones:

#### a. View Results Tree

- Shows the details of each request and response (raw data).
- Useful for debugging and verifying request data and responses.

#### b. Summary Report

Provides a tabular view of key metrics:

| Metric       | Description                                                       |
|--------------|-------------------------------------------------------------------|
| **Sample**   | Total number of requests.                                         |
| **Average**  | Average response time.                                            |
| **Min / Max**| Minimum and maximum response times.                               |
| **Error %**  | Percentage of failed requests.                                    |
| **Throughput**| Requests per second.                                              |
| **KB/sec**   | Amount of data processed per second.                              |

#### Example Analysis

- **Users**: 75
- **Ramp-Up Period**: 1 second
- **Loop Count**: 1

| Metric                | Value         |
|-----------------------|---------------|
| **Response Time (Avg)** | 350ms         |
| **Throughput**         | 0.90 requests/sec |
| **Error %**            | 14.67 %       |
| **90th Percentile Time** | 40599 ms     |

#### Observations:

- Response times are within SLA.
- Throughput is stable at 0.90 requests/sec.
- Error percentage is high, indicating the system did not handle the load well.

---

#### **Security Testing:**

---

**Security Testing** with tools like **OWASP ZAP (Zed Attack Proxy)** and **Burp Suite** helps identify vulnerabilities in web applications, ensuring they are secure from potential attacks like SQL injection, cross-site scripting (XSS), and more.

#### 1. **OWASP ZAP (Zed Attack Proxy)**

**OWASP ZAP** is an open-source security testing tool designed for finding vulnerabilities in web applications. It is widely used by developers and security professionals for **penetration testing** and **vulnerability scanning**.

#### Key Features:

- **Automated Scanning:** ZAP can automatically scan for common vulnerabilities like SQL injection, XSS, and more.
- **Passive Scanning:** It can analyze traffic between the browser and web server without actively modifying the requests.
- **Active Scanning:** It actively tests for vulnerabilities by sending malicious payloads to the target application.
- **Spidering:** Crawls through the web application to map out all accessible URLs.
- **Fuzzing:** Sends a wide range of unexpected or malformed inputs to the system to identify vulnerabilities.
- **API Testing:** ZAP can test the security of APIs with its built-in features.

#### Common Use Cases:

- Penetration testing.
- Detecting and preventing security flaws early in the development cycle.
- Validating security during continuous integration (CI) or DevOps pipelines.

---

#### 2. **Burp Suite**

**Burp Suite** is a popular and comprehensive tool for web application security testing, used by security professionals for detecting vulnerabilities and performing detailed penetration testing.

#### Key Features:

- **Interception Proxy:** Allows users to intercept, inspect, and modify HTTP/HTTPS requests and responses between the browser and the web server.
- **Scanner:** Automated scanner for detecting vulnerabilities such as XSS, SQL injection, and security misconfigurations.
- **Spider:** Crawls web applications to discover hidden content and functionality.
- **Intruder:** Allows automated brute-force attacks, fuzzing, and dictionary-based attacks.
- **Repeater:** Used to send requests repeatedly with minor modifications, useful for manual testing of vulnerabilities.
- **Extensibility:** Burp Suite has a robust plugin system, enabling the integration of third-party extensions.

#### Common Use Cases:

- **Vulnerability scanning** for web applications and APIs.
- **Penetration testing** with advanced techniques like attack vectors, brute-force, and session hijacking.
- **Security auditing** for compliance with security standards and frameworks.

---

#### Conclusion:

Both **OWASP ZAP** and **Burp Suite** are essential tools in security testing for identifying vulnerabilities in web applications. ZAP is great for quick scans and open-source use, while Burp Suite offers more robust and professional penetration testing features, making it ideal for comprehensive security assessments.

#### **ZAP Report Summary**

![Image 1-24-25 at 6 04 PM](https://github.com/user-attachments/assets/a30c492c-a59b-44cd-a523-f7ce9f6075db)

#### **Alert type**

![Image 1-24-25 at 6 03 PM](https://github.com/user-attachments/assets/688188a6-d2aa-4836-99a6-a68691db563b)

#### **Appendix**

![Image 1-24-25 at 6 04 PM](https://github.com/user-attachments/assets/092f2ee3-10c2-4ace-b32b-026cdcb722e7)

#### **Sections of a ZAP Security Report**

#### 1. Executive Summary

- Provides an overview of the security assessment.
- Highlights the total number of alerts, their severity levels (High, Medium, Low, and Informational), and key findings.

#### 2. Target Information

Includes details about the target system or application that was scanned:

- **URL(s) scanned**
- **Date and time of the scan**
- **Scanner version**

#### 3. Vulnerability Findings

A categorized list of discovered vulnerabilities, including:

| **Field**        | **Description**                                                                 |
|------------------|---------------------------------------------------------------------------------|
| **Alert Title**  | Name of the vulnerability (e.g., "SQL Injection", "Cross-Site Scripting").       |
| **Risk Level**   | Severity of the vulnerability (High, Medium, Low, Informational).               |
| **Description**  | Explains the issue and its potential impact.                                     |
| **URLs Affected**| List of endpoints where the vulnerability exists.                               |
| **Instances**    | Number of occurrences for the specific vulnerability.                           |
| **Evidence**     | Proof that the vulnerability exists, such as HTTP requests and responses.       |
| **Recommendation**| Remediation steps to fix the vulnerability.                                     |

#### 4. Scan Progress and Settings

Details on how the scan was configured:

- **Spidering depth**
- **Authentication used** (if applicable)
- **Types of tests performed** (active scan, passive scan, etc.)

---

### Code Convention

#### **Best Coding Practices for ReactJS**

#### 1. Component Design
- **Small, Reusable Components**: Create small, reusable components to improve maintainability and testability. Each component should ideally do one thing.
- **Functional Components**: Prefer using functional components with hooks (`useState`, `useEffect`, etc.) over class components.
- **Avoid Large Components**: If a component becomes too large, break it down into smaller, more manageable ones.

#### 2. State Management
- **Local State**: Use `useState` for managing local state within a component.
- **Global State**: For shared state, use Context API for simpler use cases or Redux for more complex state management needs.
- **Avoid Overusing Redux**: Don't use Redux for simple state management. The Context API or just React's state management may suffice.

#### 3. Performance Optimization
- **React.memo()**: Use `React.memo()` to prevent unnecessary re-renders of functional components.
- **Lazy Loading**: Use `React.lazy()` and `Suspense` to load components only when necessary (code splitting).
- **useMemo and useCallback**: Use these hooks to memoize values and functions, avoiding unnecessary recalculations and re-renders.

#### 4. Error Handling
- **Error Boundaries**: Use error boundaries to catch JavaScript errors in your component tree and display a fallback UI instead of crashing the whole app.
- **Proper Async Handling**: Handle asynchronous code (e.g., API calls) with proper error handling, using `try-catch` blocks.

#### 5. Code Organization
- **Folder Structure**: Organize your code into clear folders for components, hooks, pages, services, and utilities:

    ```bash
    src/
      components/
      pages/
      services/
      hooks/
      utils/
    ```

- **Separation of Concerns**: Separate business logic from UI components. Place data-fetching and API calls in services or custom hooks.

#### 6. Styling
- **CSS-in-JS**: Consider using styled-components or Emotion for scoped CSS inside your components.
- **Avoid Inline Styles**: Minimize inline styles as they may cause re-renders and performance issues.

#### 7. Code Quality
- **Linting**: Use ESLint to enforce coding standards and maintain consistency across your codebase.
- **Code Formatting**: Use Prettier for automatic code formatting to keep the codebase clean.
- **Consistent Naming Conventions**: Use consistent and descriptive naming for variables, functions, and components.

---

#### **Best Coding Practices for Spring Boot**

#### 1. Project Structure
- **Layered Architecture**: Follow a layered architecture with clear separation between the controller, service, and repository layers. This improves testability and maintainability.
    - **Controller Layer**: Handles HTTP requests.
    - **Service Layer**: Contains business logic.
    - **Repository Layer**: Manages data access.
- **DTO (Data Transfer Object)**: Use DTOs for communication between layers, especially for API responses, instead of returning entities directly.

#### 2. Configuration Management
- **Externalized Configuration**: Store configuration values (e.g., database credentials) in `application.properties` or `application.yml` files, and externalize them for different environments (e.g., development, production).
- **Profile-based Configuration**: Use Spring Profiles (`@Profile`) to differentiate configurations for different environments.

#### 3. Database and Persistence
- **Spring Data JPA**: Use Spring Data JPA for data access. Avoid writing custom queries when the built-in methods are sufficient.
- **Avoid N+1 Query Problem**: Use `@EntityGraph` or fetch join queries to avoid unnecessary database queries.
- **Pagination**: Use pagination for large datasets to reduce memory consumption and improve performance.

#### 4. Security
- **Spring Security**: Always secure your APIs using Spring Security. Use JWT or OAuth for stateless authentication in modern web applications.
- **Role-based Access Control**: Use role-based access control (RBAC) to assign appropriate permissions to users based on their roles.
- **Principle of Least Privilege**: Restrict access rights to the minimum necessary for the functioning of each user or process.

#### 5. Exception Handling
- **Global Exception Handling**: Use `@ControllerAdvice` for global exception handling, making it easier to handle errors consistently across the application.
- **Custom Error Messages**: Provide meaningful error messages in your responses to make it easier for clients to diagnose issues.

#### 6. Performance Optimization
- **Caching**: Use Spring Cache with providers like Redis or EhCache to cache frequently used data and reduce database load.
- **Asynchronous Processing**: Use `@Async` for tasks that can run in the background without blocking the main thread (e.g., sending emails, generating reports).
- **Database Connection Pooling**: Use connection pooling (HikariCP, which is the default in Spring Boot) for efficient database connections.

#### 7. Testing
- **Unit Tests**: Write unit tests for service and utility methods using JUnit and Mockito.
- **Integration Tests**: Use `@SpringBootTest` for integration tests to ensure that different layers of the application are working together as expected.
- **Test Coverage**: Aim for high test coverage, but avoid testing trivial code. Use tools like JaCoCo to track test coverage.

---

#### **Best Coding Practices for MySQL**

#### 1. Database Design
- **Normalization**: Follow the rules of database normalization (up to 3NF) to eliminate data redundancy and ensure data integrity.
- **Use Primary Keys**: Always use primary keys to uniquely identify records in a table.
- **Indexing**: Create indexes on frequently queried columns (e.g., foreign keys, columns used in WHERE clauses) to improve query performance.

#### 2. Query Optimization
- **Avoid SELECT ***: Instead of using `SELECT *`, explicitly list the columns you need to avoid unnecessary data retrieval.
- **Use Joins Wisely**: Use `INNER JOIN` and `LEFT JOIN` appropriately. Be mindful of the performance impact of complex joins.
- **Limit Query Results**: Always limit the number of rows returned using `LIMIT` or pagination for queries that fetch large datasets.
- **Avoid N+1 Queries**: Use `JOIN` or `IN` to fetch related data in a single query rather than multiple separate queries.

#### 3. Transaction Management
- **ACID Compliance**: Ensure that your transactions follow the ACID properties (Atomicity, Consistency, Isolation, Durability) to maintain database integrity.
- **Use Proper Isolation Levels**: Set appropriate isolation levels for transactions based on business requirements to avoid issues like dirty reads and lost updates.
- **Commit and Rollback**: Always use proper commit and rollback handling to ensure that database operations are either fully completed or fully reverted in case of an error.

#### 4. Data Integrity
- **Foreign Keys**: Use foreign keys to enforce relationships between tables and maintain referential integrity.
- **Avoid Storing Business Logic in Database**: Avoid using triggers and stored procedures for business logic; it is better to handle this logic in the application layer.

#### 5. Database Backup and Recovery
- **Regular Backups**: Schedule regular backups (daily, weekly) to ensure that data is recoverable in case of system failure.
- **Use Replication for High Availability**: Set up master-slave replication for high availability and disaster recovery purposes.

#### 6. Security
- **Use Prepared Statements**: Always use prepared statements or ORM frameworks like Hibernate to prevent SQL injection attacks.
- **Limit Database Access**: Restrict database access to authorized applications and users only, and use the principle of least privilege.

#### 7. Database Monitoring
- **Slow Query Log**: Enable MySQL's slow query log to identify queries that take a long time to execute. Optimize these queries.
- **Database Monitoring Tools**: Use tools like Percona Monitoring and Management (PMM) or MySQL Enterprise Monitor for real-time database performance monitoring.

---

### Error Handling

#### Error Handling in Detail for ReactJS

Effective error handling is critical in ReactJS applications to ensure that unexpected issues don't break the user experience and that developers can easily diagnose problems. React provides several tools and techniques for managing errors, both **synchronous** (JavaScript errors) and **asynchronous** (API or network requests).

Let's dive deeper into how to handle errors effectively in ReactJS.

#### **1. Error Boundaries (for Synchronous Errors)**

React Error Boundaries are a way to catch JavaScript errors in the component tree and display a fallback UI rather than letting the entire app crash. Error boundaries only catch errors in their child components, **not event handlers**, **asynchronous code**, or **errors thrown in the constructor**.

#### How Error Boundaries Work:

Error boundaries are **class components** that implement either or both of the following methods:

- **`getDerivedStateFromError()`**: This static method is used to update the component’s state based on the error that occurred.
- **`componentDidCatch()`**: This lifecycle method is used to log the error details and to provide additional context about the error.

#### Example of an Error Boundary:

```jsx
import React, { Component } from 'react';

// This class will catch JavaScript errors in child components
class ErrorBoundary extends Component {
  constructor(props) {
    super(props);
    this.state = { hasError: false, errorInfo: null };
  }

  static getDerivedStateFromError(error) {
    // Update state to show fallback UI
    return { hasError: true };
  }

  componentDidCatch(error, info) {
    // Log the error for debugging purposes
    console.error("Caught error:", error);
    console.error("Error Info:", info);
    this.setState({ errorInfo: info });
  }

  render() {
    if (this.state.hasError) {
      // You can render any custom fallback UI
      return <h1>Something went wrong!</h1>;
    }
    return this.props.children;
  }
}

export default ErrorBoundary;
```
**** Usage

```bash
<ErrorBoundary>
  <MyComponent />
</ErrorBoundary>

```
> **Note**: Error boundaries only catch errors during rendering and lifecycle methods. They don’t catch errors inside **event handlers**, **asynchronous code**, or certain methods (like `setState()`).

---

#### **2. Handling Errors in Asynchronous Code (API Calls)**

In React, most asynchronous errors occur when making API calls or performing other async operations (like fetching data). You need to manage these errors gracefully by using `try-catch` blocks within async functions.

#### Handling Errors with `fetch()`:

```jsx
import React, { useState, useEffect } from 'react';

function DataFetchingComponent() {
  const [data, setData] = useState(null);
  const [error, setError] = useState(null);

  useEffect(() => {
    async function fetchData() {
      try {
        const response = await fetch('https://api.example.com/data');
        if (!response.ok) {
          throw new Error('Failed to fetch data');
        }
        const result = await response.json();
        setData(result);
      } catch (error) {
        setError(error.message);
      }
    }

    fetchData();
  }, []); // Empty array ensures this runs once when the component mounts

  if (error) {
    return <div>Error: {error}</div>;
  }

  return <div>{data ? JSON.stringify(data) : 'Loading...'}</div>;
}

export default DataFetchingComponent;
```

#### Handling Errors with `axios`

Using `axios` for API calls is a common practice. Here's how you can handle errors in API calls made with `axios`.

#### Example with `axios`:

```jsx
import React, { useState, useEffect } from 'react';
import axios from 'axios';

function DataFetchingComponent() {
  const [data, setData] = useState(null);
  const [error, setError] = useState(null);

  useEffect(() => {
    async function fetchData() {
      try {
        const response = await axios.get('https://api.example.com/data');
        setData(response.data);
      } catch (error) {
        setError(error.response ? error.response.data : 'Error: Something went wrong!');
      }
    }

    fetchData();
  }, []);

  if (error) {
    return <div>Error: {error}</div>;
  }

  return <div>{data ? JSON.stringify(data) : 'Loading...'}</div>;
}

export default DataFetchingComponent;
```

#### Best Practices:

- **Graceful Error Handling**: Always handle errors explicitly to show the user meaningful error messages.
- **Display Fallback UI**: For async errors, display a loading spinner or a message indicating that the data is being fetched, and if an error occurs, provide a user-friendly message.
- **Retry Mechanism**: Implement retry logic where applicable, especially when dealing with transient issues like network failures.

#### **3. Handling Form Validation Errors**

When working with forms in React, it's essential to catch input validation errors before submitting the form to the backend. You can either handle this **client-side** (before submission) or **server-side** (on the backend after submission).

#### Client-Side Form Validation with State:

```jsx
import React, { useState } from 'react';

function FormWithValidation() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [error, setError] = useState('');

  const validateForm = () => {
    if (!email || !password) {
      setError('Both email and password are required');
      return false;
    }
    // You can add more validation rules like regex here
    return true;
  };

  const handleSubmit = (e) => {
    e.preventDefault();
    if (validateForm()) {
      setError('');
      // Proceed with form submission
      console.log('Form submitted');
    }
  };

  return (
    <form onSubmit={handleSubmit}>
      <input
        type="email"
        value={email}
        onChange={(e) => setEmail(e.target.value)}
        placeholder="Email"
      />
      <input
        type="password"
        value={password}
        onChange={(e) => setPassword(e.target.value)}
        placeholder="Password"
      />
      <button type="submit">Submit</button>
      {error && <div style={{ color: 'red' }}>{error}</div>}
    </form>
  );
}

export default FormWithValidation;
```
#### Validation Feedback:
- Display error messages inline, preferably under the input fields, so users know what went wrong.

#### Error Styles:
- Highlight form fields with errors by adding a red border or other visual cues to make it clear that there's an issue.

#### 4. Async Error Handling in Event Handlers

React’s event handlers (such as `onClick`, `onSubmit`) do not automatically handle errors, so you need to manage async code errors manually.

#### Handling Errors in Event Handlers:

```jsx
import React, { useState } from 'react';

function AsyncErrorHandlingComponent() {
  const [data, setData] = useState(null);
  const [error, setError] = useState('');

  const handleClick = async () => {
    try {
      const response = await fetch('https://api.example.com/data');
      if (!response.ok) throw new Error('Failed to fetch data');
      const result = await response.json();
      setData(result);
    } catch (error) {
      setError('Error: ' + error.message);
    }
  };

  return (
    <div>
      <button onClick={handleClick}>Fetch Data</button>
      {error && <div>{error}</div>}
      {data && <div>{JSON.stringify(data)}</div>}
    </div>
  );
}

export default AsyncErrorHandlingComponent;
```
#### Error Handling for Button Click: In the above example, the error is caught and displayed on the UI when the button is clicked. This makes it clear to users if something went wrong during the API call.

#### 5. Handling Network Errors

Network errors can occur if the user is offline, the server is down, or other issues arise. You can handle these errors by inspecting the error object in `catch` blocks.

#### Handling Offline Errors:

```jsx
import React, { useState } from 'react';

function OfflineErrorHandlingComponent() {
  const [error, setError] = useState(null);

  const fetchData = async () => {
    try {
      const response = await fetch('https://api.example.com/data');
      if (!response.ok) throw new Error('Failed to fetch data');
      // handle success
    } catch (err) {
      if (err.message === 'Failed to fetch') {
        setError('Network error: Please check your internet connection');
      } else {
        setError('Error: ' + err.message);
      }
    }
  };

  return (
    <div>
      <button onClick={fetchData}>Fetch Data</button>
      {error && <div>{error}</div>}
    </div>
  );
}

export default OfflineErrorHandlingComponent;
```

#### Network Error Detection: React provides the ability to detect network issues using the catch block and checking if the error message matches common network issues (e.g., Failed to fetch).

#### Retrying Requests: You can add retry logic to allow users to retry the operation if the network error occurs, or show a "Retry" button to trigger the request again.

#### Conclusion

In ReactJS, error handling can be divided into several areas: component rendering errors, asynchronous errors (e.g., API calls), form validation errors, and network errors. By leveraging **error boundaries**, **try-catch blocks**, and **client-side validation**, you can ensure a smoother user experience, provide meaningful error messages, and maintain your application’s robustness even in the face of unexpected failures.

---

#### **Error Handling in Detail for Spring Boot**

Error handling is a critical part of building robust and user-friendly Spring Boot applications. Effective error management allows you to catch issues early, return meaningful messages to the client, and ensure that the application operates smoothly even in the case of unexpected errors.

In Spring Boot, error handling can be broadly categorized into:

- **Handling Application-Level Errors** (e.g., database, application logic)
- **Validation Errors** (e.g., input validation)
- **HTTP Errors** (e.g., 404 Not Found, 500 Internal Server Error)

Let's dive into each of these areas in detail.

#### 1. Handling Application-Level Errors

#### Global Exception Handling with `@ControllerAdvice`

In Spring Boot, the `@ControllerAdvice` annotation allows you to define a global exception handler. This is used to catch exceptions across the whole application in a centralized way.

#### Example of a Global Exception Handler using `@ControllerAdvice`:

```java
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.ui.Model;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.ResponseStatus;

@ControllerAdvice
public class GlobalExceptionHandler {

    // This method will handle all exceptions of type Exception
    @ExceptionHandler(Exception.class)
    public ResponseEntity<String> handleAllExceptions(Exception ex) {
        return new ResponseEntity<>("An error occurred: " + ex.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);
    }

    // Handle specific exception (e.g., NullPointerException)
    @ExceptionHandler(NullPointerException.class)
    public ResponseEntity<String> handleNullPointerExceptions(NullPointerException ex) {
        return new ResponseEntity<>("Null Pointer Exception: " + ex.getMessage(), HttpStatus.BAD_REQUEST);
    }
}
```

#### **Explanation:**

#### @ExceptionHandler: Defines the method that will handle a specific exception. In the above example, all exceptions of type Exception are handled by handleAllExceptions(), and NullPointerException by handleNullPointerExceptions().

#### @ControllerAdvice: This annotation is used at the class level and globally applies the exception handling logic to all controllers in the application.
ResponseEntity: It is used to return an HTTP response with a custom message and status code.

#### Custom Error Response Format

It is a best practice to return a structured error response to the client. Instead of just sending an error message as a string, you can create a custom error response object.

#### Example of a Custom Error Response Object:

```java
public class ErrorResponse {
    private String message;
    private String details;

    // Constructors, getters, and setters
}
```

#### Now Modify the Global Exception Handler to Return This Structured Error Response:

```java
@ExceptionHandler(Exception.class)
public ResponseEntity<ErrorResponse> handleAllExceptions(Exception ex) {
    ErrorResponse error = new ErrorResponse("An error occurred", ex.getMessage());
    return new ResponseEntity<>(error, HttpStatus.INTERNAL_SERVER_ERROR);
}
```

#### 2. Handling Validation Errors with `@Valid` and `@ExceptionHandler`

Spring Boot makes it easy to validate input fields in REST APIs using the `@Valid` annotation. When validation fails, Spring Boot throws a `MethodArgumentNotValidException`, which can be handled by `@ExceptionHandler`.

#### Example of Handling Validation Errors:

First, define a model with validation annotations:

```java
import javax.validation.constraints.NotBlank;
import javax.validation.constraints.Size;

public class UserRequest {
    @NotBlank(message = "Username cannot be blank")
    @Size(min = 3, max = 20, message = "Username must be between 3 and 20 characters")
    private String username;

    @NotBlank(message = "Email cannot be blank")
    private String email;

    // Constructors, getters, and setters
}
```
Now, in your controller, validate the model using `@Valid`:

```java
import org.springframework.web.bind.annotation.*;
import javax.validation.Valid;

@RestController
@RequestMapping("/users")
public class UserController {

    @PostMapping("/create")
    public ResponseEntity<String> createUser(@Valid @RequestBody UserRequest userRequest) {
        // Business logic here
        return ResponseEntity.ok("User created successfully");
    }
}
```

#### Handling Validation Errors with `@ControllerAdvice`:

You can create a global handler for `MethodArgumentNotValidException` to return the validation error messages.

```java
@ControllerAdvice
public class ValidationExceptionHandler {

    @ExceptionHandler(MethodArgumentNotValidException.class)
    public ResponseEntity<List<String>> handleValidationExceptions(MethodArgumentNotValidException ex) {
        List<String> errorMessages = ex.getBindingResult()
                .getFieldErrors()
                .stream()
                .map(error -> error.getField() + ": " + error.getDefaultMessage())
                .collect(Collectors.toList());

        return new ResponseEntity<>(errorMessages, HttpStatus.BAD_REQUEST);
    }
}
```
#### Explanation:
- **`MethodArgumentNotValidException`**: This exception is thrown when validation fails in a controller method. It contains the validation error messages.
- **`getBindingResult()`**: This method retrieves the binding result, which holds the details of the validation errors.
- **`getFieldErrors()`**: This retrieves the list of errors related to specific fields. You can extract the error messages from each field and return them in a structured format.
- **Return Detailed Error Messages**: By using `getFieldErrors()` and mapping each error, you can return a list of detailed error messages to the client, providing clear feedback on what went wrong with each field.

The handler will capture validation errors and return them in a user-friendly way, allowing clients to understand exactly which fields failed and why.

### 3. Handling HTTP Errors (404, 500, etc.)

Spring Boot automatically handles common HTTP errors, such as 404 Not Found or 500 Internal Server Error, but you can customize the handling of these errors by using `@ExceptionHandler` or `@ResponseStatus`.

#### Customizing HTTP Error Responses:

For example, if you want to provide a custom message for 404 errors, you can create a custom exception and annotate it with `@ResponseStatus`.

```java
@ResponseStatus(HttpStatus.NOT_FOUND)
public class ResourceNotFoundException extends RuntimeException {
    public ResourceNotFoundException(String message) {
        super(message);
    }
}
```

You can then throw this exception in your controller methods:

```java
@GetMapping("/users/{id}")
public User getUser(@PathVariable("id") Long id) {
    User user = userService.findUserById(id);
    if (user == null) {
        throw new ResourceNotFoundException("User with ID " + id + " not found");
    }
    return user;
}
```
### Customizing 404 Page:

If you want to handle 404 errors globally for unrecognized endpoints, you can do so by creating an exception handler or a `@ControllerAdvice` that returns a custom page or JSON message.

```java
@ControllerAdvice
public class NotFoundExceptionHandler {

    @ExceptionHandler(ResourceNotFoundException.class)
    public ResponseEntity<ErrorResponse> handleResourceNotFound(ResourceNotFoundException ex) {
        ErrorResponse errorResponse = new ErrorResponse("Resource Not Found", ex.getMessage());
        return new ResponseEntity<>(errorResponse, HttpStatus.NOT_FOUND);
    }
}
```

#### 4. Handling Authentication & Authorization Errors with Spring Security

Spring Security handles authentication and authorization errors, but you can customize error handling for authentication failures and access denied exceptions.

#### Custom Authentication Failure Handler:

You can create a custom handler to handle authentication failures (invalid credentials):

```java
import org.springframework.security.core.AuthenticationException;
import org.springframework.security.web.authentication.AuthenticationFailureHandler;
import org.springframework.stereotype.Component;
import org.springframework.web.bind.annotation.ResponseStatus;
import org.springframework.http.HttpStatus;

@Component
public class CustomAuthenticationFailureHandler implements AuthenticationFailureHandler {

    @Override
    public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response,
                                        AuthenticationException exception) throws IOException, ServletException {
        response.sendError(HttpStatus.UNAUTHORIZED.value(), "Authentication Failed: " + exception.getMessage());
    }
}
```
#### Custom Access Denied Handler:

If a user tries to access a resource they are not authorized to, Spring Security will throw an `AccessDeniedException`. You can handle this by creating a custom `AccessDeniedHandler`.

```java
import org.springframework.security.access.AccessDeniedException;
import org.springframework.security.web.access.AccessDeniedHandler;
import org.springframework.stereotype.Component;
import org.springframework.http.HttpStatus;
import org.springframework.web.bind.annotation.ResponseStatus;

@Component
public class CustomAccessDeniedHandler implements AccessDeniedHandler {

    @Override
    public void handle(HttpServletRequest request, HttpServletResponse response,
                       AccessDeniedException accessDeniedException) throws IOException, ServletException {
        response.sendError(HttpStatus.FORBIDDEN.value(), "Access Denied: " + accessDeniedException.getMessage());
    }
}
```

#### This will return a 403 Forbidden response when the user tries to access a resource they are not authorized to.

#### 5. Handling Database Errors

Spring Data JPA and other database-related exceptions can be handled using the same approach as application-level errors. For example, a `DataIntegrityViolationException` can be caught and translated into a user-friendly error message.

#### Example of Handling Database Errors:

```java
@ExceptionHandler(DataIntegrityViolationException.class)
public ResponseEntity<String> handleDatabaseErrors(DataIntegrityViolationException ex) {
    return new ResponseEntity<>("Database integrity error: " + ex.getMessage(), HttpStatus.CONFLICT);
}
```
#### This ensures that when a database error occurs (like trying to insert a duplicate value), the application does not crash and the client gets a meaningful response.

#### Conclusion

Effective error handling in Spring Boot is essential to providing a smooth user experience and maintaining the integrity of the application. By leveraging global exception handling with `@ControllerAdvice`, validating user input with `@Valid`, customizing HTTP error responses, handling security-related exceptions, and managing database errors, you can ensure that your Spring Boot application is robust, user-friendly, and easy to debug.

---

#### **Error Handling in Detail for MySQL**

Error handling in MySQL is crucial to ensure data integrity, application stability, and proper error reporting. MySQL provides various error codes and mechanisms to handle issues like constraint violations, deadlocks, connection problems, etc. When working with MySQL, the goal is to handle errors gracefully by:

- Catching and reporting errors effectively.
- Ensuring data consistency and avoiding corruption.
- Managing transactions properly to maintain ACID compliance.
- Optimizing query performance to avoid common pitfalls.

Here's an overview of how to handle errors in MySQL in different areas:

#### Error Handling in Detail for MySQL

Error handling in MySQL is crucial to ensure data integrity, application stability, and proper error reporting. MySQL provides various error codes and mechanisms to handle issues like constraint violations, deadlocks, connection problems, etc. When working with MySQL, the goal is to handle errors gracefully by:

- Catching and reporting errors effectively.
- Ensuring data consistency and avoiding corruption.
- Managing transactions properly to maintain ACID compliance.
- Optimizing query performance to avoid common pitfalls.

Here's an overview of how to handle errors in MySQL in different areas:

#### 1. Handling SQL Query Errors

#### Types of Common SQL Errors:
- **Syntax Errors**: These occur when the SQL query is malformed. For example, missing keywords or incorrect syntax.

    **Example**:
    ```sql
    SELECT * FORM users;  -- Incorrect keyword FORM instead of FROM
    ```

- **Constraint Violations**: Errors related to data integrity, such as violating unique constraints or foreign key constraints.

    **Example**:
    ```sql
    INSERT INTO users (id, username) VALUES (1, 'john_doe');  -- Error if the id already exists in the UNIQUE constraint
    ```

- **Data Type Mismatch**: If the data type of a value being inserted or updated doesn't match the column definition.

    **Example**:
    ```sql
    INSERT INTO users (id, username) VALUES ('string_instead_of_int', 'john_doe');  -- Error due to type mismatch
    ```

- **Division by Zero**: A common runtime error when trying to divide a number by zero.

    **Example**:
    ```sql
    SELECT 10 / 0;  -- Error due to division by zero
    ```

#### Handling Query Errors:
To handle errors effectively, ensure your queries are written correctly and check the result status after executing a query.

**Example of handling errors in MySQL via SQL scripts:**

```sql
-- Handling duplicate entry violation (assuming the `id` column is unique)
INSERT INTO users (id, username) VALUES (1, 'john_doe');
-- If the id already exists, handle the error
-- This will not raise an error but ignore the insertion if duplicate
INSERT IGNORE INTO users (id, username) VALUES (1, 'john_doe');
```

For more detailed error management, you can use the `SHOW WARNINGS` and `SHOW ERRORS` commands to get detailed information about the most recent error.

#### Example:

```sql
-- View the last error message
SHOW ERRORS;

-- View warnings for the last query
SHOW WARNINGS;
```

#### 2. Handling Errors in Stored Procedures

In MySQL, you can use `DECLARE ... HANDLER` within stored procedures to catch and handle specific errors or conditions, which is very useful for preventing stored procedures from crashing.

#### Example of Error Handling in Stored Procedures:

```sql
DELIMITER //

CREATE PROCEDURE addUser(IN userId INT, IN userName VARCHAR(255))
BEGIN
    DECLARE EXIT HANDLER FOR SQLEXCEPTION
    BEGIN
        -- Error handling logic (e.g., rollback, logging, etc.)
        ROLLBACK;
        SELECT 'An error occurred during the insertion process.' AS ErrorMessage;
    END;

    -- Start transaction
    START TRANSACTION;

    -- Insert user data (may cause an error if userId already exists)
    INSERT INTO users (id, username) VALUES (userId, userName);

    -- Commit the transaction if no errors
    COMMIT;
END //

DELIMITER ;
```

#### Explanation:

- **`DECLARE EXIT HANDLER FOR SQLEXCEPTION`**: This declares a handler to catch any SQL exception that occurs within the stored procedure. When an exception is caught, a custom action is performed—in this case, rolling back the transaction.
  
- **`START TRANSACTION` and `COMMIT/ROLLBACK`**: These statements ensure that the changes made during the transaction are either fully committed or fully rolled back. If an error occurs, the `ROLLBACK` ensures that no partial updates are made to the database. If no error occurs, the `COMMIT` ensures that the changes are persisted.

- **Custom Error Handlers**: You can also create specific error handlers for different types of errors, such as:
  - Deadlocks (`ER_LOCK_DEADLOCK`)
  - Unique constraint violations (`ER_DUP_ENTRY`)
  - Foreign key violations, etc.
  
This structure ensures that your stored procedures are resilient to errors and maintain data integrity.

#### 3. Handling Database Connection Errors

Connection issues, such as incorrect credentials, network timeouts, or server unavailability, can occur when trying to connect to the MySQL server. These errors can be handled at the application level to ensure the application provides useful feedback to the user.

#### Common Connection Errors:
- **Error 1045**: Access denied for user (wrong username/password).
- **Error 2002**: Can't connect to MySQL server (network error).
- **Error 1049**: Unknown database (database doesn't exist).

#### Handling Connection Errors in Java (via JDBC):
In Java, you can handle connection errors by catching `SQLException` and inspecting the `SQLState` or `ErrorCode` to provide specific messages based on the error code.

```java
try {
    Connection connection = DriverManager.getConnection(
            "jdbc:mysql://localhost:3306/mydatabase", "username", "password");
} catch (SQLException ex) {
    if (ex.getErrorCode() == 1045) {
        System.out.println("Access denied: Check your username and password.");
    } else if (ex.getErrorCode() == 1049) {
        System.out.println("Unknown database: Verify the database name.");
    } else if (ex.getErrorCode() == 2002) {
        System.out.println("Unable to connect: MySQL server may be down or unreachable.");
    } else {
        System.out.println("Database connection error: " + ex.getMessage());
    }
}
```
#### Explanation:
- **SQLExceptions** provide an error code and message, which can be used to determine the cause of the issue. For example:
  - **Error Code 1045** typically indicates invalid credentials (wrong username or password).
  - **Error Code 2002** is a network-related issue (e.g., the MySQL server is unreachable).
  - **Error Code 1049** means the specified database does not exist.

- It is **recommended** to log detailed error information to aid in troubleshooting. By logging both the **error message** and **stack trace**, developers can quickly identify the root cause of connection issues and take corrective action.

#### 4. Transaction Management

When working with transactions, it's essential to manage **commits** and **rollbacks** properly to ensure data consistency. This is particularly crucial when dealing with multi-step operations, where one failure should not result in partial or inconsistent data.

#### Using Transactions in MySQL:
In MySQL, you use the `BEGIN`, `COMMIT`, and `ROLLBACK` commands to manage the transaction flow and handle any errors that might occur during multi-step operations.

#### Example of MySQL Transactions with Error Handling:

```sql
START TRANSACTION;

-- Try to insert user details
INSERT INTO users (id, username) VALUES (1, 'johndoe');

-- Simulate an error (e.g., inserting a duplicate username)
-- This will cause the transaction to fail and the changes to be rolled back
INSERT INTO users (id, username) VALUES (1, 'johndoe_duplicate');

-- If no error, commit the transaction to persist changes
COMMIT;

-- If an error occurs, rollback to ensure data consistency and no partial updates
ROLLBACK;
```
#### 5. Handling Deadlocks

Deadlocks occur when two or more transactions are blocked, waiting for each other to release locks, resulting in a situation where no transaction can proceed. In highly concurrent environments, deadlocks are a common issue and need to be handled gracefully to ensure that transactions are retried automatically and the system continues to function smoothly.

#### Handling Deadlocks in MySQL:

You can use the **`DECLARE CONTINUE HANDLER FOR SQLEXCEPTION`** statement within stored procedures to detect a deadlock and retry the transaction. If a deadlock occurs, the transaction is rolled back, and the system waits before retrying the operation.

#### Example of Deadlock Handling in Stored Procedures:

```sql
-- Retry logic in the application layer if deadlock occurs
DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
BEGIN
    -- Log the error and rollback the transaction
    ROLLBACK;

    -- Retry logic (e.g., wait for a few seconds and retry the transaction)
    -- This could involve a loop that retries the transaction up to a certain number of times
    SELECT 'Deadlock detected, retrying transaction...';
    -- Add your retry logic here (e.g., wait for a few seconds)
END;
```

#### 5. Error Handling with Foreign Key Constraints

Foreign key constraints ensure referential integrity between tables in a relational database. If you try to insert, update, or delete records that would violate these constraints, MySQL will throw a **foreign key violation error**. These errors commonly occur when you attempt to reference a non-existent record in a related table.

#### Common Scenarios for Foreign Key Violations:
1. **Inserting a record with a non-existent foreign key**: You attempt to insert a record that references a foreign key that doesn't exist in the parent table.
2. **Deleting a record that is still referenced by another table**: You try to delete a record from the parent table that is being referenced by a foreign key in another table.
3. **Updating a foreign key to a non-existent value**: You attempt to update a foreign key value to one that doesn't exist in the parent table.

#### Example of Handling Foreign Key Violations:

Suppose you have a **`users`** table that references a **`departments`** table via a foreign key on the `department_id` column in the **`employees`** table.

```sql
-- Suppose the 'users' table has a foreign key reference to 'departments' table.
-- Inserting into 'employees' without an existing 'department_id' will cause a foreign key violation if 'department_id' doesn't exist.

INSERT INTO employees (emp_id, department_id) 
VALUES (101, 999); -- Department ID 999 may not exist in the 'departments' table, leading to a foreign key violation.
```
To handle this:

Check the existence of referenced data before insertion.
Use ON DELETE CASCADE or ON UPDATE CASCADE constraints where appropriate.
```sql
CREATE TABLE employees (
    emp_id INT PRIMARY KEY,
    department_id INT,
    FOREIGN KEY (department_id) REFERENCES departments(department_id) ON DELETE CASCADE
);
```

#### 6. Optimizing Queries to Avoid Errors

MySQL can sometimes throw errors or degrade in performance if queries are not optimized. Key areas to optimize:

#### Common Query Optimization Practices

- **Indexes**: Use appropriate indexes on columns frequently used in `WHERE`, `JOIN`, and `ORDER BY` clauses.
- **Avoiding N+1 Queries**: Always use `JOIN` instead of multiple separate queries in a loop.
- **EXPLAIN**: Use the `EXPLAIN` statement to analyze the query execution plan.
- **Limit Results**: Always use `LIMIT` for pagination, especially with large datasets.

```sql
EXPLAIN SELECT * FROM users WHERE username = 'johndoe';
```
#### Handling Query Performance Errors

If a query takes too long, you may encounter a timeout error (e.g., **Error 1205: Lock wait timeout**). To address this:

- **Optimize the query for performance**.
- **Increase the timeout value** if necessary.

#### 7. Monitoring and Error Logging

MySQL provides built-in logs for tracking errors, queries, and performance.

#### Useful Logs:

- **Error Log**: Records server startup, shutdown, and critical errors.  
  **Location**: `/var/log/mysql/error.log`

- **General Query Log**: Logs all SQL queries executed on the server.  
  **Enable with**: 
  ```sql
  SET global general_log = 1;
```
- **Slow Query Log**: Logs queries that take longer than a specified time to execute.  
  **Enable with**: 
  ```sql
  SET global slow_query_log = 1;
```

#### Conclusion

Effective error handling in MySQL ensures the integrity and stability of your database and application. By properly managing:

- Query errors
- Stored procedures
- Database connections
- Transactions
- Foreign key constraints

You can prevent data corruption, ensure consistent application behavior, and troubleshoot effectively. Moreover, always optimize your queries and use logging tools to monitor the health of your MySQL database.

### Understanding Endpoints

#### **Understanding Endpoints in Web Development**

In web development, endpoints refer to specific routes or URLs that define where and how requests should be made to interact with a web application or API. These are integral to the client-server architecture, where the server listens for requests on defined endpoints and processes them accordingly, returning responses to the client.

Here's a detailed breakdown of what endpoints are, how they function, and how to design and use them effectively:

#### **What Are Endpoints?**

Endpoints are essentially URL patterns that represent a specific resource or functionality in a web application. They define the routes that clients (e.g., browsers, mobile apps) can use to request data from or send data to the server.

In RESTful APIs (Representational State Transfer), endpoints are typically mapped to CRUD (Create, Read, Update, Delete) operations on resources. These endpoints are accessed through HTTP methods like GET, POST, PUT, DELETE, etc.

For example:

- `/api/users` — Endpoint for accessing user data.
- `/api/users/{id}` — Endpoint for accessing a specific user’s data by their id.

#### **How Do Endpoints Work?**

#### **Basic Flow:**
1. **Client Sends a Request**: The client sends an HTTP request to a particular endpoint.
2. **Server Processes the Request**: The server receives the request, processes it, and performs the appropriate actions (such as querying the database or invoking business logic).
3. **Server Sends a Response**: The server sends a response back to the client, which could include data, a status message, or an error message.

#### **Request Types (HTTP Methods):**

Each endpoint typically supports certain HTTP methods to perform different actions on the resources:

- **GET**: Retrieves data from the server.  
  Example: `GET /api/users` - Retrieves a list of users.
  
- **POST**: Sends data to the server to create a new resource.  
  Example: `POST /api/users` - Creates a new user.

- **PUT**: Updates an existing resource on the server.  
  Example: `PUT /api/users/{id}` - Updates user data with a specified id.

- **DELETE**: Removes a resource from the server.  
  Example: `DELETE /api/users/{id}` - Deletes a user with a specific id.

- **PATCH**: Partially updates a resource on the server.  
  Example: `PATCH /api/users/{id}` - Updates part of the user’s data (e.g., change email address).

#### **Types of Endpoints**

#### 1. Public API Endpoints
Public endpoints are accessible by anyone without requiring authentication. These might be used to provide general information about your application or data that doesn't require security.

Example:
- `GET /api/products` — Get a list of all products.
- `GET /api/posts/{id}` — Get details of a specific blog post.

#### 2. Private / Protected API Endpoints
Private endpoints require authentication and authorization to access. They are protected by mechanisms like OAuth, JWT, or API Keys.

Example:
- `GET /api/user/profile` — Get the profile of the logged-in user.
- `POST /api/user/update` — Update the profile information of the logged-in user.

These are typically used in applications where the user's data must be protected.

#### 3. Admin Endpoints
Admin endpoints are typically reserved for administrative users who can manage data, users, or application settings. These endpoints often require higher-level privileges.

Example:
- `POST /admin/create-user` — Allows admin to create a new user.
- `DELETE /admin/delete-user/{id}` — Allows admin to delete a user by their id.

#### Endpoint Structure in RESTful APIs

In a RESTful API, endpoints are structured around resources (entities that the API works with) and the actions that can be performed on those resources.

#### Resource-Based Endpoints:
The URL path should represent the resource that the API is concerned with. It’s often plural to indicate that it handles multiple instances of that resource.

Example:
- `GET /api/users` — Retrieves all users.
- `POST /api/users` — Creates a new user.
- `GET /api/users/{id}` — Retrieves a specific user by id.
- `PUT /api/users/{id}` — Updates a user by id.
- `DELETE /api/users/{id}` — Deletes a user by id.

#### Actions vs. Resources:
- **Resources** are nouns (users, products, posts), representing the entity.
- **Actions** are verbs (create, update, delete, fetch), representing the operation performed on the resource.

#### Designing Good API Endpoints

A well-designed API endpoint structure ensures that the API is clean, intuitive, and easy to maintain. Here are some best practices for designing good API endpoints:

#### 1. Use HTTP Methods Appropriately
- **GET**: Use for retrieving data, should not have side effects (i.e., should not modify data).
- **POST**: Use for creating new resources.
- **PUT/PATCH**: Use for updating an existing resource.
- **DELETE**: Use for deleting resources.

#### 2. Use Meaningful and Consistent Naming
- Resource names should be plural to indicate collections (e.g., `/users`, `/products`).
- Use camelCase or snake_case consistently across endpoints (e.g., `/api/userProfile` or `/api/user_profile`).

#### 3. Include Parameters When Needed
Sometimes, endpoints may require parameters to filter, sort, or paginate data.

- **Path Parameters**: These are used to identify a specific resource or item (e.g., `GET /api/users/{id}`).
- **Query Parameters**: These are used for filtering, pagination, or sorting (e.g., `GET /api/users?sort=asc&limit=10`).

#### Example:
```bash
GET /api/products?page=2&size=10
```
#### This endpoint retrieves the second page of products, with each page containing 10 products.

#### 4. Provide Descriptive Status Codes
Status codes should accurately reflect the result of the request:

- **200 OK**: The request was successful.
- **201 Created**: A new resource was created.
- **400 Bad Request**: The request was invalid or missing parameters.
- **401 Unauthorized**: The request requires authentication.
- **403 Forbidden**: The request is understood but the server refuses to authorize it.
- **404 Not Found**: The requested resource could not be found.
- **500 Internal Server Error**: The server encountered an unexpected condition.

#### 5. Use Versioning for APIs
To ensure backward compatibility, it's important to version your APIs. This allows you to make changes to the API without breaking existing clients.

#### Example of Versioning in URLs:
- `/api/v1/users`
- `/api/v2/users`

#### 6. Avoid Deep Nesting
Deep nesting of resources (e.g., `/api/users/{id}/posts/{id}/comments/{id}`) can lead to complex and hard-to-read URLs. Instead, use pagination and filtering mechanisms for better scalability.

---

### Deployment

#### What is NGINX?

NGINX (pronounced "Engine-X") is an open-source, high-performance web server and reverse proxy. It also acts as a load balancer, HTTP cache, and supports SSL/TLS termination. NGINX is known for its scalability, low resource usage, and ability to handle high volumes of traffic, making it a go-to solution for serving static content, distributing load, and handling real-time applications.

#### Key Features of NGINX

- **Web Server**: NGINX serves static content (HTML, images, CSS, JavaScript) at high speed. It's optimized for delivering static files with minimal resource consumption.
- **Reverse Proxy**: It routes incoming client requests to one or more backend servers. This is commonly used to balance the load across multiple servers, improve security, and cache content.
- **Load Balancer**: NGINX distributes traffic to multiple servers using various algorithms like round-robin, least connections, IP hash, etc.
- **HTTP Cache**: It can cache responses from backend servers, reducing the load on upstream services and improving response times.
- **SSL/TLS Termination**: NGINX can handle encrypted HTTPS traffic, decrypting it and forwarding unencrypted traffic to the backend. This reduces the CPU load on backend servers.
- **Asynchronous & Event-Driven Architecture**: Unlike traditional web servers (e.g., Apache) that use a process or thread per request, NGINX uses a non-blocking, event-driven model, allowing it to handle thousands of simultaneous connections with minimal resources.

#### Why Use NGINX?

- **Performance**: NGINX is highly efficient, especially for static content and as a reverse proxy. Its event-driven architecture allows it to handle large numbers of simultaneous connections with low resource consumption.
- **Scalability**: It can scale easily, handling millions of concurrent connections and distributing load across backend servers. This makes it ideal for high-traffic websites and applications.
- **Flexibility**: NGINX is incredibly flexible, capable of acting as a reverse proxy, load balancer, web server, and more. It can be integrated into complex architectures (e.g., microservices, Kubernetes).
- **Reliability**: Known for being robust and stable, NGINX has been proven to work reliably in some of the busiest sites in the world (e.g., Netflix, GitHub, Airbnb).
- **Security**: NGINX provides strong security features such as rate limiting, access controls, and SSL/TLS termination, allowing you to protect your backend services from attacks like DDoS and unauthorized access.

#### NGINX vs Other Competitors

#### NGINX vs Apache HTTP Server

- **Architecture**: NGINX uses an event-driven, non-blocking model, while Apache uses a thread- or process-based approach. NGINX is more efficient in handling many simultaneous connections.
- **Performance**: NGINX performs better in handling static content and high traffic due to its asynchronous architecture. Apache, being process-based, has higher overhead for each connection.
- **Dynamic Content Handling**: Apache excels at serving dynamic content (via mod_php, mod_perl, etc.), while NGINX relies on backend services (like PHP-FPM or a Node.js server) for dynamic content. However, NGINX is highly effective at forwarding dynamic requests to these services.
- **Configuration**: Apache's `.htaccess` system allows for per-directory configurations, which can be more flexible but also slower. NGINX has centralized configuration files that are often simpler and faster but less flexible in some situations.
- **Resource Usage**: NGINX is more efficient in terms of CPU and memory usage when handling many simultaneous requests.

#### NGINX vs LiteSpeed

- **Speed**: LiteSpeed claims to outperform NGINX in terms of serving dynamic content (e.g., PHP), while NGINX is faster with static content.
- **Caching**: LiteSpeed has built-in caching mechanisms (like LSCache) that work out of the box for dynamic content. NGINX's caching can be configured manually or with additional modules.
- **Cost**: NGINX is open-source and free, while LiteSpeed offers both a free and paid version (with more advanced features in the paid version).
- **Ease of Use**: LiteSpeed offers a more user-friendly control panel for managing configurations, whereas NGINX requires manual editing of configuration files.

#### NGINX vs Caddy

- **SSL/TLS**: Caddy is known for automatically handling SSL certificates via Let's Encrypt, while NGINX requires manual configuration for SSL certificates.
- **Ease of Use**: Caddy’s configuration is simpler and uses a declarative style (Caddyfile), whereas NGINX uses a more complex configuration syntax (nginx.conf).
- **Performance**: NGINX tends to outperform Caddy in handling large-scale, high-traffic websites due to its event-driven architecture.

### **NGINX’s Dynamically Write Feature**

In NGINX, the **dynamically write feature** primarily refers to its ability to dynamically adjust, configure, and serve content based on **runtime changes** or **dynamic configurations**. This flexibility allows NGINX to adapt to varying traffic conditions, add or remove modules, change configurations, and more—all without requiring a complete restart. 

NGINX’s dynamic features are enabled mainly by its **modular architecture** and **configuration flexibility**, which allows for on-the-fly changes to how it handles requests. Let's explore this in detail.

---

#### **1. Dynamic Module Loading**

One of NGINX's most powerful dynamic features is the ability to **dynamically load modules**. 

When compiling NGINX, you can build it with support for **dynamic modules**, which means that you can load or unload modules as needed without having to restart the NGINX server. This feature provides significant flexibility, especially in production environments, where you may need to add new functionality or remove unnecessary modules without causing downtime.

#### **How It Works**
- **Dynamic modules** are compiled separately from the core NGINX code.
- These modules are loaded during runtime via the `load_module` directive in the NGINX configuration file (`nginx.conf`).
  
Example:
```nginx
# Dynamically load the ngx_http_rewrite_module
load_module modules/ngx_http_rewrite_module.so;
```

Once a dynamic module is loaded, its functionality becomes available to NGINX without needing to restart the server. This is especially useful for adding features like SSL/TLS support, new logging formats, or caching strategies without interrupting service.

#### **Benefits of Dynamic Module Loading**:
- **No Downtime**: You don’t need to restart NGINX when adding or removing modules, allowing for zero-downtime configuration updates.
- **Flexibility**: You can enable or disable modules as needed without recompiling NGINX. This is especially useful in environments where the needs change frequently.
- **Easier Upgrades**: When upgrading NGINX, new modules can be loaded dynamically, while old modules can be removed or replaced.

---

#### **2. Dynamic Load Balancing**

NGINX can dynamically adjust its load balancing strategy based on **server health** or **traffic conditions**. For example, NGINX can modify how it distributes traffic across upstream servers without requiring a restart.

#### **How It Works**
- NGINX uses an `upstream` block to define backend servers and can dynamically modify the traffic distribution among them based on specific criteria like the number of active connections, server health, or response time.
- The `server` directive in the `upstream` block can be used to mark servers as `down` or `backup` to dynamically remove or add them from the load balancing pool.

Example:
```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com backup;
}

server {
    location / {
        proxy_pass http://backend;
    }
}
```

In this example, `backend2.example.com` is marked as a **backup** server, which only handles requests if `backend1.example.com` goes down.

#### **Dynamic Server Removal and Addition**
- NGINX can detect if a backend server is down (using health checks or failure thresholds) and automatically remove it from the load balancing pool.
- New servers can be added dynamically by simply modifying the NGINX configuration and reloading NGINX without a restart.

Example of removing a server dynamically:
```nginx
upstream backend {
    server backend1.example.com;
    # Remove backend2 dynamically (no restart needed)
    server backend3.example.com;
}
```

---

#### **3. Dynamic Configuration Changes**

NGINX allows **dynamic changes to configurations** at runtime, which means that you can modify certain directives without needing to restart the entire service. This is essential in production environments, where uptime is critical.

#### **How It Works**
- NGINX has a **signal mechanism** that allows for a **graceful reload** of configurations. When you make changes to the configuration file (e.g., adding a new `server` block, changing the port, etc.), you can reload NGINX with minimal impact.
  
Example:
```bash
# Reload NGINX to apply changes without downtime
sudo nginx -s reload
```

This reloads the NGINX configuration by sending a signal to the running process, causing it to apply changes **without fully restarting** the server. The current worker processes will continue to handle ongoing connections while the new worker processes are spawned with the updated configuration.

#### **Dynamic Features with Config Changes**:
- **Adding Server Blocks**: You can dynamically add new virtual hosts (`server` blocks) for new websites or services.
- **Changing Resource Limits**: You can modify worker processes, connection limits, or buffer sizes dynamically.
- **Changing Load Balancing Algorithms**: If you’re using a round-robin or least-connections strategy for load balancing, you can adjust it dynamically without service interruption.
  
Example of changing worker settings dynamically:
```nginx
worker_processes 4;   # Change the number of worker processes to 4
worker_connections 1024;  # Adjust the number of connections per worker
```

By reloading the configuration (`nginx -s reload`), NGINX will adopt the new settings without dropping active connections.

---

#### **4. Dynamic Content Handling**

NGINX itself is a **high-performance web server** primarily designed for static content, but it can also dynamically handle content by **proxying requests** to backend servers or by using **external modules** (such as PHP-FPM or uWSGI) to process dynamic content.

#### **How It Works**:
- NGINX can **proxy dynamic requests** (e.g., PHP scripts or API calls) to backend servers that handle the logic and data processing, while NGINX handles traffic routing, load balancing, and caching.
  
Example for **PHP-FPM**:
```nginx
server {
    location ~ \.php$ {
        fastcgi_pass 127.0.0.1:9000;  # Send the request to PHP-FPM
        fastcgi_param SCRIPT_FILENAME /var/www/html$fastcgi_script_name;
        include fastcgi_params;
    }
}
```

- You can also use **reverse proxy** features to **dynamically route** requests to different services based on URL patterns, headers, or even load balancing strategies.
  
Example of dynamic URL routing:
```nginx
location /api/ {
    proxy_pass http://api_backend;
}

location /static/ {
    root /var/www/static;
}
```

This dynamically serves **static content** directly from the file system, while proxying API requests to a backend service.

---

#### **5. Dynamic Logging**

Another dynamic feature of NGINX is its ability to adjust **logging behavior** at runtime. While static configuration settings define where logs go, you can dynamically change things like **log format**, **log rotation**, or **log verbosity** without restarting NGINX.

#### **How It Works**
- You can modify logging levels (e.g., `error_log` and `access_log`) or rotate logs dynamically by adjusting log file paths and configuration.

Example:
```nginx
# Change error log level dynamically
error_log /var/log/nginx/error.log warn;
```

To apply the new logging settings, you can reload the NGINX configuration:
```bash
sudo nginx -s reload
```

---

#### **6. Dynamically Adjusting Resource Limits**

NGINX allows dynamic changes to server resource management to improve performance, especially under high loads. This includes adjusting worker processes, connection limits, buffer sizes, and more.

#### **How It Works**:
- For example, you can increase the **worker connections** or **worker processes** dynamically based on traffic levels without restarting NGINX.

Example:
```nginx
worker_processes auto;      # Automatically adjust number of worker processes
worker_connections 1024;     # Adjust number of allowed connections per worker
```

After making changes to these settings, a **graceful reload** can be performed to apply the new configuration while ensuring ongoing requests are not interrupted.

---

#### NGINX with Socket.IO

Socket.IO enables real-time, bidirectional communication between the client (typically browsers) and the server. NGINX is commonly used in real-time applications to handle WebSocket connections, which Socket.IO relies on.

#### How NGINX Works with Socket.IO:

- **WebSocket Proxying**: NGINX can forward WebSocket connections from clients to backend servers running Socket.IO. WebSocket uses HTTP for the initial handshake but upgrades the connection to a full-duplex communication channel. NGINX can pass this upgrade request to the backend server.
  
- **Sticky Sessions**: For WebSocket connections, NGINX can ensure that the same client is consistently routed to the same backend server throughout the duration of the WebSocket connection, which is important for session persistence.
  
- **Load Balancing**: If you have multiple backend servers, NGINX can load balance WebSocket connections to these servers, ensuring high availability and redundancy.

#### Example Configuration for Socket.IO with NGINX:

```nginx
location /socket.io/ {
    proxy_pass http://backend_socket_server;  # Backend server running Socket.IO
    proxy_http_version 1.1;                   # Ensure HTTP 1.1 is used for WebSocket support
    proxy_set_header Upgrade $http_upgrade;  # Handle the WebSocket upgrade request
    proxy_set_header Connection 'upgrade';   # Maintain connection for WebSocket communication
    proxy_set_header Host $host;              # Pass the host header to backend
    proxy_cache_bypass $http_upgrade;         # Ensure WebSocket traffic bypasses any caching
}
```

#### Explanation:

- **`proxy_pass`**: Directs NGINX to forward the request to the backend server running Socket.IO.
- **`proxy_http_version 1.1`**: Ensures WebSocket connections are handled with HTTP/1.1, required for the WebSocket protocol.
- **`proxy_set_header Upgrade $http_upgrade`**: Passes the WebSocket upgrade header to the backend server.
- **`proxy_set_header Connection 'upgrade'`**: Maintains the WebSocket connection throughout the session.
- **`proxy_set_header Host $host`**: Forwards the original host header to the backend server.
- **`proxy_cache_bypass $http_upgrade`**: Ensures that WebSocket traffic bypasses caching mechanisms.

This configuration ensures that NGINX can handle WebSocket connections, which are crucial for real-time applications like those using Socket.IO.


#### **What Are Build Logs in NGINX?**

**Build logs** in NGINX refer to the log files generated during the **compilation process** of NGINX from source code. These logs capture detailed information about the build process, including:

1. **Configuration Steps**: It records the configuration options you selected (e.g., enabling SSL, adding specific modules) when you compiled NGINX.

2. **Compilation Process**: The logs document the actual steps of compiling the NGINX source code, including which modules were compiled, any dependencies checked, and whether there were any issues.

3. **Warnings and Errors**: If there are any missing libraries, configuration issues, or errors in the code, the build logs will capture these and make troubleshooting easier.

4. **Installation Process**: They also track the installation of NGINX after the code has been successfully compiled, including file paths, libraries, and system configurations that are set up.

#### **Why Are Build Logs Important?**

1. **Troubleshooting**: Build logs provide crucial information if something goes wrong during the compilation or installation process. If NGINX doesn’t compile correctly, or if modules are not enabled as expected, the logs help identify the cause.

2. **Configuration Validation**: The logs show exactly which options were passed to the `./configure` script when NGINX was built. This helps you verify that the right modules and features were enabled.

3. **Detailed Output**: It provides a step-by-step record of the entire build process, including any problems with dependencies, missing libraries, or conflicts between components.

#### **Where Are Build Logs Stored?**

The location of NGINX build logs depends on where and how you compiled NGINX. If you compiled NGINX manually from source, you typically find the logs in the directory where you ran the `make` command.

- **Source Directory**: The build logs might be in the same directory as the NGINX source code (e.g., `/usr/local/src/nginx` or `/opt/nginx`), or in a dedicated **build directory** you created.

- **Common Locations**:

  - `/var/log/nginx_build/`

  - `/usr/local/src/nginx/`

  - `/tmp/` (temporary directory if you used a non-persistent path)

- **Log File Names**: Log files typically have names like `build.log`, `make.log`, or `install.log`.

#### **Contents of a Build Log**

A build log typically contains the following types of information:

#### 1. **Configuration Output**:

Before the actual compilation process, NGINX runs a `./configure` script where various options (e.g., enabling SSL, setting up paths, etc.) are specified. The log will capture the configuration output, detailing which modules are being enabled or disabled.

Example:

```

checking for the OpenSSL library... found

checking for pcre.h... yes

checking for zlib... yes

...

```

#### 2. **Compilation Messages**:

During the compilation process, the log will show messages about what files are being compiled, which source files are processed, and any errors or warnings encountered.

Example:

```

gcc -c -o objs/ngx_http_module.o src/http/ngx_http_module.c

...

```

#### 3. **Error and Warning Messages**:

If there are missing dependencies, configuration mistakes, or compilation errors, the log will contain **error messages** that help you pinpoint issues that need fixing before the build can succeed.

Example:

```

error: 'pcre' not found. Please install the PCRE development libraries.

```
#### 4. **Installation Details**:

Once NGINX is compiled, the installation steps (copying binaries to the correct locations, setting up configuration files, etc.) are also logged. This provides a record of exactly where files were placed on the system.

Example:

```

install -m 755 objs/nginx /usr/local/nginx/sbin/

```

#### **When Do Build Logs Get Created?**

Build logs are created during the **compilation process** when you install NGINX from source. This typically happens when you follow these steps:

1. **Download NGINX Source Code**: You download the NGINX source code from the official website or a repository. 

2. **Run the `./configure` Command**: This command prepares the system and configures NGINX with specified modules, libraries, and other options. The build log captures this configuration process.

3. **Run `make`**: This command actually compiles the NGINX source code. The build log will document the compilation of the source files.

4. **Run `make install`**: This final step installs the compiled NGINX binaries and configuration files. The build log will document this as well.

#### **Example Build Log**

Here’s an example of what the output in the build log might look like:

```

Checking for system libraries...

  - PCRE:         yes (2.9.6)

  - OpenSSL:      yes (1.1.1)

  - zlib:         yes (1.2.11)

  - HTTP2:        yes

  - SSL support:  yes

Configuring NGINX...

  - Enable SSL module: yes

  - Enable HTTP2 module: yes

Compiling NGINX...

  - gcc -c -o objs/ngx_http_ssl_module.o src/http/ngx_http_ssl_module.c

  - gcc -c -o objs/ngx_http_v2_module.o src/http/ngx_http_v2_module.c

Installation...

  - Installing NGINX binary to /usr/local/nginx/sbin/nginx

  - Installing configuration files to /usr/local/nginx/conf/

NGINX build finished successfully.

```

### **Issues in Build Logs**

During the build process, you might encounter issues that will be captured in the logs. Common issues include:

- **Missing Dependencies**: If a required library (e.g., OpenSSL or PCRE) isn’t found, the build log will flag this as an error.

- **Permissions Issues**: Sometimes, NGINX might not have permission to write files to certain directories (e.g., `/usr/local/nginx`).

- **Out of Memory**: If the server doesn’t have enough resources (memory or CPU), the log might contain messages indicating that the process was terminated unexpectedly.

#### **Managing NGINX Build Logs**

#### **Why You Need to Clear Build Logs**

When you compile or install NGINX from source, the **build logs** are generated to record the progress, errors, warnings, and configuration settings used during the compilation process. These logs can include a lot of detailed information, and while they are useful during troubleshooting or initial setup, they are generally not needed once the installation is complete. If left unchecked, these logs can take up significant disk space over time, especially if you’re compiling or updating NGINX frequently.

**Here’s why it’s important to clear build logs periodically:**
1. **Disk Space Consumption**: Build logs can grow large, especially if you’ve built NGINX multiple times or compiled with verbose logging options. If the logs are not cleaned up, they can fill up disk space, which can eventually lead to **storage exhaustion** and server performance degradation.
   
2. **Clutter**: Over time, old build logs accumulate and can make it harder to troubleshoot current builds or installations. Keeping logs organized is important for maintaining an efficient environment.

3. **Compilation and Redundancy**: If build logs are kept in directories that are also used for future builds or updates, old logs may be recompiled or accessed unnecessarily, leading to **redundant log data** or potential issues with file storage management.

4. **Security**: Sometimes, build logs contain sensitive information about your server environment, configurations, or dependencies. If these logs are not deleted, they can inadvertently expose system details or paths that could be leveraged by attackers.

#### **How to Clean Up Build Logs**

#### **1. Delete Build Logs After Installation**
After you’ve successfully compiled and installed NGINX, you can safely remove the build logs to free up space. For example, if you compiled NGINX from source, the logs are typically stored in the directory where the build process took place (often `/usr/local/src/nginx/` or a similar location).

To remove the build logs:
```bash
cd /path/to/nginx-source-directory
rm -rf *log*
```
This will delete all files with "log" in the name. Be cautious when doing this to avoid accidentally deleting necessary files.

#### **2. Periodic Log Cleanup via Cron Jobs**
If you perform frequent builds or updates (e.g., automated CI/CD pipelines), you can automate the cleanup process using a **cron job**.

For example, set up a cron job that cleans the build log directory every week or month:

```bash
# Edit the crontab
crontab -e

# Add the following line to remove logs older than 30 days
0 0 * * 0 find /path/to/nginx/logs -type f -name "*.log" -mtime +30 -exec rm -f {} \;
```
This cron job will delete all `.log` files in the specified directory that are older than 30 days.

#### **3. Log Rotation**
You can set up **log rotation** to limit the size of the log files generated during builds. This ensures that the logs don’t grow too large and consume all available space.

For example, configure a simple log rotation rule for build logs using `logrotate`:

1. **Create a new logrotate configuration**:
   ```bash
   sudo nano /etc/logrotate.d/nginx_build_logs
   ```

2. **Add log rotation settings**:
   ```text
   /path/to/nginx/build_logs/*.log {
       daily
       rotate 7
       compress
       missingok
       notifempty
       create 0644 root root
   }
   ```

   This configuration ensures that build logs are rotated daily, keeping the last 7 days’ worth of logs, and compressing old logs to save space.

#### **4. Monitor Log Growth**
Regularly check the size of your build logs to ensure they are not consuming too much disk space. You can monitor log file sizes with the following command:
```bash
du -sh /path/to/nginx/build_logs/
```
This will give you a quick overview of how much disk space the build logs are using.

---

#### **Conclusion**

While **NGINX** is a powerful tool for handling high-traffic applications, **build logs** generated during installation or compilation can accumulate and take up valuable disk space. It's important to periodically **clear** or **rotate** these logs to prevent them from consuming server resources and to ensure your server runs efficiently. Implementing automated log rotation or periodic cleanup via cron jobs will help you keep things tidy and avoid unnecessary server bloat.

### Deployment Process:

#### **1. Development** (Local Development with ReactJS and Spring Boot)

During development, you typically have two separate projects:

- **ReactJS frontend**: A **JavaScript** framework that manages the user interface (UI) and communicates with the backend via API calls.
- **Spring Boot backend**: A **Java-based framework** that handles the business logic, API endpoints, and interacts with the database (like MySQL).

**Local Development Setup**:
- **ReactJS**: You use **npm (Node Package Manager)** to manage dependencies and run the development server (usually on port 3000).
- **Spring Boot**: You run the backend using mvn spring-boot:run (if using Maven) or ./gradlew bootRun (if using Gradle), which typically runs on port 8080.

This is your local development setup, where you are actively building and testing your frontend and backend.

#### **2. Version Control** (Using GitHub)

Once you’ve made changes or added features, you **commit** your code and **push** it to a **Git repository** (e.g., GitHub, GitLab, or Bitbucket). Version control is essential for managing code revisions, collaborating with teams, and keeping track of changes over time.

#### **Steps in Version Control**:
- **Commit changes**: After writing code, use git commit to save changes locally.
  
```bash
  git commit -m "Added login feature"
```
- **Push changes**: Send your commits to the remote GitHub repository.
  
```bash
  git push origin main
```
- **Collaborate**: Your team members can pull the latest code, create branches for new features, and push their changes as well.

Once your code is pushed to GitHub, the next step is to **deploy** it to a server.

#### **3. Server Setup on Ubuntu** (Preparing the Production Server)

You need a **server** to host your application. Let’s assume you’re using **Ubuntu 24.04** on a **VPS** provided by **Hostinger**. You need to install and configure the necessary tools to run the application.

#### **1. Prepare the Server for Deployment**

Before we begin deploying the app, you need to set up your **Ubuntu server** with the necessary software.

#### **What needs to be installed on Ubuntu**:
1. **Java (for Spring Boot)**:
   - Install **OpenJDK 11** (since Spring Boot requires Java):
     
```bash
     sudo apt update
     sudo apt install openjdk-11-jdk
```

   - Verify Java installation:
     
```bash
     java -version
```

2. **Node.js and npm (for ReactJS)**:
   - Install Node.js and npm (which ReactJS uses):
     
```bash
     sudo apt install nodejs npm
```

   - Verify Node.js installation:
     
```bash
     node -v
     npm -v
```

3. **MySQL (for database)**:
   - Install MySQL server:
     
```bash
     sudo apt install mysql-server
 ``` 
   - Secure the MySQL installation:
   
```bash
     sudo mysql_secure_installation
```

   - Verify MySQL is running:
     
```bash
     sudo systemctl status mysql
```

4. **Nginx (to serve the frontend and reverse proxy requests to the backend)**:
   - Install Nginx:
     
```bash
     sudo apt install nginx
```

   - Verify Nginx is running:
     
```bash
     sudo systemctl status nginx
```

5. **Git (to pull your repositories)**:
   - Install Git:
     
```bash
     sudo apt install git
```

---

#### **2. Deploy the Spring Boot Backend**

Now we will focus on deploying the **Spring Boot backend** first. This is critical because the **ReactJS frontend** will likely depend on the backend's API endpoints, so having the backend ready before the frontend is a good approach.

#### **Steps for deploying Spring Boot**:

#### a. **Build the Spring Boot JAR File Locally**:

1. Navigate to your **Spring Boot project directory**:
   
```bash
   cd /path/to/spring-boot-app
```

2. **Package the Spring Boot application** into a JAR file:
   - If you're using **Maven**, run:
     
```bash
     mvn clean package
```

   - If you're using **Gradle**, run:
     
```bash
     ./gradlew build
```

   This will create a target/your-app.jar file (or in build/libs/ if using Gradle).

#### b. **Transfer the JAR File to the Server**:

Transfer the generated JAR file to your **Ubuntu server** using **SCP** or **FTP**:
bash
scp target/your-app.jar username@your-server-ip:/opt/your-app/

(If you used Gradle, the path will be build/libs/your-app.jar.)

#### c. **Run the Spring Boot Application**:

1. SSH into the server:
   
```bash
   ssh username@your-server-ip
```

2. Start the Spring Boot application with:
   
```bash
   java -jar /opt/your-app/your-app.jar
```
   By default, the Spring Boot app will run on port **8080**.

3. To run the application in the background, you can use **nohup**:
   
```bash
   nohup java -jar /opt/your-app/your-app.jar > /dev/null 2>&1 &
```

#### d. **Verify the Spring Boot Application**:

Make sure your Spring Boot app is running correctly by checking if it's accessible via:
```bash
http://your-server-ip:8080
```

---

#### **3. Configure Nginx to Proxy Requests to Spring Boot**

At this point, your backend (Spring Boot) is running, and Nginx is the next key component. You'll configure Nginx to reverse proxy API requests to Spring Boot and prepare for the ReactJS frontend.

#### **Steps for configuring Nginx**:
1. **Edit Nginx Configuration**:
   Create or modify an Nginx config file for your app.
   
```bash
   sudo nano /etc/nginx/sites-available/your-app
```

2. Add the following configuration to **serve your Spring Boot API** on the /api/ route:
   
```nginx
   server {
       listen 80;
       server_name your-domain.com;

       # Reverse proxy to Spring Boot
       location /api/ {
           proxy_pass http://localhost:8080/;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
       }
   }
```

   This setup ensures that all requests to your-domain.com/api/ will be forwarded to the Spring Boot app running locally on port 8080.

3. **Enable the site**:
   Create a symbolic link to the Nginx config file:
   
```bash
   sudo ln -s /etc/nginx/sites-available/your-app /etc/nginx/sites-enabled/
```

4. **Test Nginx Configuration**:
   Before applying changes, test the Nginx configuration:
   
```bash
   sudo nginx -t
```

5. **Reload Nginx**:
   After testing the config, reload Nginx to apply changes:
   
```bash
   sudo systemctl reload nginx
```

Your Spring Boot backend should now be accessible through the domain at http://your-domain.com/api/.

---

#### **4. Deploy the ReactJS Frontend**

Once the Spring Boot backend is deployed and working, we can now focus on deploying the **ReactJS frontend**.

#### **Steps for deploying ReactJS**:

#### a. **Build the ReactJS Application Locally**:
1. Navigate to your **ReactJS project** directory:
   
```bash
   cd /path/to/react-app
```

2. **Install the dependencies** (if not done already):
   
```bash
   npm install
```

3. **Build the ReactJS app** for production:
   
```bash
   npm run build
```
   This will create a build/ directory with optimized static files.

#### b. **Transfer the Build Files to the Server**:
You need to copy the contents of the build/ directory to your server.

- Use **SCP** to transfer files to the server:
   
```bash
   scp -r build/ username@your-server-ip:/var/www/your-app/
```

#### c. **Configure Nginx to Serve ReactJS Static Files**:
1. **Edit Nginx Configuration** again to serve the ReactJS files:
   
```bash
   sudo nano /etc/nginx/sites-available/your-app
```

2. Add this configuration to serve static files for the frontend:
   
```nginx
   server {
       listen 80;
       server_name your-domain.com;

       root /var/www/your-app;
       index index.html;

       location / {
           try_files $uri $uri/ /index.html;
       }

       location /api/ {
           proxy_pass http://localhost:8080/;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
       }
   }

```
   - The / location block will serve the static files (HTML, JS, CSS) generated by the ReactJS build.
   - The /api/ location block will forward API requests to the Spring Boot backend running on port 8080.

3. **Enable the Site and Reload Nginx**:
   If you haven’t already enabled the site and reloaded Nginx, follow the previous steps:
   
```bash
   sudo ln -s /etc/nginx/sites-available/your-app /etc/nginx/sites-enabled/
   sudo nginx -t
   sudo systemctl reload nginx
```

Your ReactJS frontend should now be served at http://your-domain.com, and it will be able to make API requests to the Spring Boot backend at http://your-domain.com/api/.

---

#### **5. Domain Configuration and SSL (Optional but Recommended)**

To make your app accessible via a custom domain and **secure it with HTTPS**, follow these steps:

#### **DNS Setup**:
1. **DNS**: Point your **domain name** (e.g., your-domain.com) to the **IP address** of your server through your Hostinger DNS settings.

#### **SSL Configuration with Let's Encrypt**:
1. Install **Certbot** and **Let's Encrypt** for automatic SSL certificate management:
   
```bash
   sudo apt install certbot python3-certbot-nginx
```

2. Obtain an SSL certificate for your domain:
   
```bash
   sudo certbot --nginx
```

   Certbot will automatically configure Nginx for SSL and redirect HTTP traffic to HTTPS.

---

#### **6. Final Steps**

- **Monitor Logs**: Use journalctl to monitor logs for both **Nginx** and the **Spring Boot application**.
- **Test the App**: Visit http://your-domain.com to check if the frontend is served correctly and interacts with the backend. Make sure HTTPS works if you set it up.

---
#### **Summary of the Deployment Process**:

1. **Development**: You work locally on your ReactJS frontend and Spring Boot backend.
2. **Version Control**: Use Git to push your code to GitHub.
3. **Server Setup**: Install required tools on your Ubuntu server (Java, Node.js, MySQL, Nginx, Git).
4. **App Deployment**:
   - Build and deploy the ReactJS frontend to Nginx.
   - Package and deploy the Spring Boot backend as a JAR file, and run it.
   - Configure Nginx as a reverse proxy to handle frontend and API requests.
5. **Access**: Make your app accessible via a custom domain and secure it with SSL (through Hostinger).
